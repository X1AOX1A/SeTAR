2024-06-16 05:00:37,386 | INFO | argparser.py:195 | print_args | Loading args from config file: configs/finetune/clip_base/ID_ImageNet1K/LoRA.json
2024-06-16 05:00:37,386 | INFO | argparser.py:198 | print_args | Config: 
{
    "data_root": "/data/DATASETS/SVD_OOD",
    "id_dataset": "ID_ImageNet1K",
    "split": "val",
    "batch_size": 100,
    "seed": 5,
    "device": "cuda",
    "exp_name": "LoRA",
    "log_directory": "./results/finetune/clip_base/ID_ImageNet1K/LoRA",
    "scorers": [
        "mcm_score",
        "gl_mcm_score"
    ],
    "temperature": 100,
    "recall_level": 0.95,
    "model_name": "openai/clip-vit-base-patch16",
    "model_type": "CLIP",
    "clip_ckpt": null,
    "locoop_ckpt": null,
    "lora_svd_init": false,
    "lora_svd_init_type": null,
    "lora_settings": null,
    "target_modules": [
        "mlp.fc1"
    ],
    "lora_r": 32,
    "lora_alpha": 16,
    "n_ctx": 16,
    "num_train_epochs": 5,
    "max_train_steps": null,
    "gradient_accumulation_steps": 1,
    "learning_rate": 0.01,
    "weight_decay": 0.0005,
    "momentum": 0.9,
    "lr_scheduler_type": "cosine",
    "num_warmup_steps": 0,
    "locoop_lambda": 0.1,
    "locoop_top_k": 300,
    "logging_steps": 1
}
2024-06-16 05:00:37,567 | WARNING | other.py:349 | check_os_kernel | Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2024-06-16 05:00:37,568 | INFO | finetune.py:35 | run_finetune | Loading CLIP model: openai/clip-vit-base-patch16...
trainable params: 2,457,600 || all params: 152,078,337 || trainable%: 1.6160092544936233
base_model.model.text_model.encoder.layers.0.mlp.fc1.lora_A.default.weight [32, 512]
base_model.model.text_model.encoder.layers.0.mlp.fc1.lora_B.default.weight [2048, 32]
base_model.model.text_model.encoder.layers.1.mlp.fc1.lora_A.default.weight [32, 512]
base_model.model.text_model.encoder.layers.1.mlp.fc1.lora_B.default.weight [2048, 32]
base_model.model.text_model.encoder.layers.2.mlp.fc1.lora_A.default.weight [32, 512]
base_model.model.text_model.encoder.layers.2.mlp.fc1.lora_B.default.weight [2048, 32]
base_model.model.text_model.encoder.layers.3.mlp.fc1.lora_A.default.weight [32, 512]
base_model.model.text_model.encoder.layers.3.mlp.fc1.lora_B.default.weight [2048, 32]
base_model.model.text_model.encoder.layers.4.mlp.fc1.lora_A.default.weight [32, 512]
base_model.model.text_model.encoder.layers.4.mlp.fc1.lora_B.default.weight [2048, 32]
base_model.model.text_model.encoder.layers.5.mlp.fc1.lora_A.default.weight [32, 512]
base_model.model.text_model.encoder.layers.5.mlp.fc1.lora_B.default.weight [2048, 32]
base_model.model.text_model.encoder.layers.6.mlp.fc1.lora_A.default.weight [32, 512]
base_model.model.text_model.encoder.layers.6.mlp.fc1.lora_B.default.weight [2048, 32]
base_model.model.text_model.encoder.layers.7.mlp.fc1.lora_A.default.weight [32, 512]
base_model.model.text_model.encoder.layers.7.mlp.fc1.lora_B.default.weight [2048, 32]
base_model.model.text_model.encoder.layers.8.mlp.fc1.lora_A.default.weight [32, 512]
base_model.model.text_model.encoder.layers.8.mlp.fc1.lora_B.default.weight [2048, 32]
base_model.model.text_model.encoder.layers.9.mlp.fc1.lora_A.default.weight [32, 512]
base_model.model.text_model.encoder.layers.9.mlp.fc1.lora_B.default.weight [2048, 32]
base_model.model.text_model.encoder.layers.10.mlp.fc1.lora_A.default.weight [32, 512]
base_model.model.text_model.encoder.layers.10.mlp.fc1.lora_B.default.weight [2048, 32]
base_model.model.text_model.encoder.layers.11.mlp.fc1.lora_A.default.weight [32, 512]
base_model.model.text_model.encoder.layers.11.mlp.fc1.lora_B.default.weight [2048, 32]
base_model.model.vision_model.encoder.layers.0.mlp.fc1.lora_A.default.weight [32, 768]
base_model.model.vision_model.encoder.layers.0.mlp.fc1.lora_B.default.weight [3072, 32]
base_model.model.vision_model.encoder.layers.1.mlp.fc1.lora_A.default.weight [32, 768]
base_model.model.vision_model.encoder.layers.1.mlp.fc1.lora_B.default.weight [3072, 32]
base_model.model.vision_model.encoder.layers.2.mlp.fc1.lora_A.default.weight [32, 768]
base_model.model.vision_model.encoder.layers.2.mlp.fc1.lora_B.default.weight [3072, 32]
base_model.model.vision_model.encoder.layers.3.mlp.fc1.lora_A.default.weight [32, 768]
base_model.model.vision_model.encoder.layers.3.mlp.fc1.lora_B.default.weight [3072, 32]
base_model.model.vision_model.encoder.layers.4.mlp.fc1.lora_A.default.weight [32, 768]
base_model.model.vision_model.encoder.layers.4.mlp.fc1.lora_B.default.weight [3072, 32]
base_model.model.vision_model.encoder.layers.5.mlp.fc1.lora_A.default.weight [32, 768]
base_model.model.vision_model.encoder.layers.5.mlp.fc1.lora_B.default.weight [3072, 32]
base_model.model.vision_model.encoder.layers.6.mlp.fc1.lora_A.default.weight [32, 768]
base_model.model.vision_model.encoder.layers.6.mlp.fc1.lora_B.default.weight [3072, 32]
base_model.model.vision_model.encoder.layers.7.mlp.fc1.lora_A.default.weight [32, 768]
base_model.model.vision_model.encoder.layers.7.mlp.fc1.lora_B.default.weight [3072, 32]
base_model.model.vision_model.encoder.layers.8.mlp.fc1.lora_A.default.weight [32, 768]
base_model.model.vision_model.encoder.layers.8.mlp.fc1.lora_B.default.weight [3072, 32]
base_model.model.vision_model.encoder.layers.9.mlp.fc1.lora_A.default.weight [32, 768]
base_model.model.vision_model.encoder.layers.9.mlp.fc1.lora_B.default.weight [3072, 32]
base_model.model.vision_model.encoder.layers.10.mlp.fc1.lora_A.default.weight [32, 768]
base_model.model.vision_model.encoder.layers.10.mlp.fc1.lora_B.default.weight [3072, 32]
base_model.model.vision_model.encoder.layers.11.mlp.fc1.lora_A.default.weight [32, 768]
base_model.model.vision_model.encoder.layers.11.mlp.fc1.lora_B.default.weight [3072, 32]
2024-06-16 05:00:38,934 | INFO | finetune.py:118 | run_finetune | ***** Running training *****
2024-06-16 05:00:38,935 | INFO | finetune.py:119 | run_finetune |   Num examples = 1000
2024-06-16 05:00:38,935 | INFO | finetune.py:120 | run_finetune |   Num Epochs = 5
2024-06-16 05:00:38,935 | INFO | finetune.py:121 | run_finetune |   Instantaneous batch size per device = 100
2024-06-16 05:00:38,935 | INFO | finetune.py:122 | run_finetune |   Total train batch size (w. parallel, distributed & accumulation) = 100
2024-06-16 05:00:38,935 | INFO | finetune.py:123 | run_finetune |   Gradient Accumulation steps = 1
2024-06-16 05:00:38,935 | INFO | finetune.py:124 | run_finetune |   Total optimization steps = 50
2024-06-16 05:00:41,346 | INFO | finetune.py:158 | run_finetune | Epoch 0 | Step 0 | Loss: 0.8031 | Loss ID: 1.2398 | Loss OOD: -4.3674
2024-06-16 05:00:41,966 | INFO | finetune.py:158 | run_finetune | Epoch 0 | Step 1 | Loss: 0.6258 | Loss ID: 1.0749 | Loss OOD: -4.4905
2024-06-16 05:00:42,582 | INFO | finetune.py:158 | run_finetune | Epoch 0 | Step 2 | Loss: 0.7140 | Loss ID: 1.1562 | Loss OOD: -4.4212
2024-06-16 05:00:43,198 | INFO | finetune.py:158 | run_finetune | Epoch 0 | Step 3 | Loss: 0.8845 | Loss ID: 1.3234 | Loss OOD: -4.3894
2024-06-16 05:00:43,813 | INFO | finetune.py:158 | run_finetune | Epoch 0 | Step 4 | Loss: 0.4791 | Loss ID: 0.9287 | Loss OOD: -4.4955
2024-06-16 05:00:44,430 | INFO | finetune.py:158 | run_finetune | Epoch 0 | Step 5 | Loss: 0.6963 | Loss ID: 1.1432 | Loss OOD: -4.4692
2024-06-16 05:00:45,047 | INFO | finetune.py:158 | run_finetune | Epoch 0 | Step 6 | Loss: 0.4376 | Loss ID: 0.8853 | Loss OOD: -4.4776
2024-06-16 05:00:45,664 | INFO | finetune.py:158 | run_finetune | Epoch 0 | Step 7 | Loss: 0.6691 | Loss ID: 1.1192 | Loss OOD: -4.5008
2024-06-16 05:00:46,280 | INFO | finetune.py:158 | run_finetune | Epoch 0 | Step 8 | Loss: 0.8243 | Loss ID: 1.2685 | Loss OOD: -4.4423
2024-06-16 05:00:46,967 | INFO | finetune.py:158 | run_finetune | Epoch 0 | Step 9 | Loss: 0.6118 | Loss ID: 1.0626 | Loss OOD: -4.5083
2024-06-16 05:00:48,262 | INFO | finetune.py:158 | run_finetune | Epoch 1 | Step 0 | Loss: 0.5972 | Loss ID: 1.0479 | Loss OOD: -4.5069
2024-06-16 05:00:48,880 | INFO | finetune.py:158 | run_finetune | Epoch 1 | Step 1 | Loss: 0.9031 | Loss ID: 1.3516 | Loss OOD: -4.4845
2024-06-16 05:00:49,498 | INFO | finetune.py:158 | run_finetune | Epoch 1 | Step 2 | Loss: 0.6229 | Loss ID: 1.0684 | Loss OOD: -4.4546
2024-06-16 05:00:50,116 | INFO | finetune.py:158 | run_finetune | Epoch 1 | Step 3 | Loss: 0.4503 | Loss ID: 0.8967 | Loss OOD: -4.4636
2024-06-16 05:00:50,733 | INFO | finetune.py:158 | run_finetune | Epoch 1 | Step 4 | Loss: 0.8001 | Loss ID: 1.2488 | Loss OOD: -4.4873
2024-06-16 05:00:51,350 | INFO | finetune.py:158 | run_finetune | Epoch 1 | Step 5 | Loss: 0.6586 | Loss ID: 1.1153 | Loss OOD: -4.5666
2024-06-16 05:00:51,968 | INFO | finetune.py:158 | run_finetune | Epoch 1 | Step 6 | Loss: 0.3736 | Loss ID: 0.8259 | Loss OOD: -4.5233
2024-06-16 05:00:52,586 | INFO | finetune.py:158 | run_finetune | Epoch 1 | Step 7 | Loss: 0.5134 | Loss ID: 0.9686 | Loss OOD: -4.5514
2024-06-16 05:00:53,202 | INFO | finetune.py:158 | run_finetune | Epoch 1 | Step 8 | Loss: 0.4819 | Loss ID: 0.9271 | Loss OOD: -4.4517
2024-06-16 05:00:53,892 | INFO | finetune.py:158 | run_finetune | Epoch 1 | Step 9 | Loss: 0.7355 | Loss ID: 1.1838 | Loss OOD: -4.4824
2024-06-16 05:00:55,306 | INFO | finetune.py:158 | run_finetune | Epoch 2 | Step 0 | Loss: 0.4702 | Loss ID: 0.9161 | Loss OOD: -4.4592
2024-06-16 05:00:55,926 | INFO | finetune.py:158 | run_finetune | Epoch 2 | Step 1 | Loss: 0.6585 | Loss ID: 1.1133 | Loss OOD: -4.5485
2024-06-16 05:00:56,544 | INFO | finetune.py:158 | run_finetune | Epoch 2 | Step 2 | Loss: 0.7035 | Loss ID: 1.1580 | Loss OOD: -4.5447
2024-06-16 05:00:57,163 | INFO | finetune.py:158 | run_finetune | Epoch 2 | Step 3 | Loss: 0.3992 | Loss ID: 0.8506 | Loss OOD: -4.5139
2024-06-16 05:00:57,784 | INFO | finetune.py:158 | run_finetune | Epoch 2 | Step 4 | Loss: 0.5823 | Loss ID: 1.0314 | Loss OOD: -4.4909
2024-06-16 05:00:58,405 | INFO | finetune.py:158 | run_finetune | Epoch 2 | Step 5 | Loss: 0.6689 | Loss ID: 1.1241 | Loss OOD: -4.5519
2024-06-16 05:00:59,025 | INFO | finetune.py:158 | run_finetune | Epoch 2 | Step 6 | Loss: 0.8727 | Loss ID: 1.3196 | Loss OOD: -4.4699
2024-06-16 05:00:59,644 | INFO | finetune.py:158 | run_finetune | Epoch 2 | Step 7 | Loss: 0.3756 | Loss ID: 0.8266 | Loss OOD: -4.5098
2024-06-16 05:01:00,263 | INFO | finetune.py:158 | run_finetune | Epoch 2 | Step 8 | Loss: 0.5440 | Loss ID: 0.9993 | Loss OOD: -4.5525
2024-06-16 05:01:00,964 | INFO | finetune.py:158 | run_finetune | Epoch 2 | Step 9 | Loss: 0.4206 | Loss ID: 0.8790 | Loss OOD: -4.5847
2024-06-16 05:01:02,391 | INFO | finetune.py:158 | run_finetune | Epoch 3 | Step 0 | Loss: 0.5437 | Loss ID: 0.9938 | Loss OOD: -4.5007
2024-06-16 05:01:03,013 | INFO | finetune.py:158 | run_finetune | Epoch 3 | Step 1 | Loss: 0.9070 | Loss ID: 1.3618 | Loss OOD: -4.5483
2024-06-16 05:01:03,634 | INFO | finetune.py:158 | run_finetune | Epoch 3 | Step 2 | Loss: 0.7557 | Loss ID: 1.2020 | Loss OOD: -4.4634
2024-06-16 05:01:04,256 | INFO | finetune.py:158 | run_finetune | Epoch 3 | Step 3 | Loss: 0.5126 | Loss ID: 0.9739 | Loss OOD: -4.6123
2024-06-16 05:01:04,878 | INFO | finetune.py:158 | run_finetune | Epoch 3 | Step 4 | Loss: 0.6240 | Loss ID: 1.0776 | Loss OOD: -4.5356
2024-06-16 05:01:05,499 | INFO | finetune.py:158 | run_finetune | Epoch 3 | Step 5 | Loss: 0.4795 | Loss ID: 0.9374 | Loss OOD: -4.5788
2024-06-16 05:01:06,119 | INFO | finetune.py:158 | run_finetune | Epoch 3 | Step 6 | Loss: 0.5086 | Loss ID: 0.9601 | Loss OOD: -4.5157
2024-06-16 05:01:06,739 | INFO | finetune.py:158 | run_finetune | Epoch 3 | Step 7 | Loss: 0.2454 | Loss ID: 0.7029 | Loss OOD: -4.5757
2024-06-16 05:01:07,360 | INFO | finetune.py:158 | run_finetune | Epoch 3 | Step 8 | Loss: 0.6256 | Loss ID: 1.0810 | Loss OOD: -4.5532
2024-06-16 05:01:08,051 | INFO | finetune.py:158 | run_finetune | Epoch 3 | Step 9 | Loss: 0.3065 | Loss ID: 0.7592 | Loss OOD: -4.5261
2024-06-16 05:01:09,414 | INFO | finetune.py:158 | run_finetune | Epoch 4 | Step 0 | Loss: 0.3317 | Loss ID: 0.7894 | Loss OOD: -4.5774
2024-06-16 05:01:10,036 | INFO | finetune.py:158 | run_finetune | Epoch 4 | Step 1 | Loss: 0.7169 | Loss ID: 1.1731 | Loss OOD: -4.5615
2024-06-16 05:01:10,658 | INFO | finetune.py:158 | run_finetune | Epoch 4 | Step 2 | Loss: 0.4363 | Loss ID: 0.8918 | Loss OOD: -4.5549
2024-06-16 05:01:11,280 | INFO | finetune.py:158 | run_finetune | Epoch 4 | Step 3 | Loss: 0.5822 | Loss ID: 1.0448 | Loss OOD: -4.6259
2024-06-16 05:01:11,902 | INFO | finetune.py:158 | run_finetune | Epoch 4 | Step 4 | Loss: 0.5325 | Loss ID: 0.9806 | Loss OOD: -4.4815
2024-06-16 05:01:12,524 | INFO | finetune.py:158 | run_finetune | Epoch 4 | Step 5 | Loss: 0.5643 | Loss ID: 1.0144 | Loss OOD: -4.5009
2024-06-16 05:01:13,145 | INFO | finetune.py:158 | run_finetune | Epoch 4 | Step 6 | Loss: 0.4907 | Loss ID: 0.9426 | Loss OOD: -4.5183
2024-06-16 05:01:13,766 | INFO | finetune.py:158 | run_finetune | Epoch 4 | Step 7 | Loss: 0.8269 | Loss ID: 1.2843 | Loss OOD: -4.5738
2024-06-16 05:01:14,388 | INFO | finetune.py:158 | run_finetune | Epoch 4 | Step 8 | Loss: 0.5026 | Loss ID: 0.9594 | Loss OOD: -4.5679
2024-06-16 05:01:15,081 | INFO | finetune.py:158 | run_finetune | Epoch 4 | Step 9 | Loss: 0.4578 | Loss ID: 0.9075 | Loss OOD: -4.4971
2024-06-16 05:01:15,959 | INFO | finetune.py:182 | run_finetune | Model saved to ./results/finetune/clip_base/ID_ImageNet1K/LoRA/finetuned_model.pth
2024-06-16 05:01:15,959 | INFO | finetune.py:187 | run_finetune | ############ Done! Finetune time: 0m 39s ############
2024-06-16 05:01:15,970 | INFO | test_ood.py:29 | run_test_ood | ############ Test OOD Detection ############
2024-06-16 05:01:15,970 | INFO | test_ood.py:30 | run_test_ood | Loading CLIP model: openai/clip-vit-base-patch16...
2024-06-16 05:01:16,507 | INFO | test_ood.py:45 | run_test_ood | Loading CLIP model weights from ./results/finetune/clip_base/ID_ImageNet1K/LoRA/finetuned_model.pth...
2024-06-16 05:01:16,920 | INFO | test_ood.py:63 | run_test_ood | ############ ID dataset: ID_ImageNet1K, test set: 50000 images ############
2024-06-16 05:01:16,920 | INFO | test_ood.py:65 | run_test_ood | Computing scores for ID_ImageNet1K...
2024-06-16 05:03:34,659 | INFO | model_hub.py:304 | compute_scores | Took 137.74 s to run.
2024-06-16 05:03:34,878 | INFO | test_ood.py:78 | run_test_ood | ############ OOD dataset: OOD_iNaturalist, test set: 10000 images ############
2024-06-16 05:03:34,878 | INFO | test_ood.py:80 | run_test_ood | Computing scores for OOD_iNaturalist...
2024-06-16 05:04:04,067 | INFO | model_hub.py:304 | compute_scores | Took 29.19 s to run.
2024-06-16 05:04:04,147 | INFO | metrics.py:55 | print_metrics | OOD_iNaturalist - mcm_score
2024-06-16 05:04:04,148 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:04:04,148 | INFO | metrics.py:57 | print_metrics | & 30.40 & 94.52 & 98.82
2024-06-16 05:04:05,094 | INFO | metrics.py:55 | print_metrics | OOD_iNaturalist - gl_mcm_score
2024-06-16 05:04:05,094 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:04:05,094 | INFO | metrics.py:57 | print_metrics | & 15.17 & 96.46 & 99.15
2024-06-16 05:04:05,839 | INFO | test_ood.py:78 | run_test_ood | ############ OOD dataset: OOD_Sun, test set: 10000 images ############
2024-06-16 05:04:05,839 | INFO | test_ood.py:80 | run_test_ood | Computing scores for OOD_Sun...
2024-06-16 05:04:37,468 | INFO | model_hub.py:304 | compute_scores | Took 31.63 s to run.
2024-06-16 05:04:37,543 | INFO | metrics.py:55 | print_metrics | OOD_Sun - mcm_score
2024-06-16 05:04:37,544 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:04:37,544 | INFO | metrics.py:57 | print_metrics | & 34.84 & 92.91 & 98.34
2024-06-16 05:04:38,373 | INFO | metrics.py:55 | print_metrics | OOD_Sun - gl_mcm_score
2024-06-16 05:04:38,373 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:04:38,373 | INFO | metrics.py:57 | print_metrics | & 27.75 & 93.51 & 98.33
2024-06-16 05:04:39,113 | INFO | test_ood.py:78 | run_test_ood | ############ OOD dataset: OOD_Places, test set: 10000 images ############
2024-06-16 05:04:39,113 | INFO | test_ood.py:80 | run_test_ood | Computing scores for OOD_Places...
2024-06-16 05:05:07,730 | INFO | model_hub.py:304 | compute_scores | Took 28.62 s to run.
2024-06-16 05:05:07,811 | INFO | metrics.py:55 | print_metrics | OOD_Places - mcm_score
2024-06-16 05:05:07,811 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:05:07,811 | INFO | metrics.py:57 | print_metrics | & 43.00 & 90.06 & 97.55
2024-06-16 05:05:08,595 | INFO | metrics.py:55 | print_metrics | OOD_Places - gl_mcm_score
2024-06-16 05:05:08,595 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:05:08,595 | INFO | metrics.py:57 | print_metrics | & 36.52 & 90.34 & 97.45
2024-06-16 05:05:09,348 | INFO | test_ood.py:78 | run_test_ood | ############ OOD dataset: OOD_Texture, test set: 5640 images ############
2024-06-16 05:05:09,348 | INFO | test_ood.py:80 | run_test_ood | Computing scores for OOD_Texture...
2024-06-16 05:05:25,875 | INFO | model_hub.py:304 | compute_scores | Took 16.53 s to run.
2024-06-16 05:05:25,934 | INFO | metrics.py:55 | print_metrics | OOD_Texture - mcm_score
2024-06-16 05:05:25,934 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:05:25,934 | INFO | metrics.py:57 | print_metrics | & 57.87 & 85.93 & 97.99
2024-06-16 05:05:26,674 | INFO | metrics.py:55 | print_metrics | OOD_Texture - gl_mcm_score
2024-06-16 05:05:26,674 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:05:26,674 | INFO | metrics.py:57 | print_metrics | & 57.48 & 83.17 & 97.25
2024-06-16 05:05:27,332 | INFO | test_ood.py:98 | run_test_ood | ############ Metrics for mcm_score ############
2024-06-16 05:05:27,335 | INFO | metrics.py:76 | save_metrics | ############ Mean metrics ############
2024-06-16 05:05:27,337 | INFO | metrics.py:77 | save_metrics | 
                 FPR95  AUROC  AUPR
OOD dataset                        
OOD_iNaturalist  30.40  94.52 98.82
OOD_Sun          34.84  92.91 98.34
OOD_Places       43.00  90.06 97.55
OOD_Texture      57.87  85.93 97.99
Avg              41.53  90.86 98.18
2024-06-16 05:05:27,337 | INFO | metrics.py:78 | save_metrics | Metrics saved to ./results/finetune/clip_base/ID_ImageNet1K/LoRA/metrics_mcm_score_test.csv
2024-06-16 05:05:27,338 | INFO | metrics.py:87 | save_cutoffs | ############ Thresholds Cut-off ############
2024-06-16 05:05:27,339 | INFO | metrics.py:88 | save_cutoffs | 
    OOD dataset   Cutoff
OOD_iNaturalist 0.001095
        OOD_Sun 0.001095
     OOD_Places 0.001095
    OOD_Texture 0.001095
2024-06-16 05:05:27,339 | INFO | metrics.py:89 | save_cutoffs | Thresholds cutoff saved to ./results/finetune/clip_base/ID_ImageNet1K/LoRA/cutoffs_mcm_score_test.csv
2024-06-16 05:05:27,339 | INFO | test_ood.py:98 | run_test_ood | ############ Metrics for gl_mcm_score ############
2024-06-16 05:05:27,341 | INFO | metrics.py:76 | save_metrics | ############ Mean metrics ############
2024-06-16 05:05:27,342 | INFO | metrics.py:77 | save_metrics | 
                 FPR95  AUROC  AUPR
OOD dataset                        
OOD_iNaturalist  15.17  96.46 99.15
OOD_Sun          27.75  93.51 98.33
OOD_Places       36.52  90.34 97.45
OOD_Texture      57.48  83.17 97.25
Avg              34.23  90.87 98.05
2024-06-16 05:05:27,342 | INFO | metrics.py:78 | save_metrics | Metrics saved to ./results/finetune/clip_base/ID_ImageNet1K/LoRA/metrics_gl_mcm_score_test.csv
2024-06-16 05:05:27,342 | INFO | metrics.py:87 | save_cutoffs | ############ Thresholds Cut-off ############
2024-06-16 05:05:27,343 | INFO | metrics.py:88 | save_cutoffs | 
    OOD dataset   Cutoff
OOD_iNaturalist 0.002231
        OOD_Sun 0.002231
     OOD_Places 0.002231
    OOD_Texture 0.002231
2024-06-16 05:05:27,343 | INFO | metrics.py:89 | save_cutoffs | Thresholds cutoff saved to ./results/finetune/clip_base/ID_ImageNet1K/LoRA/cutoffs_gl_mcm_score_test.csv
2024-06-16 05:05:27,343 | INFO | test_ood.py:107 | run_test_ood | ############ Done! Test time: 4m 11s ############
2024-06-16 05:05:27,344 | INFO | test_classify.py:121 | run_test_classify | ############ Test Classification ############
2024-06-16 05:05:27,344 | INFO | test_classify.py:122 | run_test_classify | Loading CLIP model: openai/clip-vit-base-patch16...
2024-06-16 05:05:27,850 | INFO | test_classify.py:137 | run_test_classify | Loading clip model weights from ./results/finetune/clip_base/ID_ImageNet1K/LoRA/finetuned_model.pth...
2024-06-16 05:05:28,170 | INFO | test_classify.py:151 | run_test_classify | ############ ID_ImageNet1K ############
2024-06-16 05:08:42,988 | INFO | test_classify.py:161 | run_test_classify | Accuracy on ID_ImageNet1K: 65.48
2024-06-16 05:08:42,989 | INFO | test_classify.py:151 | run_test_classify | ############ OOD_Sun ############
2024-06-16 05:09:09,795 | INFO | test_classify.py:161 | run_test_classify | Accuracy on OOD_Sun: 76.99
2024-06-16 05:09:09,796 | INFO | test_classify.py:151 | run_test_classify | ############ OOD_Places ############
2024-06-16 05:09:35,115 | INFO | test_classify.py:161 | run_test_classify | Accuracy on OOD_Places: 46.73
2024-06-16 05:09:35,116 | INFO | test_classify.py:151 | run_test_classify | ############ OOD_Texture ############
2024-06-16 05:09:49,888 | INFO | test_classify.py:161 | run_test_classify | Accuracy on OOD_Texture: 44.01
2024-06-16 05:09:49,889 | INFO | test_classify.py:164 | run_test_classify | ############ Summary ############
2024-06-16 05:09:49,889 | INFO | test_classify.py:166 | run_test_classify | Accuracy on ID_ImageNet1K: 65.48
2024-06-16 05:09:49,889 | INFO | test_classify.py:166 | run_test_classify | Accuracy on OOD_Sun: 76.99
2024-06-16 05:09:49,889 | INFO | test_classify.py:166 | run_test_classify | Accuracy on OOD_Places: 46.73
2024-06-16 05:09:49,889 | INFO | test_classify.py:166 | run_test_classify | Accuracy on OOD_Texture: 44.01
