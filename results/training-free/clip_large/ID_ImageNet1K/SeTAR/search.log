2024-06-16 04:57:24,355 | INFO | argparser.py:195 | print_args | Loading args from config file: configs/training_free/clip_large/ID_ImageNet/SeTAR.json
2024-06-16 04:57:24,355 | INFO | argparser.py:198 | print_args | Config: 
{
    "data_root": "/data/DATASETS/SVD_OOD",
    "id_dataset": "ID_ImageNet1K",
    "split": "val",
    "batch_size": 512,
    "seed": 5,
    "device": "cuda",
    "exp_name": "SeTAR",
    "log_directory": "./results/training-free/clip_large/ID_ImageNet1K/SeTAR",
    "scorers": [
        "loss"
    ],
    "temperature": 100,
    "recall_level": 0.95,
    "model_name": "openai/clip-vit-large-patch14",
    "model_type": "CLIP",
    "clip_ckpt": null,
    "locoop_ckpt": null,
    "lora_svd_init": true,
    "lora_svd_init_type": "small",
    "lora_settings": null,
    "target_modules": null,
    "lora_r": null,
    "lora_alpha": null,
    "n_ctx": 16,
    "searcher": "visual_text",
    "candi_ratios": [
        0,
        0.05,
        0.1,
        0.15,
        0.2,
        0.25,
        0.3,
        0.35,
        0.4
    ],
    "weight_type": "W_up",
    "best_scorer": "loss",
    "best_metric": "locoop_loss",
    "freeze_proj": true,
    "locoop_lambda": 0.5,
    "locoop_top_k": 300,
    "use_pred_label": false
}
2024-06-16 04:57:24,359 | INFO | searchers.py:66 | __init__ | Best scorer: loss
2024-06-16 04:57:24,359 | INFO | searchers.py:67 | __init__ | Best metric: locoop_loss
2024-06-16 04:57:24,359 | INFO | searchers.py:33 | __init__ | ############ Searcher Created ############
2024-06-16 04:57:24,359 | INFO | searchers.py:34 | __init__ | Searcher: visual_text
2024-06-16 04:57:24,359 | INFO | searchers.py:172 | run | Start searching low rank configs...
2024-06-16 04:59:29,766 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood   acc  ood_patch_percent
step                                                                                                         
0        visual        W_up         23           0     -1.404933  0.906337  -4.62254  75.5          52.552733

2024-06-16 05:01:34,232 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood   acc  ood_patch_percent
step                                                                                                         
0        visual        W_up         23           0     -1.404933  0.906337  -4.62254  75.5          52.552733
1        visual        W_up         22           0     -1.404933  0.906337  -4.62254  75.5          52.552733

2024-06-16 05:03:38,313 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood   acc  ood_patch_percent
step                                                                                                         
0        visual        W_up         23           0     -1.404933  0.906337  -4.62254  75.5          52.552733
1        visual        W_up         22           0     -1.404933  0.906337  -4.62254  75.5          52.552733
2        visual        W_up         21           0     -1.404933  0.906337  -4.62254  75.5          52.552733

2024-06-16 05:05:44,065 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217

2024-06-16 05:07:49,328 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217
4        visual        W_up         19        0.15     -1.408512  0.903748 -4.624519  76.099997          51.811328

2024-06-16 05:09:55,551 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217
4        visual        W_up         19        0.15     -1.408512  0.903748 -4.624519  76.099997          51.811328
5        visual        W_up         18        0.10     -1.408648  0.905461 -4.628218  76.200000          51.507030

2024-06-16 05:12:02,189 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217
4        visual        W_up         19        0.15     -1.408512  0.903748 -4.624519  76.099997          51.811328
5        visual        W_up         18        0.10     -1.408648  0.905461 -4.628218  76.200000          51.507030
6        visual        W_up         17        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030

2024-06-16 05:14:09,170 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217
4        visual        W_up         19        0.15     -1.408512  0.903748 -4.624519  76.099997          51.811328
5        visual        W_up         18        0.10     -1.408648  0.905461 -4.628218  76.200000          51.507030
6        visual        W_up         17        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
7        visual        W_up         16        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030

2024-06-16 05:16:16,442 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217
4        visual        W_up         19        0.15     -1.408512  0.903748 -4.624519  76.099997          51.811328
5        visual        W_up         18        0.10     -1.408648  0.905461 -4.628218  76.200000          51.507030
6        visual        W_up         17        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
7        visual        W_up         16        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
8        visual        W_up         15        0.05     -1.410563  0.904274 -4.629674  76.000000          51.428906

2024-06-16 05:18:24,347 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217
4        visual        W_up         19        0.15     -1.408512  0.903748 -4.624519  76.099997          51.811328
5        visual        W_up         18        0.10     -1.408648  0.905461 -4.628218  76.200000          51.507030
6        visual        W_up         17        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
7        visual        W_up         16        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
8        visual        W_up         15        0.05     -1.410563  0.904274 -4.629674  76.000000          51.428906
9        visual        W_up         14        0.10     -1.416562  0.900849 -4.634820  75.899997          51.252342

2024-06-16 05:20:33,155 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217
4        visual        W_up         19        0.15     -1.408512  0.903748 -4.624519  76.099997          51.811328
5        visual        W_up         18        0.10     -1.408648  0.905461 -4.628218  76.200000          51.507030
6        visual        W_up         17        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
7        visual        W_up         16        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
8        visual        W_up         15        0.05     -1.410563  0.904274 -4.629674  76.000000          51.428906
9        visual        W_up         14        0.10     -1.416562  0.900849 -4.634820  75.899997          51.252342
10       visual        W_up         13        0.20     -1.416798  0.903797 -4.641190  76.199996          51.159764

2024-06-16 05:22:42,395 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217
4        visual        W_up         19        0.15     -1.408512  0.903748 -4.624519  76.099997          51.811328
5        visual        W_up         18        0.10     -1.408648  0.905461 -4.628218  76.200000          51.507030
6        visual        W_up         17        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
7        visual        W_up         16        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
8        visual        W_up         15        0.05     -1.410563  0.904274 -4.629674  76.000000          51.428906
9        visual        W_up         14        0.10     -1.416562  0.900849 -4.634820  75.899997          51.252342
10       visual        W_up         13        0.20     -1.416798  0.903797 -4.641190  76.199996          51.159764
11       visual        W_up         12        0.00     -1.416798  0.903797 -4.641190  76.199996          51.159764

2024-06-16 05:24:51,891 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217
4        visual        W_up         19        0.15     -1.408512  0.903748 -4.624519  76.099997          51.811328
5        visual        W_up         18        0.10     -1.408648  0.905461 -4.628218  76.200000          51.507030
6        visual        W_up         17        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
7        visual        W_up         16        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
8        visual        W_up         15        0.05     -1.410563  0.904274 -4.629674  76.000000          51.428906
9        visual        W_up         14        0.10     -1.416562  0.900849 -4.634820  75.899997          51.252342
10       visual        W_up         13        0.20     -1.416798  0.903797 -4.641190  76.199996          51.159764
11       visual        W_up         12        0.00     -1.416798  0.903797 -4.641190  76.199996          51.159764
12       visual        W_up         11        0.15     -1.418277  0.903203 -4.642959  76.399996          51.062889

2024-06-16 05:27:01,560 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217
4        visual        W_up         19        0.15     -1.408512  0.903748 -4.624519  76.099997          51.811328
5        visual        W_up         18        0.10     -1.408648  0.905461 -4.628218  76.200000          51.507030
6        visual        W_up         17        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
7        visual        W_up         16        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
8        visual        W_up         15        0.05     -1.410563  0.904274 -4.629674  76.000000          51.428906
9        visual        W_up         14        0.10     -1.416562  0.900849 -4.634820  75.899997          51.252342
10       visual        W_up         13        0.20     -1.416798  0.903797 -4.641190  76.199996          51.159764
11       visual        W_up         12        0.00     -1.416798  0.903797 -4.641190  76.199996          51.159764
12       visual        W_up         11        0.15     -1.418277  0.903203 -4.642959  76.399996          51.062889
13       visual        W_up         10        0.00     -1.418277  0.903203 -4.642959  76.399996          51.062889

2024-06-16 05:29:11,715 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217
4        visual        W_up         19        0.15     -1.408512  0.903748 -4.624519  76.099997          51.811328
5        visual        W_up         18        0.10     -1.408648  0.905461 -4.628218  76.200000          51.507030
6        visual        W_up         17        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
7        visual        W_up         16        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
8        visual        W_up         15        0.05     -1.410563  0.904274 -4.629674  76.000000          51.428906
9        visual        W_up         14        0.10     -1.416562  0.900849 -4.634820  75.899997          51.252342
10       visual        W_up         13        0.20     -1.416798  0.903797 -4.641190  76.199996          51.159764
11       visual        W_up         12        0.00     -1.416798  0.903797 -4.641190  76.199996          51.159764
12       visual        W_up         11        0.15     -1.418277  0.903203 -4.642959  76.399996          51.062889
13       visual        W_up         10        0.00     -1.418277  0.903203 -4.642959  76.399996          51.062889
14       visual        W_up          9        0.10     -1.418311  0.903165 -4.642952  75.299997          51.119529

2024-06-16 05:31:21,895 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217
4        visual        W_up         19        0.15     -1.408512  0.903748 -4.624519  76.099997          51.811328
5        visual        W_up         18        0.10     -1.408648  0.905461 -4.628218  76.200000          51.507030
6        visual        W_up         17        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
7        visual        W_up         16        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
8        visual        W_up         15        0.05     -1.410563  0.904274 -4.629674  76.000000          51.428906
9        visual        W_up         14        0.10     -1.416562  0.900849 -4.634820  75.899997          51.252342
10       visual        W_up         13        0.20     -1.416798  0.903797 -4.641190  76.199996          51.159764
11       visual        W_up         12        0.00     -1.416798  0.903797 -4.641190  76.199996          51.159764
12       visual        W_up         11        0.15     -1.418277  0.903203 -4.642959  76.399996          51.062889
13       visual        W_up         10        0.00     -1.418277  0.903203 -4.642959  76.399996          51.062889
14       visual        W_up          9        0.10     -1.418311  0.903165 -4.642952  75.299997          51.119529
15       visual        W_up          8        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529

2024-06-16 05:33:31,571 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217
4        visual        W_up         19        0.15     -1.408512  0.903748 -4.624519  76.099997          51.811328
5        visual        W_up         18        0.10     -1.408648  0.905461 -4.628218  76.200000          51.507030
6        visual        W_up         17        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
7        visual        W_up         16        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
8        visual        W_up         15        0.05     -1.410563  0.904274 -4.629674  76.000000          51.428906
9        visual        W_up         14        0.10     -1.416562  0.900849 -4.634820  75.899997          51.252342
10       visual        W_up         13        0.20     -1.416798  0.903797 -4.641190  76.199996          51.159764
11       visual        W_up         12        0.00     -1.416798  0.903797 -4.641190  76.199996          51.159764
12       visual        W_up         11        0.15     -1.418277  0.903203 -4.642959  76.399996          51.062889
13       visual        W_up         10        0.00     -1.418277  0.903203 -4.642959  76.399996          51.062889
14       visual        W_up          9        0.10     -1.418311  0.903165 -4.642952  75.299997          51.119529
15       visual        W_up          8        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
16       visual        W_up          7        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529

2024-06-16 05:35:41,364 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217
4        visual        W_up         19        0.15     -1.408512  0.903748 -4.624519  76.099997          51.811328
5        visual        W_up         18        0.10     -1.408648  0.905461 -4.628218  76.200000          51.507030
6        visual        W_up         17        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
7        visual        W_up         16        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
8        visual        W_up         15        0.05     -1.410563  0.904274 -4.629674  76.000000          51.428906
9        visual        W_up         14        0.10     -1.416562  0.900849 -4.634820  75.899997          51.252342
10       visual        W_up         13        0.20     -1.416798  0.903797 -4.641190  76.199996          51.159764
11       visual        W_up         12        0.00     -1.416798  0.903797 -4.641190  76.199996          51.159764
12       visual        W_up         11        0.15     -1.418277  0.903203 -4.642959  76.399996          51.062889
13       visual        W_up         10        0.00     -1.418277  0.903203 -4.642959  76.399996          51.062889
14       visual        W_up          9        0.10     -1.418311  0.903165 -4.642952  75.299997          51.119529
15       visual        W_up          8        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
16       visual        W_up          7        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
17       visual        W_up          6        0.05     -1.419138  0.901809 -4.641894  75.900000          51.133202

2024-06-16 05:37:51,540 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217
4        visual        W_up         19        0.15     -1.408512  0.903748 -4.624519  76.099997          51.811328
5        visual        W_up         18        0.10     -1.408648  0.905461 -4.628218  76.200000          51.507030
6        visual        W_up         17        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
7        visual        W_up         16        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
8        visual        W_up         15        0.05     -1.410563  0.904274 -4.629674  76.000000          51.428906
9        visual        W_up         14        0.10     -1.416562  0.900849 -4.634820  75.899997          51.252342
10       visual        W_up         13        0.20     -1.416798  0.903797 -4.641190  76.199996          51.159764
11       visual        W_up         12        0.00     -1.416798  0.903797 -4.641190  76.199996          51.159764
12       visual        W_up         11        0.15     -1.418277  0.903203 -4.642959  76.399996          51.062889
13       visual        W_up         10        0.00     -1.418277  0.903203 -4.642959  76.399996          51.062889
14       visual        W_up          9        0.10     -1.418311  0.903165 -4.642952  75.299997          51.119529
15       visual        W_up          8        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
16       visual        W_up          7        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
17       visual        W_up          6        0.05     -1.419138  0.901809 -4.641894  75.900000          51.133202
18       visual        W_up          5        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202

2024-06-16 05:40:01,643 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217
4        visual        W_up         19        0.15     -1.408512  0.903748 -4.624519  76.099997          51.811328
5        visual        W_up         18        0.10     -1.408648  0.905461 -4.628218  76.200000          51.507030
6        visual        W_up         17        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
7        visual        W_up         16        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
8        visual        W_up         15        0.05     -1.410563  0.904274 -4.629674  76.000000          51.428906
9        visual        W_up         14        0.10     -1.416562  0.900849 -4.634820  75.899997          51.252342
10       visual        W_up         13        0.20     -1.416798  0.903797 -4.641190  76.199996          51.159764
11       visual        W_up         12        0.00     -1.416798  0.903797 -4.641190  76.199996          51.159764
12       visual        W_up         11        0.15     -1.418277  0.903203 -4.642959  76.399996          51.062889
13       visual        W_up         10        0.00     -1.418277  0.903203 -4.642959  76.399996          51.062889
14       visual        W_up          9        0.10     -1.418311  0.903165 -4.642952  75.299997          51.119529
15       visual        W_up          8        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
16       visual        W_up          7        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
17       visual        W_up          6        0.05     -1.419138  0.901809 -4.641894  75.900000          51.133202
18       visual        W_up          5        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
19       visual        W_up          4        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202

2024-06-16 05:42:12,323 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217
4        visual        W_up         19        0.15     -1.408512  0.903748 -4.624519  76.099997          51.811328
5        visual        W_up         18        0.10     -1.408648  0.905461 -4.628218  76.200000          51.507030
6        visual        W_up         17        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
7        visual        W_up         16        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
8        visual        W_up         15        0.05     -1.410563  0.904274 -4.629674  76.000000          51.428906
9        visual        W_up         14        0.10     -1.416562  0.900849 -4.634820  75.899997          51.252342
10       visual        W_up         13        0.20     -1.416798  0.903797 -4.641190  76.199996          51.159764
11       visual        W_up         12        0.00     -1.416798  0.903797 -4.641190  76.199996          51.159764
12       visual        W_up         11        0.15     -1.418277  0.903203 -4.642959  76.399996          51.062889
13       visual        W_up         10        0.00     -1.418277  0.903203 -4.642959  76.399996          51.062889
14       visual        W_up          9        0.10     -1.418311  0.903165 -4.642952  75.299997          51.119529
15       visual        W_up          8        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
16       visual        W_up          7        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
17       visual        W_up          6        0.05     -1.419138  0.901809 -4.641894  75.900000          51.133202
18       visual        W_up          5        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
19       visual        W_up          4        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
20       visual        W_up          3        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202

2024-06-16 05:44:22,299 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217
4        visual        W_up         19        0.15     -1.408512  0.903748 -4.624519  76.099997          51.811328
5        visual        W_up         18        0.10     -1.408648  0.905461 -4.628218  76.200000          51.507030
6        visual        W_up         17        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
7        visual        W_up         16        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
8        visual        W_up         15        0.05     -1.410563  0.904274 -4.629674  76.000000          51.428906
9        visual        W_up         14        0.10     -1.416562  0.900849 -4.634820  75.899997          51.252342
10       visual        W_up         13        0.20     -1.416798  0.903797 -4.641190  76.199996          51.159764
11       visual        W_up         12        0.00     -1.416798  0.903797 -4.641190  76.199996          51.159764
12       visual        W_up         11        0.15     -1.418277  0.903203 -4.642959  76.399996          51.062889
13       visual        W_up         10        0.00     -1.418277  0.903203 -4.642959  76.399996          51.062889
14       visual        W_up          9        0.10     -1.418311  0.903165 -4.642952  75.299997          51.119529
15       visual        W_up          8        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
16       visual        W_up          7        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
17       visual        W_up          6        0.05     -1.419138  0.901809 -4.641894  75.900000          51.133202
18       visual        W_up          5        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
19       visual        W_up          4        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
20       visual        W_up          3        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
21       visual        W_up          2        0.15     -1.420932  0.900220 -4.642305  75.799996          51.133983

2024-06-16 05:46:32,709 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217
4        visual        W_up         19        0.15     -1.408512  0.903748 -4.624519  76.099997          51.811328
5        visual        W_up         18        0.10     -1.408648  0.905461 -4.628218  76.200000          51.507030
6        visual        W_up         17        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
7        visual        W_up         16        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
8        visual        W_up         15        0.05     -1.410563  0.904274 -4.629674  76.000000          51.428906
9        visual        W_up         14        0.10     -1.416562  0.900849 -4.634820  75.899997          51.252342
10       visual        W_up         13        0.20     -1.416798  0.903797 -4.641190  76.199996          51.159764
11       visual        W_up         12        0.00     -1.416798  0.903797 -4.641190  76.199996          51.159764
12       visual        W_up         11        0.15     -1.418277  0.903203 -4.642959  76.399996          51.062889
13       visual        W_up         10        0.00     -1.418277  0.903203 -4.642959  76.399996          51.062889
14       visual        W_up          9        0.10     -1.418311  0.903165 -4.642952  75.299997          51.119529
15       visual        W_up          8        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
16       visual        W_up          7        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
17       visual        W_up          6        0.05     -1.419138  0.901809 -4.641894  75.900000          51.133202
18       visual        W_up          5        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
19       visual        W_up          4        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
20       visual        W_up          3        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
21       visual        W_up          2        0.15     -1.420932  0.900220 -4.642305  75.799996          51.133983
22       visual        W_up          1        0.00     -1.420932  0.900220 -4.642305  75.799996          51.133983

2024-06-16 05:48:44,749 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217
4        visual        W_up         19        0.15     -1.408512  0.903748 -4.624519  76.099997          51.811328
5        visual        W_up         18        0.10     -1.408648  0.905461 -4.628218  76.200000          51.507030
6        visual        W_up         17        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
7        visual        W_up         16        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
8        visual        W_up         15        0.05     -1.410563  0.904274 -4.629674  76.000000          51.428906
9        visual        W_up         14        0.10     -1.416562  0.900849 -4.634820  75.899997          51.252342
10       visual        W_up         13        0.20     -1.416798  0.903797 -4.641190  76.199996          51.159764
11       visual        W_up         12        0.00     -1.416798  0.903797 -4.641190  76.199996          51.159764
12       visual        W_up         11        0.15     -1.418277  0.903203 -4.642959  76.399996          51.062889
13       visual        W_up         10        0.00     -1.418277  0.903203 -4.642959  76.399996          51.062889
14       visual        W_up          9        0.10     -1.418311  0.903165 -4.642952  75.299997          51.119529
15       visual        W_up          8        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
16       visual        W_up          7        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
17       visual        W_up          6        0.05     -1.419138  0.901809 -4.641894  75.900000          51.133202
18       visual        W_up          5        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
19       visual        W_up          4        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
20       visual        W_up          3        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
21       visual        W_up          2        0.15     -1.420932  0.900220 -4.642305  75.799996          51.133983
22       visual        W_up          1        0.00     -1.420932  0.900220 -4.642305  75.799996          51.133983
23       visual        W_up          0        0.40     -1.421037  0.900018 -4.642108  75.899996          51.129686

2024-06-16 05:50:56,135 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217
4        visual        W_up         19        0.15     -1.408512  0.903748 -4.624519  76.099997          51.811328
5        visual        W_up         18        0.10     -1.408648  0.905461 -4.628218  76.200000          51.507030
6        visual        W_up         17        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
7        visual        W_up         16        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
8        visual        W_up         15        0.05     -1.410563  0.904274 -4.629674  76.000000          51.428906
9        visual        W_up         14        0.10     -1.416562  0.900849 -4.634820  75.899997          51.252342
10       visual        W_up         13        0.20     -1.416798  0.903797 -4.641190  76.199996          51.159764
11       visual        W_up         12        0.00     -1.416798  0.903797 -4.641190  76.199996          51.159764
12       visual        W_up         11        0.15     -1.418277  0.903203 -4.642959  76.399996          51.062889
13       visual        W_up         10        0.00     -1.418277  0.903203 -4.642959  76.399996          51.062889
14       visual        W_up          9        0.10     -1.418311  0.903165 -4.642952  75.299997          51.119529
15       visual        W_up          8        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
16       visual        W_up          7        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
17       visual        W_up          6        0.05     -1.419138  0.901809 -4.641894  75.900000          51.133202
18       visual        W_up          5        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
19       visual        W_up          4        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
20       visual        W_up          3        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
21       visual        W_up          2        0.15     -1.420932  0.900220 -4.642305  75.799996          51.133983
22       visual        W_up          1        0.00     -1.420932  0.900220 -4.642305  75.799996          51.133983
23       visual        W_up          0        0.40     -1.421037  0.900018 -4.642108  75.899996          51.129686
24         text        W_up         11        0.35     -1.435382  0.913222 -4.697208  75.600000          50.488280

2024-06-16 05:53:07,447 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217
4        visual        W_up         19        0.15     -1.408512  0.903748 -4.624519  76.099997          51.811328
5        visual        W_up         18        0.10     -1.408648  0.905461 -4.628218  76.200000          51.507030
6        visual        W_up         17        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
7        visual        W_up         16        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
8        visual        W_up         15        0.05     -1.410563  0.904274 -4.629674  76.000000          51.428906
9        visual        W_up         14        0.10     -1.416562  0.900849 -4.634820  75.899997          51.252342
10       visual        W_up         13        0.20     -1.416798  0.903797 -4.641190  76.199996          51.159764
11       visual        W_up         12        0.00     -1.416798  0.903797 -4.641190  76.199996          51.159764
12       visual        W_up         11        0.15     -1.418277  0.903203 -4.642959  76.399996          51.062889
13       visual        W_up         10        0.00     -1.418277  0.903203 -4.642959  76.399996          51.062889
14       visual        W_up          9        0.10     -1.418311  0.903165 -4.642952  75.299997          51.119529
15       visual        W_up          8        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
16       visual        W_up          7        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
17       visual        W_up          6        0.05     -1.419138  0.901809 -4.641894  75.900000          51.133202
18       visual        W_up          5        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
19       visual        W_up          4        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
20       visual        W_up          3        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
21       visual        W_up          2        0.15     -1.420932  0.900220 -4.642305  75.799996          51.133983
22       visual        W_up          1        0.00     -1.420932  0.900220 -4.642305  75.799996          51.133983
23       visual        W_up          0        0.40     -1.421037  0.900018 -4.642108  75.899996          51.129686
24         text        W_up         11        0.35     -1.435382  0.913222 -4.697208  75.600000          50.488280
25         text        W_up         10        0.00     -1.435382  0.913222 -4.697208  75.600000          50.488280

2024-06-16 05:55:19,100 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217
4        visual        W_up         19        0.15     -1.408512  0.903748 -4.624519  76.099997          51.811328
5        visual        W_up         18        0.10     -1.408648  0.905461 -4.628218  76.200000          51.507030
6        visual        W_up         17        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
7        visual        W_up         16        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
8        visual        W_up         15        0.05     -1.410563  0.904274 -4.629674  76.000000          51.428906
9        visual        W_up         14        0.10     -1.416562  0.900849 -4.634820  75.899997          51.252342
10       visual        W_up         13        0.20     -1.416798  0.903797 -4.641190  76.199996          51.159764
11       visual        W_up         12        0.00     -1.416798  0.903797 -4.641190  76.199996          51.159764
12       visual        W_up         11        0.15     -1.418277  0.903203 -4.642959  76.399996          51.062889
13       visual        W_up         10        0.00     -1.418277  0.903203 -4.642959  76.399996          51.062889
14       visual        W_up          9        0.10     -1.418311  0.903165 -4.642952  75.299997          51.119529
15       visual        W_up          8        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
16       visual        W_up          7        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
17       visual        W_up          6        0.05     -1.419138  0.901809 -4.641894  75.900000          51.133202
18       visual        W_up          5        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
19       visual        W_up          4        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
20       visual        W_up          3        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
21       visual        W_up          2        0.15     -1.420932  0.900220 -4.642305  75.799996          51.133983
22       visual        W_up          1        0.00     -1.420932  0.900220 -4.642305  75.799996          51.133983
23       visual        W_up          0        0.40     -1.421037  0.900018 -4.642108  75.899996          51.129686
24         text        W_up         11        0.35     -1.435382  0.913222 -4.697208  75.600000          50.488280
25         text        W_up         10        0.00     -1.435382  0.913222 -4.697208  75.600000          50.488280
26         text        W_up          9        0.00     -1.435382  0.913222 -4.697208  75.600000          50.488280

2024-06-16 05:57:30,049 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217
4        visual        W_up         19        0.15     -1.408512  0.903748 -4.624519  76.099997          51.811328
5        visual        W_up         18        0.10     -1.408648  0.905461 -4.628218  76.200000          51.507030
6        visual        W_up         17        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
7        visual        W_up         16        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
8        visual        W_up         15        0.05     -1.410563  0.904274 -4.629674  76.000000          51.428906
9        visual        W_up         14        0.10     -1.416562  0.900849 -4.634820  75.899997          51.252342
10       visual        W_up         13        0.20     -1.416798  0.903797 -4.641190  76.199996          51.159764
11       visual        W_up         12        0.00     -1.416798  0.903797 -4.641190  76.199996          51.159764
12       visual        W_up         11        0.15     -1.418277  0.903203 -4.642959  76.399996          51.062889
13       visual        W_up         10        0.00     -1.418277  0.903203 -4.642959  76.399996          51.062889
14       visual        W_up          9        0.10     -1.418311  0.903165 -4.642952  75.299997          51.119529
15       visual        W_up          8        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
16       visual        W_up          7        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
17       visual        W_up          6        0.05     -1.419138  0.901809 -4.641894  75.900000          51.133202
18       visual        W_up          5        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
19       visual        W_up          4        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
20       visual        W_up          3        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
21       visual        W_up          2        0.15     -1.420932  0.900220 -4.642305  75.799996          51.133983
22       visual        W_up          1        0.00     -1.420932  0.900220 -4.642305  75.799996          51.133983
23       visual        W_up          0        0.40     -1.421037  0.900018 -4.642108  75.899996          51.129686
24         text        W_up         11        0.35     -1.435382  0.913222 -4.697208  75.600000          50.488280
25         text        W_up         10        0.00     -1.435382  0.913222 -4.697208  75.600000          50.488280
26         text        W_up          9        0.00     -1.435382  0.913222 -4.697208  75.600000          50.488280
27         text        W_up          8        0.00     -1.435382  0.913222 -4.697208  75.600000          50.488280

2024-06-16 05:59:41,376 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217
4        visual        W_up         19        0.15     -1.408512  0.903748 -4.624519  76.099997          51.811328
5        visual        W_up         18        0.10     -1.408648  0.905461 -4.628218  76.200000          51.507030
6        visual        W_up         17        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
7        visual        W_up         16        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
8        visual        W_up         15        0.05     -1.410563  0.904274 -4.629674  76.000000          51.428906
9        visual        W_up         14        0.10     -1.416562  0.900849 -4.634820  75.899997          51.252342
10       visual        W_up         13        0.20     -1.416798  0.903797 -4.641190  76.199996          51.159764
11       visual        W_up         12        0.00     -1.416798  0.903797 -4.641190  76.199996          51.159764
12       visual        W_up         11        0.15     -1.418277  0.903203 -4.642959  76.399996          51.062889
13       visual        W_up         10        0.00     -1.418277  0.903203 -4.642959  76.399996          51.062889
14       visual        W_up          9        0.10     -1.418311  0.903165 -4.642952  75.299997          51.119529
15       visual        W_up          8        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
16       visual        W_up          7        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
17       visual        W_up          6        0.05     -1.419138  0.901809 -4.641894  75.900000          51.133202
18       visual        W_up          5        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
19       visual        W_up          4        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
20       visual        W_up          3        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
21       visual        W_up          2        0.15     -1.420932  0.900220 -4.642305  75.799996          51.133983
22       visual        W_up          1        0.00     -1.420932  0.900220 -4.642305  75.799996          51.133983
23       visual        W_up          0        0.40     -1.421037  0.900018 -4.642108  75.899996          51.129686
24         text        W_up         11        0.35     -1.435382  0.913222 -4.697208  75.600000          50.488280
25         text        W_up         10        0.00     -1.435382  0.913222 -4.697208  75.600000          50.488280
26         text        W_up          9        0.00     -1.435382  0.913222 -4.697208  75.600000          50.488280
27         text        W_up          8        0.00     -1.435382  0.913222 -4.697208  75.600000          50.488280
28         text        W_up          7        0.10     -1.445793  0.921184 -4.733954  75.299997          50.226562

2024-06-16 06:01:52,865 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217
4        visual        W_up         19        0.15     -1.408512  0.903748 -4.624519  76.099997          51.811328
5        visual        W_up         18        0.10     -1.408648  0.905461 -4.628218  76.200000          51.507030
6        visual        W_up         17        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
7        visual        W_up         16        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
8        visual        W_up         15        0.05     -1.410563  0.904274 -4.629674  76.000000          51.428906
9        visual        W_up         14        0.10     -1.416562  0.900849 -4.634820  75.899997          51.252342
10       visual        W_up         13        0.20     -1.416798  0.903797 -4.641190  76.199996          51.159764
11       visual        W_up         12        0.00     -1.416798  0.903797 -4.641190  76.199996          51.159764
12       visual        W_up         11        0.15     -1.418277  0.903203 -4.642959  76.399996          51.062889
13       visual        W_up         10        0.00     -1.418277  0.903203 -4.642959  76.399996          51.062889
14       visual        W_up          9        0.10     -1.418311  0.903165 -4.642952  75.299997          51.119529
15       visual        W_up          8        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
16       visual        W_up          7        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
17       visual        W_up          6        0.05     -1.419138  0.901809 -4.641894  75.900000          51.133202
18       visual        W_up          5        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
19       visual        W_up          4        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
20       visual        W_up          3        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
21       visual        W_up          2        0.15     -1.420932  0.900220 -4.642305  75.799996          51.133983
22       visual        W_up          1        0.00     -1.420932  0.900220 -4.642305  75.799996          51.133983
23       visual        W_up          0        0.40     -1.421037  0.900018 -4.642108  75.899996          51.129686
24         text        W_up         11        0.35     -1.435382  0.913222 -4.697208  75.600000          50.488280
25         text        W_up         10        0.00     -1.435382  0.913222 -4.697208  75.600000          50.488280
26         text        W_up          9        0.00     -1.435382  0.913222 -4.697208  75.600000          50.488280
27         text        W_up          8        0.00     -1.435382  0.913222 -4.697208  75.600000          50.488280
28         text        W_up          7        0.10     -1.445793  0.921184 -4.733954  75.299997          50.226562
29         text        W_up          6        0.05     -1.454266  0.919032 -4.746597  74.899997          50.124609

2024-06-16 06:04:04,356 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217
4        visual        W_up         19        0.15     -1.408512  0.903748 -4.624519  76.099997          51.811328
5        visual        W_up         18        0.10     -1.408648  0.905461 -4.628218  76.200000          51.507030
6        visual        W_up         17        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
7        visual        W_up         16        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
8        visual        W_up         15        0.05     -1.410563  0.904274 -4.629674  76.000000          51.428906
9        visual        W_up         14        0.10     -1.416562  0.900849 -4.634820  75.899997          51.252342
10       visual        W_up         13        0.20     -1.416798  0.903797 -4.641190  76.199996          51.159764
11       visual        W_up         12        0.00     -1.416798  0.903797 -4.641190  76.199996          51.159764
12       visual        W_up         11        0.15     -1.418277  0.903203 -4.642959  76.399996          51.062889
13       visual        W_up         10        0.00     -1.418277  0.903203 -4.642959  76.399996          51.062889
14       visual        W_up          9        0.10     -1.418311  0.903165 -4.642952  75.299997          51.119529
15       visual        W_up          8        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
16       visual        W_up          7        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
17       visual        W_up          6        0.05     -1.419138  0.901809 -4.641894  75.900000          51.133202
18       visual        W_up          5        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
19       visual        W_up          4        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
20       visual        W_up          3        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
21       visual        W_up          2        0.15     -1.420932  0.900220 -4.642305  75.799996          51.133983
22       visual        W_up          1        0.00     -1.420932  0.900220 -4.642305  75.799996          51.133983
23       visual        W_up          0        0.40     -1.421037  0.900018 -4.642108  75.899996          51.129686
24         text        W_up         11        0.35     -1.435382  0.913222 -4.697208  75.600000          50.488280
25         text        W_up         10        0.00     -1.435382  0.913222 -4.697208  75.600000          50.488280
26         text        W_up          9        0.00     -1.435382  0.913222 -4.697208  75.600000          50.488280
27         text        W_up          8        0.00     -1.435382  0.913222 -4.697208  75.600000          50.488280
28         text        W_up          7        0.10     -1.445793  0.921184 -4.733954  75.299997          50.226562
29         text        W_up          6        0.05     -1.454266  0.919032 -4.746597  74.899997          50.124609
30         text        W_up          5        0.35     -1.474863  0.919513 -4.788752  75.400000          50.036326

2024-06-16 06:06:16,697 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217
4        visual        W_up         19        0.15     -1.408512  0.903748 -4.624519  76.099997          51.811328
5        visual        W_up         18        0.10     -1.408648  0.905461 -4.628218  76.200000          51.507030
6        visual        W_up         17        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
7        visual        W_up         16        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
8        visual        W_up         15        0.05     -1.410563  0.904274 -4.629674  76.000000          51.428906
9        visual        W_up         14        0.10     -1.416562  0.900849 -4.634820  75.899997          51.252342
10       visual        W_up         13        0.20     -1.416798  0.903797 -4.641190  76.199996          51.159764
11       visual        W_up         12        0.00     -1.416798  0.903797 -4.641190  76.199996          51.159764
12       visual        W_up         11        0.15     -1.418277  0.903203 -4.642959  76.399996          51.062889
13       visual        W_up         10        0.00     -1.418277  0.903203 -4.642959  76.399996          51.062889
14       visual        W_up          9        0.10     -1.418311  0.903165 -4.642952  75.299997          51.119529
15       visual        W_up          8        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
16       visual        W_up          7        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
17       visual        W_up          6        0.05     -1.419138  0.901809 -4.641894  75.900000          51.133202
18       visual        W_up          5        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
19       visual        W_up          4        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
20       visual        W_up          3        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
21       visual        W_up          2        0.15     -1.420932  0.900220 -4.642305  75.799996          51.133983
22       visual        W_up          1        0.00     -1.420932  0.900220 -4.642305  75.799996          51.133983
23       visual        W_up          0        0.40     -1.421037  0.900018 -4.642108  75.899996          51.129686
24         text        W_up         11        0.35     -1.435382  0.913222 -4.697208  75.600000          50.488280
25         text        W_up         10        0.00     -1.435382  0.913222 -4.697208  75.600000          50.488280
26         text        W_up          9        0.00     -1.435382  0.913222 -4.697208  75.600000          50.488280
27         text        W_up          8        0.00     -1.435382  0.913222 -4.697208  75.600000          50.488280
28         text        W_up          7        0.10     -1.445793  0.921184 -4.733954  75.299997          50.226562
29         text        W_up          6        0.05     -1.454266  0.919032 -4.746597  74.899997          50.124609
30         text        W_up          5        0.35     -1.474863  0.919513 -4.788752  75.400000          50.036326
31         text        W_up          4        0.00     -1.474863  0.919513 -4.788752  75.400000          50.036326

2024-06-16 06:08:28,886 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217
4        visual        W_up         19        0.15     -1.408512  0.903748 -4.624519  76.099997          51.811328
5        visual        W_up         18        0.10     -1.408648  0.905461 -4.628218  76.200000          51.507030
6        visual        W_up         17        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
7        visual        W_up         16        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
8        visual        W_up         15        0.05     -1.410563  0.904274 -4.629674  76.000000          51.428906
9        visual        W_up         14        0.10     -1.416562  0.900849 -4.634820  75.899997          51.252342
10       visual        W_up         13        0.20     -1.416798  0.903797 -4.641190  76.199996          51.159764
11       visual        W_up         12        0.00     -1.416798  0.903797 -4.641190  76.199996          51.159764
12       visual        W_up         11        0.15     -1.418277  0.903203 -4.642959  76.399996          51.062889
13       visual        W_up         10        0.00     -1.418277  0.903203 -4.642959  76.399996          51.062889
14       visual        W_up          9        0.10     -1.418311  0.903165 -4.642952  75.299997          51.119529
15       visual        W_up          8        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
16       visual        W_up          7        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
17       visual        W_up          6        0.05     -1.419138  0.901809 -4.641894  75.900000          51.133202
18       visual        W_up          5        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
19       visual        W_up          4        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
20       visual        W_up          3        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
21       visual        W_up          2        0.15     -1.420932  0.900220 -4.642305  75.799996          51.133983
22       visual        W_up          1        0.00     -1.420932  0.900220 -4.642305  75.799996          51.133983
23       visual        W_up          0        0.40     -1.421037  0.900018 -4.642108  75.899996          51.129686
24         text        W_up         11        0.35     -1.435382  0.913222 -4.697208  75.600000          50.488280
25         text        W_up         10        0.00     -1.435382  0.913222 -4.697208  75.600000          50.488280
26         text        W_up          9        0.00     -1.435382  0.913222 -4.697208  75.600000          50.488280
27         text        W_up          8        0.00     -1.435382  0.913222 -4.697208  75.600000          50.488280
28         text        W_up          7        0.10     -1.445793  0.921184 -4.733954  75.299997          50.226562
29         text        W_up          6        0.05     -1.454266  0.919032 -4.746597  74.899997          50.124609
30         text        W_up          5        0.35     -1.474863  0.919513 -4.788752  75.400000          50.036326
31         text        W_up          4        0.00     -1.474863  0.919513 -4.788752  75.400000          50.036326
32         text        W_up          3        0.20     -1.479677  0.913045 -4.785445  75.700000          50.049608

2024-06-16 06:10:41,603 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217
4        visual        W_up         19        0.15     -1.408512  0.903748 -4.624519  76.099997          51.811328
5        visual        W_up         18        0.10     -1.408648  0.905461 -4.628218  76.200000          51.507030
6        visual        W_up         17        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
7        visual        W_up         16        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
8        visual        W_up         15        0.05     -1.410563  0.904274 -4.629674  76.000000          51.428906
9        visual        W_up         14        0.10     -1.416562  0.900849 -4.634820  75.899997          51.252342
10       visual        W_up         13        0.20     -1.416798  0.903797 -4.641190  76.199996          51.159764
11       visual        W_up         12        0.00     -1.416798  0.903797 -4.641190  76.199996          51.159764
12       visual        W_up         11        0.15     -1.418277  0.903203 -4.642959  76.399996          51.062889
13       visual        W_up         10        0.00     -1.418277  0.903203 -4.642959  76.399996          51.062889
14       visual        W_up          9        0.10     -1.418311  0.903165 -4.642952  75.299997          51.119529
15       visual        W_up          8        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
16       visual        W_up          7        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
17       visual        W_up          6        0.05     -1.419138  0.901809 -4.641894  75.900000          51.133202
18       visual        W_up          5        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
19       visual        W_up          4        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
20       visual        W_up          3        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
21       visual        W_up          2        0.15     -1.420932  0.900220 -4.642305  75.799996          51.133983
22       visual        W_up          1        0.00     -1.420932  0.900220 -4.642305  75.799996          51.133983
23       visual        W_up          0        0.40     -1.421037  0.900018 -4.642108  75.899996          51.129686
24         text        W_up         11        0.35     -1.435382  0.913222 -4.697208  75.600000          50.488280
25         text        W_up         10        0.00     -1.435382  0.913222 -4.697208  75.600000          50.488280
26         text        W_up          9        0.00     -1.435382  0.913222 -4.697208  75.600000          50.488280
27         text        W_up          8        0.00     -1.435382  0.913222 -4.697208  75.600000          50.488280
28         text        W_up          7        0.10     -1.445793  0.921184 -4.733954  75.299997          50.226562
29         text        W_up          6        0.05     -1.454266  0.919032 -4.746597  74.899997          50.124609
30         text        W_up          5        0.35     -1.474863  0.919513 -4.788752  75.400000          50.036326
31         text        W_up          4        0.00     -1.474863  0.919513 -4.788752  75.400000          50.036326
32         text        W_up          3        0.20     -1.479677  0.913045 -4.785445  75.700000          50.049608
33         text        W_up          2        0.00     -1.479677  0.913045 -4.785445  75.700000          50.049608

2024-06-16 06:12:54,055 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217
4        visual        W_up         19        0.15     -1.408512  0.903748 -4.624519  76.099997          51.811328
5        visual        W_up         18        0.10     -1.408648  0.905461 -4.628218  76.200000          51.507030
6        visual        W_up         17        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
7        visual        W_up         16        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
8        visual        W_up         15        0.05     -1.410563  0.904274 -4.629674  76.000000          51.428906
9        visual        W_up         14        0.10     -1.416562  0.900849 -4.634820  75.899997          51.252342
10       visual        W_up         13        0.20     -1.416798  0.903797 -4.641190  76.199996          51.159764
11       visual        W_up         12        0.00     -1.416798  0.903797 -4.641190  76.199996          51.159764
12       visual        W_up         11        0.15     -1.418277  0.903203 -4.642959  76.399996          51.062889
13       visual        W_up         10        0.00     -1.418277  0.903203 -4.642959  76.399996          51.062889
14       visual        W_up          9        0.10     -1.418311  0.903165 -4.642952  75.299997          51.119529
15       visual        W_up          8        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
16       visual        W_up          7        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
17       visual        W_up          6        0.05     -1.419138  0.901809 -4.641894  75.900000          51.133202
18       visual        W_up          5        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
19       visual        W_up          4        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
20       visual        W_up          3        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
21       visual        W_up          2        0.15     -1.420932  0.900220 -4.642305  75.799996          51.133983
22       visual        W_up          1        0.00     -1.420932  0.900220 -4.642305  75.799996          51.133983
23       visual        W_up          0        0.40     -1.421037  0.900018 -4.642108  75.899996          51.129686
24         text        W_up         11        0.35     -1.435382  0.913222 -4.697208  75.600000          50.488280
25         text        W_up         10        0.00     -1.435382  0.913222 -4.697208  75.600000          50.488280
26         text        W_up          9        0.00     -1.435382  0.913222 -4.697208  75.600000          50.488280
27         text        W_up          8        0.00     -1.435382  0.913222 -4.697208  75.600000          50.488280
28         text        W_up          7        0.10     -1.445793  0.921184 -4.733954  75.299997          50.226562
29         text        W_up          6        0.05     -1.454266  0.919032 -4.746597  74.899997          50.124609
30         text        W_up          5        0.35     -1.474863  0.919513 -4.788752  75.400000          50.036326
31         text        W_up          4        0.00     -1.474863  0.919513 -4.788752  75.400000          50.036326
32         text        W_up          3        0.20     -1.479677  0.913045 -4.785445  75.700000          50.049608
33         text        W_up          2        0.00     -1.479677  0.913045 -4.785445  75.700000          50.049608
34         text        W_up          1        0.05     -1.485701  0.897701 -4.766804  76.100000          50.029686

2024-06-16 06:15:07,037 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
1        visual        W_up         22        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
2        visual        W_up         21        0.00     -1.404933  0.906337 -4.622540  75.500000          52.552733
3        visual        W_up         20        0.05     -1.407539  0.903296 -4.621671  75.999997          52.449217
4        visual        W_up         19        0.15     -1.408512  0.903748 -4.624519  76.099997          51.811328
5        visual        W_up         18        0.10     -1.408648  0.905461 -4.628218  76.200000          51.507030
6        visual        W_up         17        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
7        visual        W_up         16        0.00     -1.408648  0.905461 -4.628218  76.200000          51.507030
8        visual        W_up         15        0.05     -1.410563  0.904274 -4.629674  76.000000          51.428906
9        visual        W_up         14        0.10     -1.416562  0.900849 -4.634820  75.899997          51.252342
10       visual        W_up         13        0.20     -1.416798  0.903797 -4.641190  76.199996          51.159764
11       visual        W_up         12        0.00     -1.416798  0.903797 -4.641190  76.199996          51.159764
12       visual        W_up         11        0.15     -1.418277  0.903203 -4.642959  76.399996          51.062889
13       visual        W_up         10        0.00     -1.418277  0.903203 -4.642959  76.399996          51.062889
14       visual        W_up          9        0.10     -1.418311  0.903165 -4.642952  75.299997          51.119529
15       visual        W_up          8        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
16       visual        W_up          7        0.00     -1.418311  0.903165 -4.642952  75.299997          51.119529
17       visual        W_up          6        0.05     -1.419138  0.901809 -4.641894  75.900000          51.133202
18       visual        W_up          5        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
19       visual        W_up          4        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
20       visual        W_up          3        0.00     -1.419138  0.901809 -4.641894  75.900000          51.133202
21       visual        W_up          2        0.15     -1.420932  0.900220 -4.642305  75.799996          51.133983
22       visual        W_up          1        0.00     -1.420932  0.900220 -4.642305  75.799996          51.133983
23       visual        W_up          0        0.40     -1.421037  0.900018 -4.642108  75.899996          51.129686
24         text        W_up         11        0.35     -1.435382  0.913222 -4.697208  75.600000          50.488280
25         text        W_up         10        0.00     -1.435382  0.913222 -4.697208  75.600000          50.488280
26         text        W_up          9        0.00     -1.435382  0.913222 -4.697208  75.600000          50.488280
27         text        W_up          8        0.00     -1.435382  0.913222 -4.697208  75.600000          50.488280
28         text        W_up          7        0.10     -1.445793  0.921184 -4.733954  75.299997          50.226562
29         text        W_up          6        0.05     -1.454266  0.919032 -4.746597  74.899997          50.124609
30         text        W_up          5        0.35     -1.474863  0.919513 -4.788752  75.400000          50.036326
31         text        W_up          4        0.00     -1.474863  0.919513 -4.788752  75.400000          50.036326
32         text        W_up          3        0.20     -1.479677  0.913045 -4.785445  75.700000          50.049608
33         text        W_up          2        0.00     -1.479677  0.913045 -4.785445  75.700000          50.049608
34         text        W_up          1        0.05     -1.485701  0.897701 -4.766804  76.100000          50.029686
35         text        W_up          0        0.20     -1.495205  0.891132 -4.772675  76.900000          49.992187

2024-06-16 06:15:07,047 | INFO | searchers.py:208 | run | Best low rank configs: 
[['visual', 'W_up', 23, 0], ['visual', 'W_up', 22, 0], ['visual', 'W_up', 21, 0], ['visual', 'W_up', 20, 0.05], ['visual', 'W_up', 19, 0.15], ['visual', 'W_up', 18, 0.1], ['visual', 'W_up', 17, 0], ['visual', 'W_up', 16, 0], ['visual', 'W_up', 15, 0.05], ['visual', 'W_up', 14, 0.1], ['visual', 'W_up', 13, 0.2], ['visual', 'W_up', 12, 0], ['visual', 'W_up', 11, 0.15], ['visual', 'W_up', 10, 0], ['visual', 'W_up', 9, 0.1], ['visual', 'W_up', 8, 0], ['visual', 'W_up', 7, 0], ['visual', 'W_up', 6, 0.05], ['visual', 'W_up', 5, 0], ['visual', 'W_up', 4, 0], ['visual', 'W_up', 3, 0], ['visual', 'W_up', 2, 0.15], ['visual', 'W_up', 1, 0], ['visual', 'W_up', 0, 0.4], ['text', 'W_up', 11, 0.35], ['text', 'W_up', 10, 0], ['text', 'W_up', 9, 0], ['text', 'W_up', 8, 0], ['text', 'W_up', 7, 0.1], ['text', 'W_up', 6, 0.05], ['text', 'W_up', 5, 0.35], ['text', 'W_up', 4, 0], ['text', 'W_up', 3, 0.2], ['text', 'W_up', 2, 0], ['text', 'W_up', 1, 0.05], ['text', 'W_up', 0, 0.2]]
2024-06-16 06:15:07,047 | INFO | searchers.py:211 | run | ############ Done! Search time: 77m 43s ############
2024-06-16 06:15:07,048 | INFO | test_ood.py:29 | run_test_ood | ############ Test OOD Detection ############
2024-06-16 06:15:07,048 | INFO | test_ood.py:30 | run_test_ood | Loading CLIP model: openai/clip-vit-large-patch14...
2024-06-16 06:15:07,525 | INFO | test_ood.py:39 | run_test_ood | Applying SVD prune to 'small' weights...
2024-06-16 06:15:07,528 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.23.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 06:15:07,528 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.22.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 06:15:07,528 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.21.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 06:15:07,528 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.20.mlp.fc1] [rank(51)=round(full_rank(1024)*rank_ratio(0.05))]
2024-06-16 06:15:07,528 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.19.mlp.fc1] [rank(154)=round(full_rank(1024)*rank_ratio(0.15))]
2024-06-16 06:15:07,528 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.18.mlp.fc1] [rank(102)=round(full_rank(1024)*rank_ratio(0.1))]
2024-06-16 06:15:07,528 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.17.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 06:15:07,528 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.16.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 06:15:07,528 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.15.mlp.fc1] [rank(51)=round(full_rank(1024)*rank_ratio(0.05))]
2024-06-16 06:15:07,528 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.14.mlp.fc1] [rank(102)=round(full_rank(1024)*rank_ratio(0.1))]
2024-06-16 06:15:07,528 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.13.mlp.fc1] [rank(205)=round(full_rank(1024)*rank_ratio(0.2))]
2024-06-16 06:15:07,528 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.12.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 06:15:07,528 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.11.mlp.fc1] [rank(154)=round(full_rank(1024)*rank_ratio(0.15))]
2024-06-16 06:15:07,528 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.10.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 06:15:07,528 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.9.mlp.fc1] [rank(102)=round(full_rank(1024)*rank_ratio(0.1))]
2024-06-16 06:15:07,528 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.8.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 06:15:07,528 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.7.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 06:15:07,528 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.6.mlp.fc1] [rank(51)=round(full_rank(1024)*rank_ratio(0.05))]
2024-06-16 06:15:07,528 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.5.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 06:15:07,529 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.4.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 06:15:07,529 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.3.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 06:15:07,529 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.2.mlp.fc1] [rank(154)=round(full_rank(1024)*rank_ratio(0.15))]
2024-06-16 06:15:07,529 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.1.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 06:15:07,529 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.0.mlp.fc1] [rank(410)=round(full_rank(1024)*rank_ratio(0.4))]
2024-06-16 06:15:07,529 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.11.mlp.fc1] [rank(269)=round(full_rank(768)*rank_ratio(0.35))]
2024-06-16 06:15:07,529 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.10.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 06:15:07,529 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.9.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 06:15:07,529 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.8.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 06:15:07,529 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.7.mlp.fc1] [rank(77)=round(full_rank(768)*rank_ratio(0.1))]
2024-06-16 06:15:07,529 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.6.mlp.fc1] [rank(38)=round(full_rank(768)*rank_ratio(0.05))]
2024-06-16 06:15:07,529 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.5.mlp.fc1] [rank(269)=round(full_rank(768)*rank_ratio(0.35))]
2024-06-16 06:15:07,529 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.4.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 06:15:07,529 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.3.mlp.fc1] [rank(154)=round(full_rank(768)*rank_ratio(0.2))]
2024-06-16 06:15:07,529 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.2.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 06:15:07,529 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.1.mlp.fc1] [rank(38)=round(full_rank(768)*rank_ratio(0.05))]
2024-06-16 06:15:07,529 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.0.mlp.fc1] [rank(154)=round(full_rank(768)*rank_ratio(0.2))]
2024-06-16 06:15:07,529 | INFO | model_hub.py:194 | to_target_modules | lora_settings -> target_modules: 
{
    "vision_model.encoder.layers.23.mlp.fc1": 0,
    "vision_model.encoder.layers.22.mlp.fc1": 0,
    "vision_model.encoder.layers.21.mlp.fc1": 0,
    "vision_model.encoder.layers.20.mlp.fc1": 51,
    "vision_model.encoder.layers.19.mlp.fc1": 154,
    "vision_model.encoder.layers.18.mlp.fc1": 102,
    "vision_model.encoder.layers.17.mlp.fc1": 0,
    "vision_model.encoder.layers.16.mlp.fc1": 0,
    "vision_model.encoder.layers.15.mlp.fc1": 51,
    "vision_model.encoder.layers.14.mlp.fc1": 102,
    "vision_model.encoder.layers.13.mlp.fc1": 205,
    "vision_model.encoder.layers.12.mlp.fc1": 0,
    "vision_model.encoder.layers.11.mlp.fc1": 154,
    "vision_model.encoder.layers.10.mlp.fc1": 0,
    "vision_model.encoder.layers.9.mlp.fc1": 102,
    "vision_model.encoder.layers.8.mlp.fc1": 0,
    "vision_model.encoder.layers.7.mlp.fc1": 0,
    "vision_model.encoder.layers.6.mlp.fc1": 51,
    "vision_model.encoder.layers.5.mlp.fc1": 0,
    "vision_model.encoder.layers.4.mlp.fc1": 0,
    "vision_model.encoder.layers.3.mlp.fc1": 0,
    "vision_model.encoder.layers.2.mlp.fc1": 154,
    "vision_model.encoder.layers.1.mlp.fc1": 0,
    "vision_model.encoder.layers.0.mlp.fc1": 410,
    "text_model.encoder.layers.11.mlp.fc1": 269,
    "text_model.encoder.layers.10.mlp.fc1": 0,
    "text_model.encoder.layers.9.mlp.fc1": 0,
    "text_model.encoder.layers.8.mlp.fc1": 0,
    "text_model.encoder.layers.7.mlp.fc1": 77,
    "text_model.encoder.layers.6.mlp.fc1": 38,
    "text_model.encoder.layers.5.mlp.fc1": 269,
    "text_model.encoder.layers.4.mlp.fc1": 0,
    "text_model.encoder.layers.3.mlp.fc1": 154,
    "text_model.encoder.layers.2.mlp.fc1": 0,
    "text_model.encoder.layers.1.mlp.fc1": 38,
    "text_model.encoder.layers.0.mlp.fc1": 154
}
2024-06-16 06:15:07,531 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.23.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:15:07,531 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.22.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:15:07,531 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.21.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:15:07,534 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.20.mlp.fc1] [Rank: 51]
2024-06-16 06:15:07,541 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.19.mlp.fc1] [Rank: 154]
2024-06-16 06:15:07,545 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.18.mlp.fc1] [Rank: 102]
2024-06-16 06:15:07,545 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.17.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:15:07,545 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.16.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:15:07,548 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.15.mlp.fc1] [Rank: 51]
2024-06-16 06:15:07,552 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.14.mlp.fc1] [Rank: 102]
2024-06-16 06:15:07,561 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.13.mlp.fc1] [Rank: 205]
2024-06-16 06:15:07,561 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.12.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:15:07,568 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.11.mlp.fc1] [Rank: 154]
2024-06-16 06:15:07,568 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.10.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:15:07,572 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.9.mlp.fc1] [Rank: 102]
2024-06-16 06:15:07,572 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.8.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:15:07,572 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.7.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:15:07,575 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.6.mlp.fc1] [Rank: 51]
2024-06-16 06:15:07,575 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.5.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:15:07,575 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.4.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:15:07,575 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.3.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:15:07,582 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.2.mlp.fc1] [Rank: 154]
2024-06-16 06:15:07,582 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.1.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:15:07,599 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.0.mlp.fc1] [Rank: 410]
2024-06-16 06:15:07,608 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.11.mlp.fc1] [Rank: 269]
2024-06-16 06:15:07,608 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.10.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:15:07,608 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.9.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:15:07,608 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.8.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:15:07,611 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.7.mlp.fc1] [Rank: 77]
2024-06-16 06:15:07,613 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.6.mlp.fc1] [Rank: 38]
2024-06-16 06:15:07,621 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.5.mlp.fc1] [Rank: 269]
2024-06-16 06:15:07,622 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.4.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:15:07,627 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.3.mlp.fc1] [Rank: 154]
2024-06-16 06:15:07,627 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.2.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:15:07,628 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.1.mlp.fc1] [Rank: 38]
2024-06-16 06:15:07,634 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.0.mlp.fc1] [Rank: 154]
2024-06-16 06:15:08,447 | INFO | model.py:192 | svd_init | SVD initialized for adapter 'default'.
2024-06-16 06:15:08,614 | INFO | test_ood.py:63 | run_test_ood | ############ ID dataset: ID_ImageNet1K, test set: 50000 images ############
2024-06-16 06:15:08,614 | INFO | test_ood.py:65 | run_test_ood | Computing scores for ID_ImageNet1K...
2024-06-16 06:23:35,374 | INFO | model_hub.py:304 | compute_scores | Took 506.76 s to run.
2024-06-16 06:23:35,545 | INFO | test_ood.py:78 | run_test_ood | ############ OOD dataset: OOD_iNaturalist, test set: 10000 images ############
2024-06-16 06:23:35,545 | INFO | test_ood.py:80 | run_test_ood | Computing scores for OOD_iNaturalist...
2024-06-16 06:25:22,219 | INFO | model_hub.py:304 | compute_scores | Took 106.67 s to run.
2024-06-16 06:25:22,292 | INFO | metrics.py:55 | print_metrics | OOD_iNaturalist - mcm_score
2024-06-16 06:25:22,292 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 06:25:22,292 | INFO | metrics.py:57 | print_metrics | & 26.96 & 95.14 & 98.97
2024-06-16 06:25:23,082 | INFO | metrics.py:55 | print_metrics | OOD_iNaturalist - gl_mcm_score
2024-06-16 06:25:23,082 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 06:25:23,082 | INFO | metrics.py:57 | print_metrics | & 30.96 & 94.04 & 98.68
2024-06-16 06:25:23,827 | INFO | test_ood.py:78 | run_test_ood | ############ OOD dataset: OOD_Sun, test set: 10000 images ############
2024-06-16 06:25:23,828 | INFO | test_ood.py:80 | run_test_ood | Computing scores for OOD_Sun...
2024-06-16 06:27:11,187 | INFO | model_hub.py:304 | compute_scores | Took 107.36 s to run.
2024-06-16 06:27:11,257 | INFO | metrics.py:55 | print_metrics | OOD_Sun - mcm_score
2024-06-16 06:27:11,257 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 06:27:11,257 | INFO | metrics.py:57 | print_metrics | & 27.12 & 94.54 & 98.77
2024-06-16 06:27:11,954 | INFO | metrics.py:55 | print_metrics | OOD_Sun - gl_mcm_score
2024-06-16 06:27:11,954 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 06:27:11,954 | INFO | metrics.py:57 | print_metrics | & 28.72 & 94.08 & 98.60
2024-06-16 06:27:12,688 | INFO | test_ood.py:78 | run_test_ood | ############ OOD dataset: OOD_Places, test set: 10000 images ############
2024-06-16 06:27:12,688 | INFO | test_ood.py:80 | run_test_ood | Computing scores for OOD_Places...
2024-06-16 06:28:56,209 | INFO | model_hub.py:304 | compute_scores | Took 103.52 s to run.
2024-06-16 06:28:56,279 | INFO | metrics.py:55 | print_metrics | OOD_Places - mcm_score
2024-06-16 06:28:56,279 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 06:28:56,279 | INFO | metrics.py:57 | print_metrics | & 32.04 & 92.55 & 98.18
2024-06-16 06:28:56,966 | INFO | metrics.py:55 | print_metrics | OOD_Places - gl_mcm_score
2024-06-16 06:28:56,966 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 06:28:56,966 | INFO | metrics.py:57 | print_metrics | & 34.58 & 91.89 & 98.00
2024-06-16 06:28:57,634 | INFO | test_ood.py:78 | run_test_ood | ############ OOD dataset: OOD_Texture, test set: 5640 images ############
2024-06-16 06:28:57,634 | INFO | test_ood.py:80 | run_test_ood | Computing scores for OOD_Texture...
2024-06-16 06:29:57,076 | INFO | model_hub.py:304 | compute_scores | Took 59.44 s to run.
2024-06-16 06:29:57,138 | INFO | metrics.py:55 | print_metrics | OOD_Texture - mcm_score
2024-06-16 06:29:57,138 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 06:29:57,138 | INFO | metrics.py:57 | print_metrics | & 58.90 & 85.45 & 97.94
2024-06-16 06:29:58,015 | INFO | metrics.py:55 | print_metrics | OOD_Texture - gl_mcm_score
2024-06-16 06:29:58,016 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 06:29:58,016 | INFO | metrics.py:57 | print_metrics | & 63.90 & 80.89 & 97.04
2024-06-16 06:29:58,716 | INFO | test_ood.py:98 | run_test_ood | ############ Metrics for mcm_score ############
2024-06-16 06:29:58,719 | INFO | metrics.py:76 | save_metrics | ############ Mean metrics ############
2024-06-16 06:29:58,720 | INFO | metrics.py:77 | save_metrics | 
                 FPR95  AUROC  AUPR
OOD dataset                        
OOD_iNaturalist  26.96  95.14 98.97
OOD_Sun          27.12  94.54 98.77
OOD_Places       32.04  92.55 98.18
OOD_Texture      58.90  85.45 97.94
Avg              36.26  91.92 98.46
2024-06-16 06:29:58,720 | INFO | metrics.py:78 | save_metrics | Metrics saved to ./results/training-free/clip_large/ID_ImageNet1K/SeTAR/metrics_mcm_score_test.csv
2024-06-16 06:29:58,721 | INFO | metrics.py:87 | save_cutoffs | ############ Thresholds Cut-off ############
2024-06-16 06:29:58,722 | INFO | metrics.py:88 | save_cutoffs | 
    OOD dataset   Cutoff
OOD_iNaturalist 0.001103
        OOD_Sun 0.001103
     OOD_Places 0.001103
    OOD_Texture 0.001103
2024-06-16 06:29:58,722 | INFO | metrics.py:89 | save_cutoffs | Thresholds cutoff saved to ./results/training-free/clip_large/ID_ImageNet1K/SeTAR/cutoffs_mcm_score_test.csv
2024-06-16 06:29:58,722 | INFO | test_ood.py:98 | run_test_ood | ############ Metrics for gl_mcm_score ############
2024-06-16 06:29:58,724 | INFO | metrics.py:76 | save_metrics | ############ Mean metrics ############
2024-06-16 06:29:58,725 | INFO | metrics.py:77 | save_metrics | 
                 FPR95  AUROC  AUPR
OOD dataset                        
OOD_iNaturalist  30.96  94.04 98.68
OOD_Sun          28.72  94.08 98.60
OOD_Places       34.58  91.89 98.00
OOD_Texture      63.90  80.89 97.04
Avg              39.54  90.22 98.08
2024-06-16 06:29:58,725 | INFO | metrics.py:78 | save_metrics | Metrics saved to ./results/training-free/clip_large/ID_ImageNet1K/SeTAR/metrics_gl_mcm_score_test.csv
2024-06-16 06:29:58,726 | INFO | metrics.py:87 | save_cutoffs | ############ Thresholds Cut-off ############
2024-06-16 06:29:58,726 | INFO | metrics.py:88 | save_cutoffs | 
    OOD dataset   Cutoff
OOD_iNaturalist 0.002234
        OOD_Sun 0.002234
     OOD_Places 0.002234
    OOD_Texture 0.002234
2024-06-16 06:29:58,726 | INFO | metrics.py:89 | save_cutoffs | Thresholds cutoff saved to ./results/training-free/clip_large/ID_ImageNet1K/SeTAR/cutoffs_gl_mcm_score_test.csv
2024-06-16 06:29:58,726 | INFO | test_ood.py:107 | run_test_ood | ############ Done! Test time: 14m 52s ############
2024-06-16 06:29:58,727 | INFO | test_classify.py:121 | run_test_classify | ############ Test Classification ############
2024-06-16 06:29:58,727 | INFO | test_classify.py:122 | run_test_classify | Loading CLIP model: openai/clip-vit-large-patch14...
2024-06-16 06:29:59,208 | INFO | test_classify.py:131 | run_test_classify | Applying SVD prune to 'small' weights...
2024-06-16 06:29:59,211 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.23.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 06:29:59,211 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.22.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 06:29:59,212 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.21.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 06:29:59,212 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.20.mlp.fc1] [rank(51)=round(full_rank(1024)*rank_ratio(0.05))]
2024-06-16 06:29:59,212 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.19.mlp.fc1] [rank(154)=round(full_rank(1024)*rank_ratio(0.15))]
2024-06-16 06:29:59,212 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.18.mlp.fc1] [rank(102)=round(full_rank(1024)*rank_ratio(0.1))]
2024-06-16 06:29:59,212 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.17.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 06:29:59,212 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.16.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 06:29:59,212 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.15.mlp.fc1] [rank(51)=round(full_rank(1024)*rank_ratio(0.05))]
2024-06-16 06:29:59,212 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.14.mlp.fc1] [rank(102)=round(full_rank(1024)*rank_ratio(0.1))]
2024-06-16 06:29:59,212 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.13.mlp.fc1] [rank(205)=round(full_rank(1024)*rank_ratio(0.2))]
2024-06-16 06:29:59,212 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.12.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 06:29:59,212 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.11.mlp.fc1] [rank(154)=round(full_rank(1024)*rank_ratio(0.15))]
2024-06-16 06:29:59,212 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.10.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 06:29:59,212 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.9.mlp.fc1] [rank(102)=round(full_rank(1024)*rank_ratio(0.1))]
2024-06-16 06:29:59,212 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.8.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 06:29:59,212 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.7.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 06:29:59,212 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.6.mlp.fc1] [rank(51)=round(full_rank(1024)*rank_ratio(0.05))]
2024-06-16 06:29:59,212 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.5.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 06:29:59,212 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.4.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 06:29:59,212 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.3.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 06:29:59,212 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.2.mlp.fc1] [rank(154)=round(full_rank(1024)*rank_ratio(0.15))]
2024-06-16 06:29:59,212 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.1.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 06:29:59,213 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.0.mlp.fc1] [rank(410)=round(full_rank(1024)*rank_ratio(0.4))]
2024-06-16 06:29:59,213 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.11.mlp.fc1] [rank(269)=round(full_rank(768)*rank_ratio(0.35))]
2024-06-16 06:29:59,213 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.10.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 06:29:59,213 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.9.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 06:29:59,213 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.8.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 06:29:59,213 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.7.mlp.fc1] [rank(77)=round(full_rank(768)*rank_ratio(0.1))]
2024-06-16 06:29:59,213 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.6.mlp.fc1] [rank(38)=round(full_rank(768)*rank_ratio(0.05))]
2024-06-16 06:29:59,213 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.5.mlp.fc1] [rank(269)=round(full_rank(768)*rank_ratio(0.35))]
2024-06-16 06:29:59,213 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.4.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 06:29:59,213 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.3.mlp.fc1] [rank(154)=round(full_rank(768)*rank_ratio(0.2))]
2024-06-16 06:29:59,213 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.2.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 06:29:59,213 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.1.mlp.fc1] [rank(38)=round(full_rank(768)*rank_ratio(0.05))]
2024-06-16 06:29:59,213 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.0.mlp.fc1] [rank(154)=round(full_rank(768)*rank_ratio(0.2))]
2024-06-16 06:29:59,213 | INFO | model_hub.py:194 | to_target_modules | lora_settings -> target_modules: 
{
    "vision_model.encoder.layers.23.mlp.fc1": 0,
    "vision_model.encoder.layers.22.mlp.fc1": 0,
    "vision_model.encoder.layers.21.mlp.fc1": 0,
    "vision_model.encoder.layers.20.mlp.fc1": 51,
    "vision_model.encoder.layers.19.mlp.fc1": 154,
    "vision_model.encoder.layers.18.mlp.fc1": 102,
    "vision_model.encoder.layers.17.mlp.fc1": 0,
    "vision_model.encoder.layers.16.mlp.fc1": 0,
    "vision_model.encoder.layers.15.mlp.fc1": 51,
    "vision_model.encoder.layers.14.mlp.fc1": 102,
    "vision_model.encoder.layers.13.mlp.fc1": 205,
    "vision_model.encoder.layers.12.mlp.fc1": 0,
    "vision_model.encoder.layers.11.mlp.fc1": 154,
    "vision_model.encoder.layers.10.mlp.fc1": 0,
    "vision_model.encoder.layers.9.mlp.fc1": 102,
    "vision_model.encoder.layers.8.mlp.fc1": 0,
    "vision_model.encoder.layers.7.mlp.fc1": 0,
    "vision_model.encoder.layers.6.mlp.fc1": 51,
    "vision_model.encoder.layers.5.mlp.fc1": 0,
    "vision_model.encoder.layers.4.mlp.fc1": 0,
    "vision_model.encoder.layers.3.mlp.fc1": 0,
    "vision_model.encoder.layers.2.mlp.fc1": 154,
    "vision_model.encoder.layers.1.mlp.fc1": 0,
    "vision_model.encoder.layers.0.mlp.fc1": 410,
    "text_model.encoder.layers.11.mlp.fc1": 269,
    "text_model.encoder.layers.10.mlp.fc1": 0,
    "text_model.encoder.layers.9.mlp.fc1": 0,
    "text_model.encoder.layers.8.mlp.fc1": 0,
    "text_model.encoder.layers.7.mlp.fc1": 77,
    "text_model.encoder.layers.6.mlp.fc1": 38,
    "text_model.encoder.layers.5.mlp.fc1": 269,
    "text_model.encoder.layers.4.mlp.fc1": 0,
    "text_model.encoder.layers.3.mlp.fc1": 154,
    "text_model.encoder.layers.2.mlp.fc1": 0,
    "text_model.encoder.layers.1.mlp.fc1": 38,
    "text_model.encoder.layers.0.mlp.fc1": 154
}
2024-06-16 06:29:59,215 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.23.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:29:59,215 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.22.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:29:59,215 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.21.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:29:59,219 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.20.mlp.fc1] [Rank: 51]
2024-06-16 06:29:59,225 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.19.mlp.fc1] [Rank: 154]
2024-06-16 06:29:59,230 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.18.mlp.fc1] [Rank: 102]
2024-06-16 06:29:59,230 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.17.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:29:59,230 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.16.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:29:59,233 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.15.mlp.fc1] [Rank: 51]
2024-06-16 06:29:59,238 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.14.mlp.fc1] [Rank: 102]
2024-06-16 06:29:59,246 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.13.mlp.fc1] [Rank: 205]
2024-06-16 06:29:59,246 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.12.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:29:59,253 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.11.mlp.fc1] [Rank: 154]
2024-06-16 06:29:59,253 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.10.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:29:59,257 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.9.mlp.fc1] [Rank: 102]
2024-06-16 06:29:59,258 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.8.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:29:59,258 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.7.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:29:59,260 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.6.mlp.fc1] [Rank: 51]
2024-06-16 06:29:59,260 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.5.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:29:59,260 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.4.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:29:59,260 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.3.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:29:59,267 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.2.mlp.fc1] [Rank: 154]
2024-06-16 06:29:59,267 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.1.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:29:59,285 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.0.mlp.fc1] [Rank: 410]
2024-06-16 06:29:59,293 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.11.mlp.fc1] [Rank: 269]
2024-06-16 06:29:59,293 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.10.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:29:59,293 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.9.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:29:59,293 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.8.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:29:59,296 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.7.mlp.fc1] [Rank: 77]
2024-06-16 06:29:59,298 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.6.mlp.fc1] [Rank: 38]
2024-06-16 06:29:59,306 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.5.mlp.fc1] [Rank: 269]
2024-06-16 06:29:59,306 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.4.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:29:59,312 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.3.mlp.fc1] [Rank: 154]
2024-06-16 06:29:59,312 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.2.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 06:29:59,313 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.1.mlp.fc1] [Rank: 38]
2024-06-16 06:29:59,318 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.0.mlp.fc1] [Rank: 154]
2024-06-16 06:30:00,158 | INFO | model.py:192 | svd_init | SVD initialized for adapter 'default'.
2024-06-16 06:30:00,191 | INFO | test_classify.py:151 | run_test_classify | ############ ID_ImageNet1K ############
2024-06-16 06:38:17,614 | INFO | test_classify.py:161 | run_test_classify | Accuracy on ID_ImageNet1K: 70.10
2024-06-16 06:38:17,615 | INFO | test_classify.py:151 | run_test_classify | ############ OOD_Sun ############
2024-06-16 06:40:00,262 | INFO | test_classify.py:161 | run_test_classify | Accuracy on OOD_Sun: 75.17
2024-06-16 06:40:00,262 | INFO | test_classify.py:151 | run_test_classify | ############ OOD_Places ############
2024-06-16 06:41:39,371 | INFO | test_classify.py:161 | run_test_classify | Accuracy on OOD_Places: 46.49
2024-06-16 06:41:39,371 | INFO | test_classify.py:151 | run_test_classify | ############ OOD_Texture ############
2024-06-16 06:42:36,729 | INFO | test_classify.py:161 | run_test_classify | Accuracy on OOD_Texture: 51.03
2024-06-16 06:42:36,729 | INFO | test_classify.py:164 | run_test_classify | ############ Summary ############
2024-06-16 06:42:36,729 | INFO | test_classify.py:166 | run_test_classify | Accuracy on ID_ImageNet1K: 70.10
2024-06-16 06:42:36,729 | INFO | test_classify.py:166 | run_test_classify | Accuracy on OOD_Sun: 75.17
2024-06-16 06:42:36,729 | INFO | test_classify.py:166 | run_test_classify | Accuracy on OOD_Places: 46.49
2024-06-16 06:42:36,730 | INFO | test_classify.py:166 | run_test_classify | Accuracy on OOD_Texture: 51.03
