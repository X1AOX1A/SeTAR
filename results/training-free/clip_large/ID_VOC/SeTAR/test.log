2024-06-16 05:14:36,937 | INFO | test_ood.py:29 | run_test_ood | ############ Test OOD Detection ############
2024-06-16 05:14:36,937 | INFO | test_ood.py:30 | run_test_ood | Loading CLIP model: openai/clip-vit-large-patch14...
2024-06-16 05:14:37,484 | INFO | test_ood.py:39 | run_test_ood | Applying SVD prune to 'small' weights...
2024-06-16 05:14:37,486 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.23.mlp.fc1] [rank(410)=round(full_rank(1024)*rank_ratio(0.4))]
2024-06-16 05:14:37,486 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.22.mlp.fc1] [rank(358)=round(full_rank(1024)*rank_ratio(0.35))]
2024-06-16 05:14:37,486 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.21.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.20.mlp.fc1] [rank(205)=round(full_rank(1024)*rank_ratio(0.2))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.19.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.18.mlp.fc1] [rank(307)=round(full_rank(1024)*rank_ratio(0.3))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.17.mlp.fc1] [rank(256)=round(full_rank(1024)*rank_ratio(0.25))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.16.mlp.fc1] [rank(102)=round(full_rank(1024)*rank_ratio(0.1))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.15.mlp.fc1] [rank(51)=round(full_rank(1024)*rank_ratio(0.05))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.14.mlp.fc1] [rank(256)=round(full_rank(1024)*rank_ratio(0.25))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.13.mlp.fc1] [rank(51)=round(full_rank(1024)*rank_ratio(0.05))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.12.mlp.fc1] [rank(307)=round(full_rank(1024)*rank_ratio(0.3))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.11.mlp.fc1] [rank(51)=round(full_rank(1024)*rank_ratio(0.05))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.10.mlp.fc1] [rank(102)=round(full_rank(1024)*rank_ratio(0.1))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.9.mlp.fc1] [rank(154)=round(full_rank(1024)*rank_ratio(0.15))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.8.mlp.fc1] [rank(51)=round(full_rank(1024)*rank_ratio(0.05))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.7.mlp.fc1] [rank(205)=round(full_rank(1024)*rank_ratio(0.2))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.6.mlp.fc1] [rank(154)=round(full_rank(1024)*rank_ratio(0.15))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.5.mlp.fc1] [rank(307)=round(full_rank(1024)*rank_ratio(0.3))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.4.mlp.fc1] [rank(102)=round(full_rank(1024)*rank_ratio(0.1))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.3.mlp.fc1] [rank(102)=round(full_rank(1024)*rank_ratio(0.1))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.2.mlp.fc1] [rank(205)=round(full_rank(1024)*rank_ratio(0.2))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.1.mlp.fc1] [rank(102)=round(full_rank(1024)*rank_ratio(0.1))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.0.mlp.fc1] [rank(358)=round(full_rank(1024)*rank_ratio(0.35))]
2024-06-16 05:14:37,488 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.11.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 05:14:37,488 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.10.mlp.fc1] [rank(38)=round(full_rank(768)*rank_ratio(0.05))]
2024-06-16 05:14:37,488 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.9.mlp.fc1] [rank(38)=round(full_rank(768)*rank_ratio(0.05))]
2024-06-16 05:14:37,488 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.8.mlp.fc1] [rank(307)=round(full_rank(768)*rank_ratio(0.4))]
2024-06-16 05:14:37,488 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.7.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 05:14:37,488 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.6.mlp.fc1] [rank(115)=round(full_rank(768)*rank_ratio(0.15))]
2024-06-16 05:14:37,488 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.5.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 05:14:37,488 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.4.mlp.fc1] [rank(230)=round(full_rank(768)*rank_ratio(0.3))]
2024-06-16 05:14:37,488 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.3.mlp.fc1] [rank(307)=round(full_rank(768)*rank_ratio(0.4))]
2024-06-16 05:14:37,488 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.2.mlp.fc1] [rank(38)=round(full_rank(768)*rank_ratio(0.05))]
2024-06-16 05:14:37,488 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.1.mlp.fc1] [rank(38)=round(full_rank(768)*rank_ratio(0.05))]
2024-06-16 05:14:37,488 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.0.mlp.fc1] [rank(307)=round(full_rank(768)*rank_ratio(0.4))]
2024-06-16 05:14:37,488 | INFO | model_hub.py:194 | to_target_modules | lora_settings -> target_modules: 
{
    "vision_model.encoder.layers.23.mlp.fc1": 410,
    "vision_model.encoder.layers.22.mlp.fc1": 358,
    "vision_model.encoder.layers.21.mlp.fc1": 0,
    "vision_model.encoder.layers.20.mlp.fc1": 205,
    "vision_model.encoder.layers.19.mlp.fc1": 0,
    "vision_model.encoder.layers.18.mlp.fc1": 307,
    "vision_model.encoder.layers.17.mlp.fc1": 256,
    "vision_model.encoder.layers.16.mlp.fc1": 102,
    "vision_model.encoder.layers.15.mlp.fc1": 51,
    "vision_model.encoder.layers.14.mlp.fc1": 256,
    "vision_model.encoder.layers.13.mlp.fc1": 51,
    "vision_model.encoder.layers.12.mlp.fc1": 307,
    "vision_model.encoder.layers.11.mlp.fc1": 51,
    "vision_model.encoder.layers.10.mlp.fc1": 102,
    "vision_model.encoder.layers.9.mlp.fc1": 154,
    "vision_model.encoder.layers.8.mlp.fc1": 51,
    "vision_model.encoder.layers.7.mlp.fc1": 205,
    "vision_model.encoder.layers.6.mlp.fc1": 154,
    "vision_model.encoder.layers.5.mlp.fc1": 307,
    "vision_model.encoder.layers.4.mlp.fc1": 102,
    "vision_model.encoder.layers.3.mlp.fc1": 102,
    "vision_model.encoder.layers.2.mlp.fc1": 205,
    "vision_model.encoder.layers.1.mlp.fc1": 102,
    "vision_model.encoder.layers.0.mlp.fc1": 358,
    "text_model.encoder.layers.11.mlp.fc1": 0,
    "text_model.encoder.layers.10.mlp.fc1": 38,
    "text_model.encoder.layers.9.mlp.fc1": 38,
    "text_model.encoder.layers.8.mlp.fc1": 307,
    "text_model.encoder.layers.7.mlp.fc1": 0,
    "text_model.encoder.layers.6.mlp.fc1": 115,
    "text_model.encoder.layers.5.mlp.fc1": 0,
    "text_model.encoder.layers.4.mlp.fc1": 230,
    "text_model.encoder.layers.3.mlp.fc1": 307,
    "text_model.encoder.layers.2.mlp.fc1": 38,
    "text_model.encoder.layers.1.mlp.fc1": 38,
    "text_model.encoder.layers.0.mlp.fc1": 307
}
2024-06-16 05:14:37,506 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.23.mlp.fc1] [Rank: 410]
2024-06-16 05:14:37,521 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.22.mlp.fc1] [Rank: 358]
2024-06-16 05:14:37,521 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.21.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:14:37,530 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.20.mlp.fc1] [Rank: 205]
2024-06-16 05:14:37,530 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.19.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:14:37,543 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.18.mlp.fc1] [Rank: 307]
2024-06-16 05:14:37,554 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.17.mlp.fc1] [Rank: 256]
2024-06-16 05:14:37,558 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.16.mlp.fc1] [Rank: 102]
2024-06-16 05:14:37,561 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.15.mlp.fc1] [Rank: 51]
2024-06-16 05:14:37,572 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.14.mlp.fc1] [Rank: 256]
2024-06-16 05:14:37,575 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.13.mlp.fc1] [Rank: 51]
2024-06-16 05:14:37,587 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.12.mlp.fc1] [Rank: 307]
2024-06-16 05:14:37,590 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.11.mlp.fc1] [Rank: 51]
2024-06-16 05:14:37,594 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.10.mlp.fc1] [Rank: 102]
2024-06-16 05:14:37,601 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.9.mlp.fc1] [Rank: 154]
2024-06-16 05:14:37,603 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.8.mlp.fc1] [Rank: 51]
2024-06-16 05:14:37,612 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.7.mlp.fc1] [Rank: 205]
2024-06-16 05:14:37,619 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.6.mlp.fc1] [Rank: 154]
2024-06-16 05:14:37,632 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.5.mlp.fc1] [Rank: 307]
2024-06-16 05:14:37,638 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.4.mlp.fc1] [Rank: 102]
2024-06-16 05:14:37,643 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.3.mlp.fc1] [Rank: 102]
2024-06-16 05:14:37,652 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.2.mlp.fc1] [Rank: 205]
2024-06-16 05:14:37,656 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.1.mlp.fc1] [Rank: 102]
2024-06-16 05:14:37,671 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.0.mlp.fc1] [Rank: 358]
2024-06-16 05:14:37,671 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.11.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:14:37,673 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.10.mlp.fc1] [Rank: 38]
2024-06-16 05:14:37,674 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.9.mlp.fc1] [Rank: 38]
2024-06-16 05:14:37,684 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.8.mlp.fc1] [Rank: 307]
2024-06-16 05:14:37,684 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.7.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:14:37,688 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.6.mlp.fc1] [Rank: 115]
2024-06-16 05:14:37,688 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.5.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:14:37,695 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.4.mlp.fc1] [Rank: 230]
2024-06-16 05:14:37,705 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.3.mlp.fc1] [Rank: 307]
2024-06-16 05:14:37,706 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.2.mlp.fc1] [Rank: 38]
2024-06-16 05:14:37,708 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.1.mlp.fc1] [Rank: 38]
2024-06-16 05:14:37,718 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.0.mlp.fc1] [Rank: 307]
2024-06-16 05:14:39,199 | INFO | model.py:192 | svd_init | SVD initialized for adapter 'default'.
2024-06-16 05:14:39,243 | INFO | test_ood.py:63 | run_test_ood | ############ ID dataset: ID_VOC, test set: 906 images ############
2024-06-16 05:14:39,243 | INFO | test_ood.py:65 | run_test_ood | Computing scores for ID_VOC...
2024-06-16 05:14:50,737 | INFO | model_hub.py:304 | compute_scores | Took 11.49 s to run.
2024-06-16 05:14:50,773 | INFO | test_ood.py:78 | run_test_ood | ############ OOD dataset: OOD_iNaturalist, test set: 10000 images ############
2024-06-16 05:14:50,773 | INFO | test_ood.py:80 | run_test_ood | Computing scores for OOD_iNaturalist...
2024-06-16 05:16:36,066 | INFO | model_hub.py:304 | compute_scores | Took 105.29 s to run.
2024-06-16 05:16:36,124 | INFO | metrics.py:55 | print_metrics | OOD_iNaturalist - mcm_score
2024-06-16 05:16:36,124 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:16:36,124 | INFO | metrics.py:57 | print_metrics | & 26.05 & 96.23 & 86.48
2024-06-16 05:16:36,968 | INFO | metrics.py:55 | print_metrics | OOD_iNaturalist - gl_mcm_score
2024-06-16 05:16:36,969 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:16:36,969 | INFO | metrics.py:57 | print_metrics | & 9.62 & 97.51 & 90.61
2024-06-16 05:16:37,417 | INFO | test_ood.py:78 | run_test_ood | ############ OOD dataset: OOD_Sun, test set: 10000 images ############
2024-06-16 05:16:37,417 | INFO | test_ood.py:80 | run_test_ood | Computing scores for OOD_Sun...
2024-06-16 05:18:23,342 | INFO | model_hub.py:304 | compute_scores | Took 105.92 s to run.
2024-06-16 05:18:23,379 | INFO | metrics.py:55 | print_metrics | OOD_Sun - mcm_score
2024-06-16 05:18:23,379 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:18:23,379 | INFO | metrics.py:57 | print_metrics | & 35.97 & 94.20 & 74.51
2024-06-16 05:18:23,998 | INFO | metrics.py:55 | print_metrics | OOD_Sun - gl_mcm_score
2024-06-16 05:18:23,999 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:18:23,999 | INFO | metrics.py:57 | print_metrics | & 27.75 & 94.73 & 77.84
2024-06-16 05:18:24,450 | INFO | test_ood.py:78 | run_test_ood | ############ OOD dataset: OOD_Places, test set: 10000 images ############
2024-06-16 05:18:24,450 | INFO | test_ood.py:80 | run_test_ood | Computing scores for OOD_Places...
2024-06-16 05:20:07,022 | INFO | model_hub.py:304 | compute_scores | Took 102.57 s to run.
2024-06-16 05:20:07,064 | INFO | metrics.py:55 | print_metrics | OOD_Places - mcm_score
2024-06-16 05:20:07,064 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:20:07,064 | INFO | metrics.py:57 | print_metrics | & 33.10 & 92.45 & 58.29
2024-06-16 05:20:07,618 | INFO | metrics.py:55 | print_metrics | OOD_Places - gl_mcm_score
2024-06-16 05:20:07,618 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:20:07,618 | INFO | metrics.py:57 | print_metrics | & 28.85 & 92.99 & 62.44
2024-06-16 05:20:08,030 | INFO | test_ood.py:78 | run_test_ood | ############ OOD dataset: OOD_Texture, test set: 5640 images ############
2024-06-16 05:20:08,030 | INFO | test_ood.py:80 | run_test_ood | Computing scores for OOD_Texture...
2024-06-16 05:21:06,512 | INFO | model_hub.py:304 | compute_scores | Took 58.48 s to run.
2024-06-16 05:21:06,541 | INFO | metrics.py:55 | print_metrics | OOD_Texture - mcm_score
2024-06-16 05:21:06,541 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:21:06,541 | INFO | metrics.py:57 | print_metrics | & 50.32 & 91.91 & 76.74
2024-06-16 05:21:07,083 | INFO | metrics.py:55 | print_metrics | OOD_Texture - gl_mcm_score
2024-06-16 05:21:07,083 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:21:07,083 | INFO | metrics.py:57 | print_metrics | & 41.77 & 92.40 & 75.58
2024-06-16 05:21:07,509 | INFO | test_ood.py:78 | run_test_ood | ############ OOD dataset: OOD_ImageNet22K, test set: 18335 images ############
2024-06-16 05:21:07,509 | INFO | test_ood.py:80 | run_test_ood | Computing scores for OOD_ImageNet22K...
2024-06-16 05:24:10,268 | INFO | model_hub.py:304 | compute_scores | Took 182.76 s to run.
2024-06-16 05:24:10,336 | INFO | metrics.py:55 | print_metrics | OOD_ImageNet22K - mcm_score
2024-06-16 05:24:10,336 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:24:10,336 | INFO | metrics.py:57 | print_metrics | & 57.69 & 92.02 & 66.86
2024-06-16 05:24:10,887 | INFO | metrics.py:55 | print_metrics | OOD_ImageNet22K - gl_mcm_score
2024-06-16 05:24:10,888 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:24:10,888 | INFO | metrics.py:57 | print_metrics | & 39.42 & 93.98 & 72.30
2024-06-16 05:24:11,385 | INFO | test_ood.py:78 | run_test_ood | ############ OOD dataset: OOD_COCO, test set: 1000 images ############
2024-06-16 05:24:11,385 | INFO | test_ood.py:80 | run_test_ood | Computing scores for OOD_COCO...
2024-06-16 05:24:24,455 | INFO | model_hub.py:304 | compute_scores | Took 13.07 s to run.
2024-06-16 05:24:24,468 | INFO | metrics.py:55 | print_metrics | OOD_COCO - mcm_score
2024-06-16 05:24:24,468 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:24:24,469 | INFO | metrics.py:57 | print_metrics | & 52.30 & 90.67 & 90.73
2024-06-16 05:24:24,892 | INFO | metrics.py:55 | print_metrics | OOD_COCO - gl_mcm_score
2024-06-16 05:24:24,892 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:24:24,892 | INFO | metrics.py:57 | print_metrics | & 39.30 & 92.38 & 92.42
2024-06-16 05:24:25,275 | INFO | test_ood.py:98 | run_test_ood | ############ Metrics for mcm_score ############
2024-06-16 05:24:25,278 | INFO | metrics.py:76 | save_metrics | ############ Mean metrics ############
2024-06-16 05:24:25,279 | INFO | metrics.py:77 | save_metrics | 
                 FPR95  AUROC  AUPR
OOD dataset                        
OOD_iNaturalist  26.05  96.23 86.48
OOD_Sun          35.97  94.20 74.51
OOD_Places       33.10  92.45 58.29
OOD_Texture      50.32  91.91 76.74
OOD_ImageNet22K  57.69  92.02 66.86
OOD_COCO         52.30  90.67 90.73
Avg              42.57  92.91 75.60
2024-06-16 05:24:25,279 | INFO | metrics.py:78 | save_metrics | Metrics saved to ./results/training-free/clip_large/ID_VOC/SeTAR/metrics_mcm_score_test.csv
2024-06-16 05:24:25,280 | INFO | metrics.py:87 | save_cutoffs | ############ Thresholds Cut-off ############
2024-06-16 05:24:25,281 | INFO | metrics.py:88 | save_cutoffs | 
    OOD dataset   Cutoff
OOD_iNaturalist 0.073618
        OOD_Sun 0.073618
     OOD_Places 0.073619
    OOD_Texture 0.073619
OOD_ImageNet22K 0.073618
       OOD_COCO 0.073620
2024-06-16 05:24:25,281 | INFO | metrics.py:89 | save_cutoffs | Thresholds cutoff saved to ./results/training-free/clip_large/ID_VOC/SeTAR/cutoffs_mcm_score_test.csv
2024-06-16 05:24:25,281 | INFO | test_ood.py:98 | run_test_ood | ############ Metrics for gl_mcm_score ############
2024-06-16 05:24:25,283 | INFO | metrics.py:76 | save_metrics | ############ Mean metrics ############
2024-06-16 05:24:25,284 | INFO | metrics.py:77 | save_metrics | 
                 FPR95  AUROC  AUPR
OOD dataset                        
OOD_iNaturalist   9.62  97.51 90.61
OOD_Sun          27.75  94.73 77.84
OOD_Places       28.85  92.99 62.44
OOD_Texture      41.77  92.40 75.58
OOD_ImageNet22K  39.42  93.98 72.30
OOD_COCO         39.30  92.38 92.42
Avg              31.12  94.00 78.53
2024-06-16 05:24:25,284 | INFO | metrics.py:78 | save_metrics | Metrics saved to ./results/training-free/clip_large/ID_VOC/SeTAR/metrics_gl_mcm_score_test.csv
2024-06-16 05:24:25,284 | INFO | metrics.py:87 | save_cutoffs | ############ Thresholds Cut-off ############
2024-06-16 05:24:25,285 | INFO | metrics.py:88 | save_cutoffs | 
    OOD dataset   Cutoff
OOD_iNaturalist 0.149756
        OOD_Sun 0.149757
     OOD_Places 0.149757
    OOD_Texture 0.149757
OOD_ImageNet22K 0.149756
       OOD_COCO 0.149757
2024-06-16 05:24:25,285 | INFO | metrics.py:89 | save_cutoffs | Thresholds cutoff saved to ./results/training-free/clip_large/ID_VOC/SeTAR/cutoffs_gl_mcm_score_test.csv
2024-06-16 05:24:25,285 | INFO | test_ood.py:107 | run_test_ood | ############ Done! Test time: 9m 48s ############
2024-06-16 05:24:25,285 | INFO | test_classify.py:121 | run_test_classify | ############ Test Classification ############
2024-06-16 05:24:25,286 | INFO | test_classify.py:122 | run_test_classify | Loading CLIP model: openai/clip-vit-large-patch14...
2024-06-16 05:24:25,843 | INFO | test_classify.py:131 | run_test_classify | Applying SVD prune to 'small' weights...
2024-06-16 05:24:25,847 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.23.mlp.fc1] [rank(410)=round(full_rank(1024)*rank_ratio(0.4))]
2024-06-16 05:24:25,847 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.22.mlp.fc1] [rank(358)=round(full_rank(1024)*rank_ratio(0.35))]
2024-06-16 05:24:25,847 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.21.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 05:24:25,847 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.20.mlp.fc1] [rank(205)=round(full_rank(1024)*rank_ratio(0.2))]
2024-06-16 05:24:25,847 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.19.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 05:24:25,847 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.18.mlp.fc1] [rank(307)=round(full_rank(1024)*rank_ratio(0.3))]
2024-06-16 05:24:25,847 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.17.mlp.fc1] [rank(256)=round(full_rank(1024)*rank_ratio(0.25))]
2024-06-16 05:24:25,847 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.16.mlp.fc1] [rank(102)=round(full_rank(1024)*rank_ratio(0.1))]
2024-06-16 05:24:25,847 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.15.mlp.fc1] [rank(51)=round(full_rank(1024)*rank_ratio(0.05))]
2024-06-16 05:24:25,847 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.14.mlp.fc1] [rank(256)=round(full_rank(1024)*rank_ratio(0.25))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.13.mlp.fc1] [rank(51)=round(full_rank(1024)*rank_ratio(0.05))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.12.mlp.fc1] [rank(307)=round(full_rank(1024)*rank_ratio(0.3))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.11.mlp.fc1] [rank(51)=round(full_rank(1024)*rank_ratio(0.05))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.10.mlp.fc1] [rank(102)=round(full_rank(1024)*rank_ratio(0.1))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.9.mlp.fc1] [rank(154)=round(full_rank(1024)*rank_ratio(0.15))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.8.mlp.fc1] [rank(51)=round(full_rank(1024)*rank_ratio(0.05))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.7.mlp.fc1] [rank(205)=round(full_rank(1024)*rank_ratio(0.2))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.6.mlp.fc1] [rank(154)=round(full_rank(1024)*rank_ratio(0.15))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.5.mlp.fc1] [rank(307)=round(full_rank(1024)*rank_ratio(0.3))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.4.mlp.fc1] [rank(102)=round(full_rank(1024)*rank_ratio(0.1))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.3.mlp.fc1] [rank(102)=round(full_rank(1024)*rank_ratio(0.1))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.2.mlp.fc1] [rank(205)=round(full_rank(1024)*rank_ratio(0.2))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.1.mlp.fc1] [rank(102)=round(full_rank(1024)*rank_ratio(0.1))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.0.mlp.fc1] [rank(358)=round(full_rank(1024)*rank_ratio(0.35))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.11.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.10.mlp.fc1] [rank(38)=round(full_rank(768)*rank_ratio(0.05))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.9.mlp.fc1] [rank(38)=round(full_rank(768)*rank_ratio(0.05))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.8.mlp.fc1] [rank(307)=round(full_rank(768)*rank_ratio(0.4))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.7.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.6.mlp.fc1] [rank(115)=round(full_rank(768)*rank_ratio(0.15))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.5.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.4.mlp.fc1] [rank(230)=round(full_rank(768)*rank_ratio(0.3))]
2024-06-16 05:24:25,849 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.3.mlp.fc1] [rank(307)=round(full_rank(768)*rank_ratio(0.4))]
2024-06-16 05:24:25,849 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.2.mlp.fc1] [rank(38)=round(full_rank(768)*rank_ratio(0.05))]
2024-06-16 05:24:25,849 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.1.mlp.fc1] [rank(38)=round(full_rank(768)*rank_ratio(0.05))]
2024-06-16 05:24:25,849 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.0.mlp.fc1] [rank(307)=round(full_rank(768)*rank_ratio(0.4))]
2024-06-16 05:24:25,849 | INFO | model_hub.py:194 | to_target_modules | lora_settings -> target_modules: 
{
    "vision_model.encoder.layers.23.mlp.fc1": 410,
    "vision_model.encoder.layers.22.mlp.fc1": 358,
    "vision_model.encoder.layers.21.mlp.fc1": 0,
    "vision_model.encoder.layers.20.mlp.fc1": 205,
    "vision_model.encoder.layers.19.mlp.fc1": 0,
    "vision_model.encoder.layers.18.mlp.fc1": 307,
    "vision_model.encoder.layers.17.mlp.fc1": 256,
    "vision_model.encoder.layers.16.mlp.fc1": 102,
    "vision_model.encoder.layers.15.mlp.fc1": 51,
    "vision_model.encoder.layers.14.mlp.fc1": 256,
    "vision_model.encoder.layers.13.mlp.fc1": 51,
    "vision_model.encoder.layers.12.mlp.fc1": 307,
    "vision_model.encoder.layers.11.mlp.fc1": 51,
    "vision_model.encoder.layers.10.mlp.fc1": 102,
    "vision_model.encoder.layers.9.mlp.fc1": 154,
    "vision_model.encoder.layers.8.mlp.fc1": 51,
    "vision_model.encoder.layers.7.mlp.fc1": 205,
    "vision_model.encoder.layers.6.mlp.fc1": 154,
    "vision_model.encoder.layers.5.mlp.fc1": 307,
    "vision_model.encoder.layers.4.mlp.fc1": 102,
    "vision_model.encoder.layers.3.mlp.fc1": 102,
    "vision_model.encoder.layers.2.mlp.fc1": 205,
    "vision_model.encoder.layers.1.mlp.fc1": 102,
    "vision_model.encoder.layers.0.mlp.fc1": 358,
    "text_model.encoder.layers.11.mlp.fc1": 0,
    "text_model.encoder.layers.10.mlp.fc1": 38,
    "text_model.encoder.layers.9.mlp.fc1": 38,
    "text_model.encoder.layers.8.mlp.fc1": 307,
    "text_model.encoder.layers.7.mlp.fc1": 0,
    "text_model.encoder.layers.6.mlp.fc1": 115,
    "text_model.encoder.layers.5.mlp.fc1": 0,
    "text_model.encoder.layers.4.mlp.fc1": 230,
    "text_model.encoder.layers.3.mlp.fc1": 307,
    "text_model.encoder.layers.2.mlp.fc1": 38,
    "text_model.encoder.layers.1.mlp.fc1": 38,
    "text_model.encoder.layers.0.mlp.fc1": 307
}
2024-06-16 05:24:25,871 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.23.mlp.fc1] [Rank: 410]
2024-06-16 05:24:25,890 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.22.mlp.fc1] [Rank: 358]
2024-06-16 05:24:25,890 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.21.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:24:25,901 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.20.mlp.fc1] [Rank: 205]
2024-06-16 05:24:25,901 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.19.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:24:25,918 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.18.mlp.fc1] [Rank: 307]
2024-06-16 05:24:25,931 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.17.mlp.fc1] [Rank: 256]
2024-06-16 05:24:25,937 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.16.mlp.fc1] [Rank: 102]
2024-06-16 05:24:25,941 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.15.mlp.fc1] [Rank: 51]
2024-06-16 05:24:25,953 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.14.mlp.fc1] [Rank: 256]
2024-06-16 05:24:25,957 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.13.mlp.fc1] [Rank: 51]
2024-06-16 05:24:25,970 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.12.mlp.fc1] [Rank: 307]
2024-06-16 05:24:25,973 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.11.mlp.fc1] [Rank: 51]
2024-06-16 05:24:25,977 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.10.mlp.fc1] [Rank: 102]
2024-06-16 05:24:25,984 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.9.mlp.fc1] [Rank: 154]
2024-06-16 05:24:25,986 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.8.mlp.fc1] [Rank: 51]
2024-06-16 05:24:25,997 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.7.mlp.fc1] [Rank: 205]
2024-06-16 05:24:26,005 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.6.mlp.fc1] [Rank: 154]
2024-06-16 05:24:26,043 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.5.mlp.fc1] [Rank: 307]
2024-06-16 05:24:26,077 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.4.mlp.fc1] [Rank: 102]
2024-06-16 05:24:26,083 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.3.mlp.fc1] [Rank: 102]
2024-06-16 05:24:26,106 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.2.mlp.fc1] [Rank: 205]
2024-06-16 05:24:26,113 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.1.mlp.fc1] [Rank: 102]
2024-06-16 05:24:26,138 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.0.mlp.fc1] [Rank: 358]
2024-06-16 05:24:26,138 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.11.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:24:26,141 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.10.mlp.fc1] [Rank: 38]
2024-06-16 05:24:26,143 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.9.mlp.fc1] [Rank: 38]
2024-06-16 05:24:26,159 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.8.mlp.fc1] [Rank: 307]
2024-06-16 05:24:26,159 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.7.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:24:26,164 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.6.mlp.fc1] [Rank: 115]
2024-06-16 05:24:26,164 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.5.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:24:26,171 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.4.mlp.fc1] [Rank: 230]
2024-06-16 05:24:26,181 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.3.mlp.fc1] [Rank: 307]
2024-06-16 05:24:26,183 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.2.mlp.fc1] [Rank: 38]
2024-06-16 05:24:26,185 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.1.mlp.fc1] [Rank: 38]
2024-06-16 05:24:26,195 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.0.mlp.fc1] [Rank: 307]
2024-06-16 05:24:27,689 | INFO | model.py:192 | svd_init | SVD initialized for adapter 'default'.
2024-06-16 05:24:27,727 | INFO | test_classify.py:151 | run_test_classify | ############ ID_ImageNet1K ############
2024-06-16 05:32:57,477 | INFO | test_classify.py:161 | run_test_classify | Accuracy on ID_ImageNet1K: 68.20
2024-06-16 05:32:57,477 | INFO | test_classify.py:151 | run_test_classify | ############ OOD_Sun ############
2024-06-16 05:34:42,168 | INFO | test_classify.py:161 | run_test_classify | Accuracy on OOD_Sun: 74.55
2024-06-16 05:34:42,168 | INFO | test_classify.py:151 | run_test_classify | ############ OOD_Places ############
2024-06-16 05:36:23,700 | INFO | test_classify.py:161 | run_test_classify | Accuracy on OOD_Places: 46.47
2024-06-16 05:36:23,700 | INFO | test_classify.py:151 | run_test_classify | ############ OOD_Texture ############
2024-06-16 05:37:22,229 | INFO | test_classify.py:161 | run_test_classify | Accuracy on OOD_Texture: 50.51
2024-06-16 05:37:22,229 | INFO | test_classify.py:164 | run_test_classify | ############ Summary ############
2024-06-16 05:37:22,229 | INFO | test_classify.py:166 | run_test_classify | Accuracy on ID_ImageNet1K: 68.20
2024-06-16 05:37:22,229 | INFO | test_classify.py:166 | run_test_classify | Accuracy on OOD_Sun: 74.55
2024-06-16 05:37:22,229 | INFO | test_classify.py:166 | run_test_classify | Accuracy on OOD_Places: 46.47
2024-06-16 05:37:22,229 | INFO | test_classify.py:166 | run_test_classify | Accuracy on OOD_Texture: 50.51
