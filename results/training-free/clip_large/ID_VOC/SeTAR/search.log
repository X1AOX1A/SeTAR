2024-06-16 04:57:33,777 | INFO | argparser.py:195 | print_args | Loading args from config file: configs/training_free/clip_large/ID_VOC/SeTAR.json
2024-06-16 04:57:33,777 | INFO | argparser.py:198 | print_args | Config: 
{
    "data_root": "/data/DATASETS/SVD_OOD",
    "id_dataset": "ID_VOC",
    "split": "val",
    "batch_size": 512,
    "seed": 5,
    "device": "cuda",
    "exp_name": "SeTAR",
    "log_directory": "./results/training-free/clip_large/ID_VOC/SeTAR",
    "scorers": [
        "loss"
    ],
    "temperature": 100,
    "recall_level": 0.95,
    "model_name": "openai/clip-vit-large-patch14",
    "model_type": "CLIP",
    "clip_ckpt": null,
    "locoop_ckpt": null,
    "lora_svd_init": true,
    "lora_svd_init_type": "small",
    "lora_settings": null,
    "target_modules": null,
    "lora_r": null,
    "lora_alpha": null,
    "n_ctx": 16,
    "searcher": "visual_text",
    "candi_ratios": [
        0,
        0.05,
        0.1,
        0.15,
        0.2,
        0.25,
        0.3,
        0.35,
        0.4
    ],
    "weight_type": "W_up",
    "best_scorer": "loss",
    "best_metric": "locoop_loss",
    "freeze_proj": true,
    "locoop_lambda": 0.3,
    "locoop_top_k": 6,
    "use_pred_label": false
}
2024-06-16 04:57:33,781 | INFO | searchers.py:66 | __init__ | Best scorer: loss
2024-06-16 04:57:33,781 | INFO | searchers.py:67 | __init__ | Best metric: locoop_loss
2024-06-16 04:57:33,781 | INFO | searchers.py:33 | __init__ | ############ Searcher Created ############
2024-06-16 04:57:33,781 | INFO | searchers.py:34 | __init__ | Searcher: visual_text
2024-06-16 04:57:33,781 | INFO | searchers.py:172 | run | Start searching low rank configs...
2024-06-16 04:57:55,206 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23         0.4      0.063866  0.630032  -1.88722  80.851059          51.728718

2024-06-16 04:58:15,869 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394

2024-06-16 04:58:37,292 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394

2024-06-16 04:58:58,684 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207

2024-06-16 04:59:20,586 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207
4        visual        W_up         19        0.00      0.041445  0.604492 -1.876823  79.787231          51.421207

2024-06-16 04:59:42,503 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207
4        visual        W_up         19        0.00      0.041445  0.604492 -1.876823  79.787231          51.421207
5        visual        W_up         18        0.30      0.027478  0.588392 -1.869712  82.978722          50.623333

2024-06-16 05:00:05,300 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207
4        visual        W_up         19        0.00      0.041445  0.604492 -1.876823  79.787231          51.421207
5        visual        W_up         18        0.30      0.027478  0.588392 -1.869712  82.978722          50.623333
6        visual        W_up         17        0.25      0.024647  0.585189 -1.868474  80.851059          50.199467

2024-06-16 05:00:28,489 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207
4        visual        W_up         19        0.00      0.041445  0.604492 -1.876823  79.787231          51.421207
5        visual        W_up         18        0.30      0.027478  0.588392 -1.869712  82.978722          50.623333
6        visual        W_up         17        0.25      0.024647  0.585189 -1.868474  80.851059          50.199467
7        visual        W_up         16        0.10      0.019626  0.579654 -1.866758  81.914886          49.921043

2024-06-16 05:00:52,302 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207
4        visual        W_up         19        0.00      0.041445  0.604492 -1.876823  79.787231          51.421207
5        visual        W_up         18        0.30      0.027478  0.588392 -1.869712  82.978722          50.623333
6        visual        W_up         17        0.25      0.024647  0.585189 -1.868474  80.851059          50.199467
7        visual        W_up         16        0.10      0.019626  0.579654 -1.866758  81.914886          49.921043
8        visual        W_up         15        0.05      0.014317  0.574241 -1.866414  81.914886          49.829620

2024-06-16 05:01:16,440 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207
4        visual        W_up         19        0.00      0.041445  0.604492 -1.876823  79.787231          51.421207
5        visual        W_up         18        0.30      0.027478  0.588392 -1.869712  82.978722          50.623333
6        visual        W_up         17        0.25      0.024647  0.585189 -1.868474  80.851059          50.199467
7        visual        W_up         16        0.10      0.019626  0.579654 -1.866758  81.914886          49.921043
8        visual        W_up         15        0.05      0.014317  0.574241 -1.866414  81.914886          49.829620
9        visual        W_up         14        0.25      0.005878  0.565525 -1.865491  84.042549          50.054020

2024-06-16 05:01:41,503 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207
4        visual        W_up         19        0.00      0.041445  0.604492 -1.876823  79.787231          51.421207
5        visual        W_up         18        0.30      0.027478  0.588392 -1.869712  82.978722          50.623333
6        visual        W_up         17        0.25      0.024647  0.585189 -1.868474  80.851059          50.199467
7        visual        W_up         16        0.10      0.019626  0.579654 -1.866758  81.914886          49.921043
8        visual        W_up         15        0.05      0.014317  0.574241 -1.866414  81.914886          49.829620
9        visual        W_up         14        0.25      0.005878  0.565525 -1.865491  84.042549          50.054020
10       visual        W_up         13        0.05      0.004716  0.564943 -1.867421  84.042549          50.211929

2024-06-16 05:02:07,032 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207
4        visual        W_up         19        0.00      0.041445  0.604492 -1.876823  79.787231          51.421207
5        visual        W_up         18        0.30      0.027478  0.588392 -1.869712  82.978722          50.623333
6        visual        W_up         17        0.25      0.024647  0.585189 -1.868474  80.851059          50.199467
7        visual        W_up         16        0.10      0.019626  0.579654 -1.866758  81.914886          49.921043
8        visual        W_up         15        0.05      0.014317  0.574241 -1.866414  81.914886          49.829620
9        visual        W_up         14        0.25      0.005878  0.565525 -1.865491  84.042549          50.054020
10       visual        W_up         13        0.05      0.004716  0.564943 -1.867421  84.042549          50.211929
11       visual        W_up         12        0.30     -0.018952  0.541628 -1.868599  84.042549          50.644112

2024-06-16 05:02:33,045 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207
4        visual        W_up         19        0.00      0.041445  0.604492 -1.876823  79.787231          51.421207
5        visual        W_up         18        0.30      0.027478  0.588392 -1.869712  82.978722          50.623333
6        visual        W_up         17        0.25      0.024647  0.585189 -1.868474  80.851059          50.199467
7        visual        W_up         16        0.10      0.019626  0.579654 -1.866758  81.914886          49.921043
8        visual        W_up         15        0.05      0.014317  0.574241 -1.866414  81.914886          49.829620
9        visual        W_up         14        0.25      0.005878  0.565525 -1.865491  84.042549          50.054020
10       visual        W_up         13        0.05      0.004716  0.564943 -1.867421  84.042549          50.211929
11       visual        W_up         12        0.30     -0.018952  0.541628 -1.868599  84.042549          50.644112
12       visual        W_up         11        0.05     -0.025269  0.536262 -1.871771  82.978722          50.752155

2024-06-16 05:02:59,342 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207
4        visual        W_up         19        0.00      0.041445  0.604492 -1.876823  79.787231          51.421207
5        visual        W_up         18        0.30      0.027478  0.588392 -1.869712  82.978722          50.623333
6        visual        W_up         17        0.25      0.024647  0.585189 -1.868474  80.851059          50.199467
7        visual        W_up         16        0.10      0.019626  0.579654 -1.866758  81.914886          49.921043
8        visual        W_up         15        0.05      0.014317  0.574241 -1.866414  81.914886          49.829620
9        visual        W_up         14        0.25      0.005878  0.565525 -1.865491  84.042549          50.054020
10       visual        W_up         13        0.05      0.004716  0.564943 -1.867421  84.042549          50.211929
11       visual        W_up         12        0.30     -0.018952  0.541628 -1.868599  84.042549          50.644112
12       visual        W_up         11        0.05     -0.025269  0.536262 -1.871771  82.978722          50.752155
13       visual        W_up         10        0.10     -0.031650  0.529723 -1.871246  84.042549          51.026428

2024-06-16 05:03:26,184 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207
4        visual        W_up         19        0.00      0.041445  0.604492 -1.876823  79.787231          51.421207
5        visual        W_up         18        0.30      0.027478  0.588392 -1.869712  82.978722          50.623333
6        visual        W_up         17        0.25      0.024647  0.585189 -1.868474  80.851059          50.199467
7        visual        W_up         16        0.10      0.019626  0.579654 -1.866758  81.914886          49.921043
8        visual        W_up         15        0.05      0.014317  0.574241 -1.866414  81.914886          49.829620
9        visual        W_up         14        0.25      0.005878  0.565525 -1.865491  84.042549          50.054020
10       visual        W_up         13        0.05      0.004716  0.564943 -1.867421  84.042549          50.211929
11       visual        W_up         12        0.30     -0.018952  0.541628 -1.868599  84.042549          50.644112
12       visual        W_up         11        0.05     -0.025269  0.536262 -1.871771  82.978722          50.752155
13       visual        W_up         10        0.10     -0.031650  0.529723 -1.871246  84.042549          51.026428
14       visual        W_up          9        0.15     -0.034220  0.526048 -1.867559  84.042549          51.117851

2024-06-16 05:03:53,550 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207
4        visual        W_up         19        0.00      0.041445  0.604492 -1.876823  79.787231          51.421207
5        visual        W_up         18        0.30      0.027478  0.588392 -1.869712  82.978722          50.623333
6        visual        W_up         17        0.25      0.024647  0.585189 -1.868474  80.851059          50.199467
7        visual        W_up         16        0.10      0.019626  0.579654 -1.866758  81.914886          49.921043
8        visual        W_up         15        0.05      0.014317  0.574241 -1.866414  81.914886          49.829620
9        visual        W_up         14        0.25      0.005878  0.565525 -1.865491  84.042549          50.054020
10       visual        W_up         13        0.05      0.004716  0.564943 -1.867421  84.042549          50.211929
11       visual        W_up         12        0.30     -0.018952  0.541628 -1.868599  84.042549          50.644112
12       visual        W_up         11        0.05     -0.025269  0.536262 -1.871771  82.978722          50.752155
13       visual        W_up         10        0.10     -0.031650  0.529723 -1.871246  84.042549          51.026428
14       visual        W_up          9        0.15     -0.034220  0.526048 -1.867559  84.042549          51.117851
15       visual        W_up          8        0.05     -0.038564  0.521694 -1.867526  84.042549          51.188492

2024-06-16 05:04:21,874 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207
4        visual        W_up         19        0.00      0.041445  0.604492 -1.876823  79.787231          51.421207
5        visual        W_up         18        0.30      0.027478  0.588392 -1.869712  82.978722          50.623333
6        visual        W_up         17        0.25      0.024647  0.585189 -1.868474  80.851059          50.199467
7        visual        W_up         16        0.10      0.019626  0.579654 -1.866758  81.914886          49.921043
8        visual        W_up         15        0.05      0.014317  0.574241 -1.866414  81.914886          49.829620
9        visual        W_up         14        0.25      0.005878  0.565525 -1.865491  84.042549          50.054020
10       visual        W_up         13        0.05      0.004716  0.564943 -1.867421  84.042549          50.211929
11       visual        W_up         12        0.30     -0.018952  0.541628 -1.868599  84.042549          50.644112
12       visual        W_up         11        0.05     -0.025269  0.536262 -1.871771  82.978722          50.752155
13       visual        W_up         10        0.10     -0.031650  0.529723 -1.871246  84.042549          51.026428
14       visual        W_up          9        0.15     -0.034220  0.526048 -1.867559  84.042549          51.117851
15       visual        W_up          8        0.05     -0.038564  0.521694 -1.867526  84.042549          51.188492
16       visual        W_up          7        0.20     -0.039047  0.521462 -1.868363  84.042549          51.392120

2024-06-16 05:04:50,997 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207
4        visual        W_up         19        0.00      0.041445  0.604492 -1.876823  79.787231          51.421207
5        visual        W_up         18        0.30      0.027478  0.588392 -1.869712  82.978722          50.623333
6        visual        W_up         17        0.25      0.024647  0.585189 -1.868474  80.851059          50.199467
7        visual        W_up         16        0.10      0.019626  0.579654 -1.866758  81.914886          49.921043
8        visual        W_up         15        0.05      0.014317  0.574241 -1.866414  81.914886          49.829620
9        visual        W_up         14        0.25      0.005878  0.565525 -1.865491  84.042549          50.054020
10       visual        W_up         13        0.05      0.004716  0.564943 -1.867421  84.042549          50.211929
11       visual        W_up         12        0.30     -0.018952  0.541628 -1.868599  84.042549          50.644112
12       visual        W_up         11        0.05     -0.025269  0.536262 -1.871771  82.978722          50.752155
13       visual        W_up         10        0.10     -0.031650  0.529723 -1.871246  84.042549          51.026428
14       visual        W_up          9        0.15     -0.034220  0.526048 -1.867559  84.042549          51.117851
15       visual        W_up          8        0.05     -0.038564  0.521694 -1.867526  84.042549          51.188492
16       visual        W_up          7        0.20     -0.039047  0.521462 -1.868363  84.042549          51.392120
17       visual        W_up          6        0.15     -0.040530  0.519734 -1.867546  84.042549          51.387966

2024-06-16 05:05:20,354 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207
4        visual        W_up         19        0.00      0.041445  0.604492 -1.876823  79.787231          51.421207
5        visual        W_up         18        0.30      0.027478  0.588392 -1.869712  82.978722          50.623333
6        visual        W_up         17        0.25      0.024647  0.585189 -1.868474  80.851059          50.199467
7        visual        W_up         16        0.10      0.019626  0.579654 -1.866758  81.914886          49.921043
8        visual        W_up         15        0.05      0.014317  0.574241 -1.866414  81.914886          49.829620
9        visual        W_up         14        0.25      0.005878  0.565525 -1.865491  84.042549          50.054020
10       visual        W_up         13        0.05      0.004716  0.564943 -1.867421  84.042549          50.211929
11       visual        W_up         12        0.30     -0.018952  0.541628 -1.868599  84.042549          50.644112
12       visual        W_up         11        0.05     -0.025269  0.536262 -1.871771  82.978722          50.752155
13       visual        W_up         10        0.10     -0.031650  0.529723 -1.871246  84.042549          51.026428
14       visual        W_up          9        0.15     -0.034220  0.526048 -1.867559  84.042549          51.117851
15       visual        W_up          8        0.05     -0.038564  0.521694 -1.867526  84.042549          51.188492
16       visual        W_up          7        0.20     -0.039047  0.521462 -1.868363  84.042549          51.392120
17       visual        W_up          6        0.15     -0.040530  0.519734 -1.867546  84.042549          51.387966
18       visual        W_up          5        0.30     -0.046065  0.514436 -1.868337  84.042549          51.279919

2024-06-16 05:05:49,922 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207
4        visual        W_up         19        0.00      0.041445  0.604492 -1.876823  79.787231          51.421207
5        visual        W_up         18        0.30      0.027478  0.588392 -1.869712  82.978722          50.623333
6        visual        W_up         17        0.25      0.024647  0.585189 -1.868474  80.851059          50.199467
7        visual        W_up         16        0.10      0.019626  0.579654 -1.866758  81.914886          49.921043
8        visual        W_up         15        0.05      0.014317  0.574241 -1.866414  81.914886          49.829620
9        visual        W_up         14        0.25      0.005878  0.565525 -1.865491  84.042549          50.054020
10       visual        W_up         13        0.05      0.004716  0.564943 -1.867421  84.042549          50.211929
11       visual        W_up         12        0.30     -0.018952  0.541628 -1.868599  84.042549          50.644112
12       visual        W_up         11        0.05     -0.025269  0.536262 -1.871771  82.978722          50.752155
13       visual        W_up         10        0.10     -0.031650  0.529723 -1.871246  84.042549          51.026428
14       visual        W_up          9        0.15     -0.034220  0.526048 -1.867559  84.042549          51.117851
15       visual        W_up          8        0.05     -0.038564  0.521694 -1.867526  84.042549          51.188492
16       visual        W_up          7        0.20     -0.039047  0.521462 -1.868363  84.042549          51.392120
17       visual        W_up          6        0.15     -0.040530  0.519734 -1.867546  84.042549          51.387966
18       visual        W_up          5        0.30     -0.046065  0.514436 -1.868337  84.042549          51.279919
19       visual        W_up          4        0.10     -0.046719  0.513966 -1.868948  84.042549          51.138626

2024-06-16 05:06:19,997 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207
4        visual        W_up         19        0.00      0.041445  0.604492 -1.876823  79.787231          51.421207
5        visual        W_up         18        0.30      0.027478  0.588392 -1.869712  82.978722          50.623333
6        visual        W_up         17        0.25      0.024647  0.585189 -1.868474  80.851059          50.199467
7        visual        W_up         16        0.10      0.019626  0.579654 -1.866758  81.914886          49.921043
8        visual        W_up         15        0.05      0.014317  0.574241 -1.866414  81.914886          49.829620
9        visual        W_up         14        0.25      0.005878  0.565525 -1.865491  84.042549          50.054020
10       visual        W_up         13        0.05      0.004716  0.564943 -1.867421  84.042549          50.211929
11       visual        W_up         12        0.30     -0.018952  0.541628 -1.868599  84.042549          50.644112
12       visual        W_up         11        0.05     -0.025269  0.536262 -1.871771  82.978722          50.752155
13       visual        W_up         10        0.10     -0.031650  0.529723 -1.871246  84.042549          51.026428
14       visual        W_up          9        0.15     -0.034220  0.526048 -1.867559  84.042549          51.117851
15       visual        W_up          8        0.05     -0.038564  0.521694 -1.867526  84.042549          51.188492
16       visual        W_up          7        0.20     -0.039047  0.521462 -1.868363  84.042549          51.392120
17       visual        W_up          6        0.15     -0.040530  0.519734 -1.867546  84.042549          51.387966
18       visual        W_up          5        0.30     -0.046065  0.514436 -1.868337  84.042549          51.279919
19       visual        W_up          4        0.10     -0.046719  0.513966 -1.868948  84.042549          51.138626
20       visual        W_up          3        0.10     -0.047318  0.513373 -1.868970  85.106377          51.130318

2024-06-16 05:06:50,648 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207
4        visual        W_up         19        0.00      0.041445  0.604492 -1.876823  79.787231          51.421207
5        visual        W_up         18        0.30      0.027478  0.588392 -1.869712  82.978722          50.623333
6        visual        W_up         17        0.25      0.024647  0.585189 -1.868474  80.851059          50.199467
7        visual        W_up         16        0.10      0.019626  0.579654 -1.866758  81.914886          49.921043
8        visual        W_up         15        0.05      0.014317  0.574241 -1.866414  81.914886          49.829620
9        visual        W_up         14        0.25      0.005878  0.565525 -1.865491  84.042549          50.054020
10       visual        W_up         13        0.05      0.004716  0.564943 -1.867421  84.042549          50.211929
11       visual        W_up         12        0.30     -0.018952  0.541628 -1.868599  84.042549          50.644112
12       visual        W_up         11        0.05     -0.025269  0.536262 -1.871771  82.978722          50.752155
13       visual        W_up         10        0.10     -0.031650  0.529723 -1.871246  84.042549          51.026428
14       visual        W_up          9        0.15     -0.034220  0.526048 -1.867559  84.042549          51.117851
15       visual        W_up          8        0.05     -0.038564  0.521694 -1.867526  84.042549          51.188492
16       visual        W_up          7        0.20     -0.039047  0.521462 -1.868363  84.042549          51.392120
17       visual        W_up          6        0.15     -0.040530  0.519734 -1.867546  84.042549          51.387966
18       visual        W_up          5        0.30     -0.046065  0.514436 -1.868337  84.042549          51.279919
19       visual        W_up          4        0.10     -0.046719  0.513966 -1.868948  84.042549          51.138626
20       visual        W_up          3        0.10     -0.047318  0.513373 -1.868970  85.106377          51.130318
21       visual        W_up          2        0.20     -0.050690  0.509905 -1.868649  84.042549          51.101227

2024-06-16 05:07:21,658 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207
4        visual        W_up         19        0.00      0.041445  0.604492 -1.876823  79.787231          51.421207
5        visual        W_up         18        0.30      0.027478  0.588392 -1.869712  82.978722          50.623333
6        visual        W_up         17        0.25      0.024647  0.585189 -1.868474  80.851059          50.199467
7        visual        W_up         16        0.10      0.019626  0.579654 -1.866758  81.914886          49.921043
8        visual        W_up         15        0.05      0.014317  0.574241 -1.866414  81.914886          49.829620
9        visual        W_up         14        0.25      0.005878  0.565525 -1.865491  84.042549          50.054020
10       visual        W_up         13        0.05      0.004716  0.564943 -1.867421  84.042549          50.211929
11       visual        W_up         12        0.30     -0.018952  0.541628 -1.868599  84.042549          50.644112
12       visual        W_up         11        0.05     -0.025269  0.536262 -1.871771  82.978722          50.752155
13       visual        W_up         10        0.10     -0.031650  0.529723 -1.871246  84.042549          51.026428
14       visual        W_up          9        0.15     -0.034220  0.526048 -1.867559  84.042549          51.117851
15       visual        W_up          8        0.05     -0.038564  0.521694 -1.867526  84.042549          51.188492
16       visual        W_up          7        0.20     -0.039047  0.521462 -1.868363  84.042549          51.392120
17       visual        W_up          6        0.15     -0.040530  0.519734 -1.867546  84.042549          51.387966
18       visual        W_up          5        0.30     -0.046065  0.514436 -1.868337  84.042549          51.279919
19       visual        W_up          4        0.10     -0.046719  0.513966 -1.868948  84.042549          51.138626
20       visual        W_up          3        0.10     -0.047318  0.513373 -1.868970  85.106377          51.130318
21       visual        W_up          2        0.20     -0.050690  0.509905 -1.868649  84.042549          51.101227
22       visual        W_up          1        0.10     -0.051216  0.509371 -1.868622  84.042549          51.059677

2024-06-16 05:07:53,368 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207
4        visual        W_up         19        0.00      0.041445  0.604492 -1.876823  79.787231          51.421207
5        visual        W_up         18        0.30      0.027478  0.588392 -1.869712  82.978722          50.623333
6        visual        W_up         17        0.25      0.024647  0.585189 -1.868474  80.851059          50.199467
7        visual        W_up         16        0.10      0.019626  0.579654 -1.866758  81.914886          49.921043
8        visual        W_up         15        0.05      0.014317  0.574241 -1.866414  81.914886          49.829620
9        visual        W_up         14        0.25      0.005878  0.565525 -1.865491  84.042549          50.054020
10       visual        W_up         13        0.05      0.004716  0.564943 -1.867421  84.042549          50.211929
11       visual        W_up         12        0.30     -0.018952  0.541628 -1.868599  84.042549          50.644112
12       visual        W_up         11        0.05     -0.025269  0.536262 -1.871771  82.978722          50.752155
13       visual        W_up         10        0.10     -0.031650  0.529723 -1.871246  84.042549          51.026428
14       visual        W_up          9        0.15     -0.034220  0.526048 -1.867559  84.042549          51.117851
15       visual        W_up          8        0.05     -0.038564  0.521694 -1.867526  84.042549          51.188492
16       visual        W_up          7        0.20     -0.039047  0.521462 -1.868363  84.042549          51.392120
17       visual        W_up          6        0.15     -0.040530  0.519734 -1.867546  84.042549          51.387966
18       visual        W_up          5        0.30     -0.046065  0.514436 -1.868337  84.042549          51.279919
19       visual        W_up          4        0.10     -0.046719  0.513966 -1.868948  84.042549          51.138626
20       visual        W_up          3        0.10     -0.047318  0.513373 -1.868970  85.106377          51.130318
21       visual        W_up          2        0.20     -0.050690  0.509905 -1.868649  84.042549          51.101227
22       visual        W_up          1        0.10     -0.051216  0.509371 -1.868622  84.042549          51.059677
23       visual        W_up          0        0.35     -0.052313  0.508245 -1.868526  84.042549          51.055515

2024-06-16 05:08:25,489 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207
4        visual        W_up         19        0.00      0.041445  0.604492 -1.876823  79.787231          51.421207
5        visual        W_up         18        0.30      0.027478  0.588392 -1.869712  82.978722          50.623333
6        visual        W_up         17        0.25      0.024647  0.585189 -1.868474  80.851059          50.199467
7        visual        W_up         16        0.10      0.019626  0.579654 -1.866758  81.914886          49.921043
8        visual        W_up         15        0.05      0.014317  0.574241 -1.866414  81.914886          49.829620
9        visual        W_up         14        0.25      0.005878  0.565525 -1.865491  84.042549          50.054020
10       visual        W_up         13        0.05      0.004716  0.564943 -1.867421  84.042549          50.211929
11       visual        W_up         12        0.30     -0.018952  0.541628 -1.868599  84.042549          50.644112
12       visual        W_up         11        0.05     -0.025269  0.536262 -1.871771  82.978722          50.752155
13       visual        W_up         10        0.10     -0.031650  0.529723 -1.871246  84.042549          51.026428
14       visual        W_up          9        0.15     -0.034220  0.526048 -1.867559  84.042549          51.117851
15       visual        W_up          8        0.05     -0.038564  0.521694 -1.867526  84.042549          51.188492
16       visual        W_up          7        0.20     -0.039047  0.521462 -1.868363  84.042549          51.392120
17       visual        W_up          6        0.15     -0.040530  0.519734 -1.867546  84.042549          51.387966
18       visual        W_up          5        0.30     -0.046065  0.514436 -1.868337  84.042549          51.279919
19       visual        W_up          4        0.10     -0.046719  0.513966 -1.868948  84.042549          51.138626
20       visual        W_up          3        0.10     -0.047318  0.513373 -1.868970  85.106377          51.130318
21       visual        W_up          2        0.20     -0.050690  0.509905 -1.868649  84.042549          51.101227
22       visual        W_up          1        0.10     -0.051216  0.509371 -1.868622  84.042549          51.059677
23       visual        W_up          0        0.35     -0.052313  0.508245 -1.868526  84.042549          51.055515
24         text        W_up         11        0.00     -0.052313  0.508245 -1.868526  84.042549          51.055515

2024-06-16 05:08:57,987 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207
4        visual        W_up         19        0.00      0.041445  0.604492 -1.876823  79.787231          51.421207
5        visual        W_up         18        0.30      0.027478  0.588392 -1.869712  82.978722          50.623333
6        visual        W_up         17        0.25      0.024647  0.585189 -1.868474  80.851059          50.199467
7        visual        W_up         16        0.10      0.019626  0.579654 -1.866758  81.914886          49.921043
8        visual        W_up         15        0.05      0.014317  0.574241 -1.866414  81.914886          49.829620
9        visual        W_up         14        0.25      0.005878  0.565525 -1.865491  84.042549          50.054020
10       visual        W_up         13        0.05      0.004716  0.564943 -1.867421  84.042549          50.211929
11       visual        W_up         12        0.30     -0.018952  0.541628 -1.868599  84.042549          50.644112
12       visual        W_up         11        0.05     -0.025269  0.536262 -1.871771  82.978722          50.752155
13       visual        W_up         10        0.10     -0.031650  0.529723 -1.871246  84.042549          51.026428
14       visual        W_up          9        0.15     -0.034220  0.526048 -1.867559  84.042549          51.117851
15       visual        W_up          8        0.05     -0.038564  0.521694 -1.867526  84.042549          51.188492
16       visual        W_up          7        0.20     -0.039047  0.521462 -1.868363  84.042549          51.392120
17       visual        W_up          6        0.15     -0.040530  0.519734 -1.867546  84.042549          51.387966
18       visual        W_up          5        0.30     -0.046065  0.514436 -1.868337  84.042549          51.279919
19       visual        W_up          4        0.10     -0.046719  0.513966 -1.868948  84.042549          51.138626
20       visual        W_up          3        0.10     -0.047318  0.513373 -1.868970  85.106377          51.130318
21       visual        W_up          2        0.20     -0.050690  0.509905 -1.868649  84.042549          51.101227
22       visual        W_up          1        0.10     -0.051216  0.509371 -1.868622  84.042549          51.059677
23       visual        W_up          0        0.35     -0.052313  0.508245 -1.868526  84.042549          51.055515
24         text        W_up         11        0.00     -0.052313  0.508245 -1.868526  84.042549          51.055515
25         text        W_up         10        0.05     -0.060959  0.501824 -1.875944  84.042549          51.117851

2024-06-16 05:09:31,058 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207
4        visual        W_up         19        0.00      0.041445  0.604492 -1.876823  79.787231          51.421207
5        visual        W_up         18        0.30      0.027478  0.588392 -1.869712  82.978722          50.623333
6        visual        W_up         17        0.25      0.024647  0.585189 -1.868474  80.851059          50.199467
7        visual        W_up         16        0.10      0.019626  0.579654 -1.866758  81.914886          49.921043
8        visual        W_up         15        0.05      0.014317  0.574241 -1.866414  81.914886          49.829620
9        visual        W_up         14        0.25      0.005878  0.565525 -1.865491  84.042549          50.054020
10       visual        W_up         13        0.05      0.004716  0.564943 -1.867421  84.042549          50.211929
11       visual        W_up         12        0.30     -0.018952  0.541628 -1.868599  84.042549          50.644112
12       visual        W_up         11        0.05     -0.025269  0.536262 -1.871771  82.978722          50.752155
13       visual        W_up         10        0.10     -0.031650  0.529723 -1.871246  84.042549          51.026428
14       visual        W_up          9        0.15     -0.034220  0.526048 -1.867559  84.042549          51.117851
15       visual        W_up          8        0.05     -0.038564  0.521694 -1.867526  84.042549          51.188492
16       visual        W_up          7        0.20     -0.039047  0.521462 -1.868363  84.042549          51.392120
17       visual        W_up          6        0.15     -0.040530  0.519734 -1.867546  84.042549          51.387966
18       visual        W_up          5        0.30     -0.046065  0.514436 -1.868337  84.042549          51.279919
19       visual        W_up          4        0.10     -0.046719  0.513966 -1.868948  84.042549          51.138626
20       visual        W_up          3        0.10     -0.047318  0.513373 -1.868970  85.106377          51.130318
21       visual        W_up          2        0.20     -0.050690  0.509905 -1.868649  84.042549          51.101227
22       visual        W_up          1        0.10     -0.051216  0.509371 -1.868622  84.042549          51.059677
23       visual        W_up          0        0.35     -0.052313  0.508245 -1.868526  84.042549          51.055515
24         text        W_up         11        0.00     -0.052313  0.508245 -1.868526  84.042549          51.055515
25         text        W_up         10        0.05     -0.060959  0.501824 -1.875944  84.042549          51.117851
26         text        W_up          9        0.05     -0.064110  0.498561 -1.875569  85.106377          50.968246

2024-06-16 05:10:03,968 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207
4        visual        W_up         19        0.00      0.041445  0.604492 -1.876823  79.787231          51.421207
5        visual        W_up         18        0.30      0.027478  0.588392 -1.869712  82.978722          50.623333
6        visual        W_up         17        0.25      0.024647  0.585189 -1.868474  80.851059          50.199467
7        visual        W_up         16        0.10      0.019626  0.579654 -1.866758  81.914886          49.921043
8        visual        W_up         15        0.05      0.014317  0.574241 -1.866414  81.914886          49.829620
9        visual        W_up         14        0.25      0.005878  0.565525 -1.865491  84.042549          50.054020
10       visual        W_up         13        0.05      0.004716  0.564943 -1.867421  84.042549          50.211929
11       visual        W_up         12        0.30     -0.018952  0.541628 -1.868599  84.042549          50.644112
12       visual        W_up         11        0.05     -0.025269  0.536262 -1.871771  82.978722          50.752155
13       visual        W_up         10        0.10     -0.031650  0.529723 -1.871246  84.042549          51.026428
14       visual        W_up          9        0.15     -0.034220  0.526048 -1.867559  84.042549          51.117851
15       visual        W_up          8        0.05     -0.038564  0.521694 -1.867526  84.042549          51.188492
16       visual        W_up          7        0.20     -0.039047  0.521462 -1.868363  84.042549          51.392120
17       visual        W_up          6        0.15     -0.040530  0.519734 -1.867546  84.042549          51.387966
18       visual        W_up          5        0.30     -0.046065  0.514436 -1.868337  84.042549          51.279919
19       visual        W_up          4        0.10     -0.046719  0.513966 -1.868948  84.042549          51.138626
20       visual        W_up          3        0.10     -0.047318  0.513373 -1.868970  85.106377          51.130318
21       visual        W_up          2        0.20     -0.050690  0.509905 -1.868649  84.042549          51.101227
22       visual        W_up          1        0.10     -0.051216  0.509371 -1.868622  84.042549          51.059677
23       visual        W_up          0        0.35     -0.052313  0.508245 -1.868526  84.042549          51.055515
24         text        W_up         11        0.00     -0.052313  0.508245 -1.868526  84.042549          51.055515
25         text        W_up         10        0.05     -0.060959  0.501824 -1.875944  84.042549          51.117851
26         text        W_up          9        0.05     -0.064110  0.498561 -1.875569  85.106377          50.968246
27         text        W_up          8        0.40     -0.067955  0.489954 -1.859697  85.106377          49.667553

2024-06-16 05:10:37,098 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207
4        visual        W_up         19        0.00      0.041445  0.604492 -1.876823  79.787231          51.421207
5        visual        W_up         18        0.30      0.027478  0.588392 -1.869712  82.978722          50.623333
6        visual        W_up         17        0.25      0.024647  0.585189 -1.868474  80.851059          50.199467
7        visual        W_up         16        0.10      0.019626  0.579654 -1.866758  81.914886          49.921043
8        visual        W_up         15        0.05      0.014317  0.574241 -1.866414  81.914886          49.829620
9        visual        W_up         14        0.25      0.005878  0.565525 -1.865491  84.042549          50.054020
10       visual        W_up         13        0.05      0.004716  0.564943 -1.867421  84.042549          50.211929
11       visual        W_up         12        0.30     -0.018952  0.541628 -1.868599  84.042549          50.644112
12       visual        W_up         11        0.05     -0.025269  0.536262 -1.871771  82.978722          50.752155
13       visual        W_up         10        0.10     -0.031650  0.529723 -1.871246  84.042549          51.026428
14       visual        W_up          9        0.15     -0.034220  0.526048 -1.867559  84.042549          51.117851
15       visual        W_up          8        0.05     -0.038564  0.521694 -1.867526  84.042549          51.188492
16       visual        W_up          7        0.20     -0.039047  0.521462 -1.868363  84.042549          51.392120
17       visual        W_up          6        0.15     -0.040530  0.519734 -1.867546  84.042549          51.387966
18       visual        W_up          5        0.30     -0.046065  0.514436 -1.868337  84.042549          51.279919
19       visual        W_up          4        0.10     -0.046719  0.513966 -1.868948  84.042549          51.138626
20       visual        W_up          3        0.10     -0.047318  0.513373 -1.868970  85.106377          51.130318
21       visual        W_up          2        0.20     -0.050690  0.509905 -1.868649  84.042549          51.101227
22       visual        W_up          1        0.10     -0.051216  0.509371 -1.868622  84.042549          51.059677
23       visual        W_up          0        0.35     -0.052313  0.508245 -1.868526  84.042549          51.055515
24         text        W_up         11        0.00     -0.052313  0.508245 -1.868526  84.042549          51.055515
25         text        W_up         10        0.05     -0.060959  0.501824 -1.875944  84.042549          51.117851
26         text        W_up          9        0.05     -0.064110  0.498561 -1.875569  85.106377          50.968246
27         text        W_up          8        0.40     -0.067955  0.489954 -1.859697  85.106377          49.667553
28         text        W_up          7        0.00     -0.067955  0.489954 -1.859697  85.106377          49.667553

2024-06-16 05:11:10,249 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207
4        visual        W_up         19        0.00      0.041445  0.604492 -1.876823  79.787231          51.421207
5        visual        W_up         18        0.30      0.027478  0.588392 -1.869712  82.978722          50.623333
6        visual        W_up         17        0.25      0.024647  0.585189 -1.868474  80.851059          50.199467
7        visual        W_up         16        0.10      0.019626  0.579654 -1.866758  81.914886          49.921043
8        visual        W_up         15        0.05      0.014317  0.574241 -1.866414  81.914886          49.829620
9        visual        W_up         14        0.25      0.005878  0.565525 -1.865491  84.042549          50.054020
10       visual        W_up         13        0.05      0.004716  0.564943 -1.867421  84.042549          50.211929
11       visual        W_up         12        0.30     -0.018952  0.541628 -1.868599  84.042549          50.644112
12       visual        W_up         11        0.05     -0.025269  0.536262 -1.871771  82.978722          50.752155
13       visual        W_up         10        0.10     -0.031650  0.529723 -1.871246  84.042549          51.026428
14       visual        W_up          9        0.15     -0.034220  0.526048 -1.867559  84.042549          51.117851
15       visual        W_up          8        0.05     -0.038564  0.521694 -1.867526  84.042549          51.188492
16       visual        W_up          7        0.20     -0.039047  0.521462 -1.868363  84.042549          51.392120
17       visual        W_up          6        0.15     -0.040530  0.519734 -1.867546  84.042549          51.387966
18       visual        W_up          5        0.30     -0.046065  0.514436 -1.868337  84.042549          51.279919
19       visual        W_up          4        0.10     -0.046719  0.513966 -1.868948  84.042549          51.138626
20       visual        W_up          3        0.10     -0.047318  0.513373 -1.868970  85.106377          51.130318
21       visual        W_up          2        0.20     -0.050690  0.509905 -1.868649  84.042549          51.101227
22       visual        W_up          1        0.10     -0.051216  0.509371 -1.868622  84.042549          51.059677
23       visual        W_up          0        0.35     -0.052313  0.508245 -1.868526  84.042549          51.055515
24         text        W_up         11        0.00     -0.052313  0.508245 -1.868526  84.042549          51.055515
25         text        W_up         10        0.05     -0.060959  0.501824 -1.875944  84.042549          51.117851
26         text        W_up          9        0.05     -0.064110  0.498561 -1.875569  85.106377          50.968246
27         text        W_up          8        0.40     -0.067955  0.489954 -1.859697  85.106377          49.667553
28         text        W_up          7        0.00     -0.067955  0.489954 -1.859697  85.106377          49.667553
29         text        W_up          6        0.15     -0.073768  0.485872 -1.865465  86.170212          48.728390

2024-06-16 05:11:43,950 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207
4        visual        W_up         19        0.00      0.041445  0.604492 -1.876823  79.787231          51.421207
5        visual        W_up         18        0.30      0.027478  0.588392 -1.869712  82.978722          50.623333
6        visual        W_up         17        0.25      0.024647  0.585189 -1.868474  80.851059          50.199467
7        visual        W_up         16        0.10      0.019626  0.579654 -1.866758  81.914886          49.921043
8        visual        W_up         15        0.05      0.014317  0.574241 -1.866414  81.914886          49.829620
9        visual        W_up         14        0.25      0.005878  0.565525 -1.865491  84.042549          50.054020
10       visual        W_up         13        0.05      0.004716  0.564943 -1.867421  84.042549          50.211929
11       visual        W_up         12        0.30     -0.018952  0.541628 -1.868599  84.042549          50.644112
12       visual        W_up         11        0.05     -0.025269  0.536262 -1.871771  82.978722          50.752155
13       visual        W_up         10        0.10     -0.031650  0.529723 -1.871246  84.042549          51.026428
14       visual        W_up          9        0.15     -0.034220  0.526048 -1.867559  84.042549          51.117851
15       visual        W_up          8        0.05     -0.038564  0.521694 -1.867526  84.042549          51.188492
16       visual        W_up          7        0.20     -0.039047  0.521462 -1.868363  84.042549          51.392120
17       visual        W_up          6        0.15     -0.040530  0.519734 -1.867546  84.042549          51.387966
18       visual        W_up          5        0.30     -0.046065  0.514436 -1.868337  84.042549          51.279919
19       visual        W_up          4        0.10     -0.046719  0.513966 -1.868948  84.042549          51.138626
20       visual        W_up          3        0.10     -0.047318  0.513373 -1.868970  85.106377          51.130318
21       visual        W_up          2        0.20     -0.050690  0.509905 -1.868649  84.042549          51.101227
22       visual        W_up          1        0.10     -0.051216  0.509371 -1.868622  84.042549          51.059677
23       visual        W_up          0        0.35     -0.052313  0.508245 -1.868526  84.042549          51.055515
24         text        W_up         11        0.00     -0.052313  0.508245 -1.868526  84.042549          51.055515
25         text        W_up         10        0.05     -0.060959  0.501824 -1.875944  84.042549          51.117851
26         text        W_up          9        0.05     -0.064110  0.498561 -1.875569  85.106377          50.968246
27         text        W_up          8        0.40     -0.067955  0.489954 -1.859697  85.106377          49.667553
28         text        W_up          7        0.00     -0.067955  0.489954 -1.859697  85.106377          49.667553
29         text        W_up          6        0.15     -0.073768  0.485872 -1.865465  86.170212          48.728390
30         text        W_up          5        0.00     -0.073768  0.485872 -1.865465  86.170212          48.728390

2024-06-16 05:12:17,907 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207
4        visual        W_up         19        0.00      0.041445  0.604492 -1.876823  79.787231          51.421207
5        visual        W_up         18        0.30      0.027478  0.588392 -1.869712  82.978722          50.623333
6        visual        W_up         17        0.25      0.024647  0.585189 -1.868474  80.851059          50.199467
7        visual        W_up         16        0.10      0.019626  0.579654 -1.866758  81.914886          49.921043
8        visual        W_up         15        0.05      0.014317  0.574241 -1.866414  81.914886          49.829620
9        visual        W_up         14        0.25      0.005878  0.565525 -1.865491  84.042549          50.054020
10       visual        W_up         13        0.05      0.004716  0.564943 -1.867421  84.042549          50.211929
11       visual        W_up         12        0.30     -0.018952  0.541628 -1.868599  84.042549          50.644112
12       visual        W_up         11        0.05     -0.025269  0.536262 -1.871771  82.978722          50.752155
13       visual        W_up         10        0.10     -0.031650  0.529723 -1.871246  84.042549          51.026428
14       visual        W_up          9        0.15     -0.034220  0.526048 -1.867559  84.042549          51.117851
15       visual        W_up          8        0.05     -0.038564  0.521694 -1.867526  84.042549          51.188492
16       visual        W_up          7        0.20     -0.039047  0.521462 -1.868363  84.042549          51.392120
17       visual        W_up          6        0.15     -0.040530  0.519734 -1.867546  84.042549          51.387966
18       visual        W_up          5        0.30     -0.046065  0.514436 -1.868337  84.042549          51.279919
19       visual        W_up          4        0.10     -0.046719  0.513966 -1.868948  84.042549          51.138626
20       visual        W_up          3        0.10     -0.047318  0.513373 -1.868970  85.106377          51.130318
21       visual        W_up          2        0.20     -0.050690  0.509905 -1.868649  84.042549          51.101227
22       visual        W_up          1        0.10     -0.051216  0.509371 -1.868622  84.042549          51.059677
23       visual        W_up          0        0.35     -0.052313  0.508245 -1.868526  84.042549          51.055515
24         text        W_up         11        0.00     -0.052313  0.508245 -1.868526  84.042549          51.055515
25         text        W_up         10        0.05     -0.060959  0.501824 -1.875944  84.042549          51.117851
26         text        W_up          9        0.05     -0.064110  0.498561 -1.875569  85.106377          50.968246
27         text        W_up          8        0.40     -0.067955  0.489954 -1.859697  85.106377          49.667553
28         text        W_up          7        0.00     -0.067955  0.489954 -1.859697  85.106377          49.667553
29         text        W_up          6        0.15     -0.073768  0.485872 -1.865465  86.170212          48.728390
30         text        W_up          5        0.00     -0.073768  0.485872 -1.865465  86.170212          48.728390
31         text        W_up          4        0.30     -0.089160  0.468391 -1.858502  88.297867          46.438660

2024-06-16 05:12:52,102 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207
4        visual        W_up         19        0.00      0.041445  0.604492 -1.876823  79.787231          51.421207
5        visual        W_up         18        0.30      0.027478  0.588392 -1.869712  82.978722          50.623333
6        visual        W_up         17        0.25      0.024647  0.585189 -1.868474  80.851059          50.199467
7        visual        W_up         16        0.10      0.019626  0.579654 -1.866758  81.914886          49.921043
8        visual        W_up         15        0.05      0.014317  0.574241 -1.866414  81.914886          49.829620
9        visual        W_up         14        0.25      0.005878  0.565525 -1.865491  84.042549          50.054020
10       visual        W_up         13        0.05      0.004716  0.564943 -1.867421  84.042549          50.211929
11       visual        W_up         12        0.30     -0.018952  0.541628 -1.868599  84.042549          50.644112
12       visual        W_up         11        0.05     -0.025269  0.536262 -1.871771  82.978722          50.752155
13       visual        W_up         10        0.10     -0.031650  0.529723 -1.871246  84.042549          51.026428
14       visual        W_up          9        0.15     -0.034220  0.526048 -1.867559  84.042549          51.117851
15       visual        W_up          8        0.05     -0.038564  0.521694 -1.867526  84.042549          51.188492
16       visual        W_up          7        0.20     -0.039047  0.521462 -1.868363  84.042549          51.392120
17       visual        W_up          6        0.15     -0.040530  0.519734 -1.867546  84.042549          51.387966
18       visual        W_up          5        0.30     -0.046065  0.514436 -1.868337  84.042549          51.279919
19       visual        W_up          4        0.10     -0.046719  0.513966 -1.868948  84.042549          51.138626
20       visual        W_up          3        0.10     -0.047318  0.513373 -1.868970  85.106377          51.130318
21       visual        W_up          2        0.20     -0.050690  0.509905 -1.868649  84.042549          51.101227
22       visual        W_up          1        0.10     -0.051216  0.509371 -1.868622  84.042549          51.059677
23       visual        W_up          0        0.35     -0.052313  0.508245 -1.868526  84.042549          51.055515
24         text        W_up         11        0.00     -0.052313  0.508245 -1.868526  84.042549          51.055515
25         text        W_up         10        0.05     -0.060959  0.501824 -1.875944  84.042549          51.117851
26         text        W_up          9        0.05     -0.064110  0.498561 -1.875569  85.106377          50.968246
27         text        W_up          8        0.40     -0.067955  0.489954 -1.859697  85.106377          49.667553
28         text        W_up          7        0.00     -0.067955  0.489954 -1.859697  85.106377          49.667553
29         text        W_up          6        0.15     -0.073768  0.485872 -1.865465  86.170212          48.728390
30         text        W_up          5        0.00     -0.073768  0.485872 -1.865465  86.170212          48.728390
31         text        W_up          4        0.30     -0.089160  0.468391 -1.858502  88.297867          46.438660
32         text        W_up          3        0.40     -0.099570  0.455636 -1.850688  87.234039          45.457943

2024-06-16 05:13:26,754 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207
4        visual        W_up         19        0.00      0.041445  0.604492 -1.876823  79.787231          51.421207
5        visual        W_up         18        0.30      0.027478  0.588392 -1.869712  82.978722          50.623333
6        visual        W_up         17        0.25      0.024647  0.585189 -1.868474  80.851059          50.199467
7        visual        W_up         16        0.10      0.019626  0.579654 -1.866758  81.914886          49.921043
8        visual        W_up         15        0.05      0.014317  0.574241 -1.866414  81.914886          49.829620
9        visual        W_up         14        0.25      0.005878  0.565525 -1.865491  84.042549          50.054020
10       visual        W_up         13        0.05      0.004716  0.564943 -1.867421  84.042549          50.211929
11       visual        W_up         12        0.30     -0.018952  0.541628 -1.868599  84.042549          50.644112
12       visual        W_up         11        0.05     -0.025269  0.536262 -1.871771  82.978722          50.752155
13       visual        W_up         10        0.10     -0.031650  0.529723 -1.871246  84.042549          51.026428
14       visual        W_up          9        0.15     -0.034220  0.526048 -1.867559  84.042549          51.117851
15       visual        W_up          8        0.05     -0.038564  0.521694 -1.867526  84.042549          51.188492
16       visual        W_up          7        0.20     -0.039047  0.521462 -1.868363  84.042549          51.392120
17       visual        W_up          6        0.15     -0.040530  0.519734 -1.867546  84.042549          51.387966
18       visual        W_up          5        0.30     -0.046065  0.514436 -1.868337  84.042549          51.279919
19       visual        W_up          4        0.10     -0.046719  0.513966 -1.868948  84.042549          51.138626
20       visual        W_up          3        0.10     -0.047318  0.513373 -1.868970  85.106377          51.130318
21       visual        W_up          2        0.20     -0.050690  0.509905 -1.868649  84.042549          51.101227
22       visual        W_up          1        0.10     -0.051216  0.509371 -1.868622  84.042549          51.059677
23       visual        W_up          0        0.35     -0.052313  0.508245 -1.868526  84.042549          51.055515
24         text        W_up         11        0.00     -0.052313  0.508245 -1.868526  84.042549          51.055515
25         text        W_up         10        0.05     -0.060959  0.501824 -1.875944  84.042549          51.117851
26         text        W_up          9        0.05     -0.064110  0.498561 -1.875569  85.106377          50.968246
27         text        W_up          8        0.40     -0.067955  0.489954 -1.859697  85.106377          49.667553
28         text        W_up          7        0.00     -0.067955  0.489954 -1.859697  85.106377          49.667553
29         text        W_up          6        0.15     -0.073768  0.485872 -1.865465  86.170212          48.728390
30         text        W_up          5        0.00     -0.073768  0.485872 -1.865465  86.170212          48.728390
31         text        W_up          4        0.30     -0.089160  0.468391 -1.858502  88.297867          46.438660
32         text        W_up          3        0.40     -0.099570  0.455636 -1.850688  87.234039          45.457943
33         text        W_up          2        0.05     -0.103519  0.453291 -1.856034  86.170212          45.474564

2024-06-16 05:14:01,625 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207
4        visual        W_up         19        0.00      0.041445  0.604492 -1.876823  79.787231          51.421207
5        visual        W_up         18        0.30      0.027478  0.588392 -1.869712  82.978722          50.623333
6        visual        W_up         17        0.25      0.024647  0.585189 -1.868474  80.851059          50.199467
7        visual        W_up         16        0.10      0.019626  0.579654 -1.866758  81.914886          49.921043
8        visual        W_up         15        0.05      0.014317  0.574241 -1.866414  81.914886          49.829620
9        visual        W_up         14        0.25      0.005878  0.565525 -1.865491  84.042549          50.054020
10       visual        W_up         13        0.05      0.004716  0.564943 -1.867421  84.042549          50.211929
11       visual        W_up         12        0.30     -0.018952  0.541628 -1.868599  84.042549          50.644112
12       visual        W_up         11        0.05     -0.025269  0.536262 -1.871771  82.978722          50.752155
13       visual        W_up         10        0.10     -0.031650  0.529723 -1.871246  84.042549          51.026428
14       visual        W_up          9        0.15     -0.034220  0.526048 -1.867559  84.042549          51.117851
15       visual        W_up          8        0.05     -0.038564  0.521694 -1.867526  84.042549          51.188492
16       visual        W_up          7        0.20     -0.039047  0.521462 -1.868363  84.042549          51.392120
17       visual        W_up          6        0.15     -0.040530  0.519734 -1.867546  84.042549          51.387966
18       visual        W_up          5        0.30     -0.046065  0.514436 -1.868337  84.042549          51.279919
19       visual        W_up          4        0.10     -0.046719  0.513966 -1.868948  84.042549          51.138626
20       visual        W_up          3        0.10     -0.047318  0.513373 -1.868970  85.106377          51.130318
21       visual        W_up          2        0.20     -0.050690  0.509905 -1.868649  84.042549          51.101227
22       visual        W_up          1        0.10     -0.051216  0.509371 -1.868622  84.042549          51.059677
23       visual        W_up          0        0.35     -0.052313  0.508245 -1.868526  84.042549          51.055515
24         text        W_up         11        0.00     -0.052313  0.508245 -1.868526  84.042549          51.055515
25         text        W_up         10        0.05     -0.060959  0.501824 -1.875944  84.042549          51.117851
26         text        W_up          9        0.05     -0.064110  0.498561 -1.875569  85.106377          50.968246
27         text        W_up          8        0.40     -0.067955  0.489954 -1.859697  85.106377          49.667553
28         text        W_up          7        0.00     -0.067955  0.489954 -1.859697  85.106377          49.667553
29         text        W_up          6        0.15     -0.073768  0.485872 -1.865465  86.170212          48.728390
30         text        W_up          5        0.00     -0.073768  0.485872 -1.865465  86.170212          48.728390
31         text        W_up          4        0.30     -0.089160  0.468391 -1.858502  88.297867          46.438660
32         text        W_up          3        0.40     -0.099570  0.455636 -1.850688  87.234039          45.457943
33         text        W_up          2        0.05     -0.103519  0.453291 -1.856034  86.170212          45.474564
34         text        W_up          1        0.05     -0.112692  0.446631 -1.864411  87.234039          45.046539

2024-06-16 05:14:36,925 | INFO | searchers.py:202 | run | Current best settings: 
     tower_type weight_type  layer_num  best_ratio  locoop_loss*   loss_id  loss_ood        acc  ood_patch_percent
step                                                                                                              
0        visual        W_up         23        0.40      0.063866  0.630032 -1.887220  80.851059          51.728718
1        visual        W_up         22        0.35      0.042949  0.605949 -1.876667  80.851059          52.040394
2        visual        W_up         21        0.00      0.042949  0.605949 -1.876667  80.851059          52.040394
3        visual        W_up         20        0.20      0.041445  0.604492 -1.876823  79.787231          51.421207
4        visual        W_up         19        0.00      0.041445  0.604492 -1.876823  79.787231          51.421207
5        visual        W_up         18        0.30      0.027478  0.588392 -1.869712  82.978722          50.623333
6        visual        W_up         17        0.25      0.024647  0.585189 -1.868474  80.851059          50.199467
7        visual        W_up         16        0.10      0.019626  0.579654 -1.866758  81.914886          49.921043
8        visual        W_up         15        0.05      0.014317  0.574241 -1.866414  81.914886          49.829620
9        visual        W_up         14        0.25      0.005878  0.565525 -1.865491  84.042549          50.054020
10       visual        W_up         13        0.05      0.004716  0.564943 -1.867421  84.042549          50.211929
11       visual        W_up         12        0.30     -0.018952  0.541628 -1.868599  84.042549          50.644112
12       visual        W_up         11        0.05     -0.025269  0.536262 -1.871771  82.978722          50.752155
13       visual        W_up         10        0.10     -0.031650  0.529723 -1.871246  84.042549          51.026428
14       visual        W_up          9        0.15     -0.034220  0.526048 -1.867559  84.042549          51.117851
15       visual        W_up          8        0.05     -0.038564  0.521694 -1.867526  84.042549          51.188492
16       visual        W_up          7        0.20     -0.039047  0.521462 -1.868363  84.042549          51.392120
17       visual        W_up          6        0.15     -0.040530  0.519734 -1.867546  84.042549          51.387966
18       visual        W_up          5        0.30     -0.046065  0.514436 -1.868337  84.042549          51.279919
19       visual        W_up          4        0.10     -0.046719  0.513966 -1.868948  84.042549          51.138626
20       visual        W_up          3        0.10     -0.047318  0.513373 -1.868970  85.106377          51.130318
21       visual        W_up          2        0.20     -0.050690  0.509905 -1.868649  84.042549          51.101227
22       visual        W_up          1        0.10     -0.051216  0.509371 -1.868622  84.042549          51.059677
23       visual        W_up          0        0.35     -0.052313  0.508245 -1.868526  84.042549          51.055515
24         text        W_up         11        0.00     -0.052313  0.508245 -1.868526  84.042549          51.055515
25         text        W_up         10        0.05     -0.060959  0.501824 -1.875944  84.042549          51.117851
26         text        W_up          9        0.05     -0.064110  0.498561 -1.875569  85.106377          50.968246
27         text        W_up          8        0.40     -0.067955  0.489954 -1.859697  85.106377          49.667553
28         text        W_up          7        0.00     -0.067955  0.489954 -1.859697  85.106377          49.667553
29         text        W_up          6        0.15     -0.073768  0.485872 -1.865465  86.170212          48.728390
30         text        W_up          5        0.00     -0.073768  0.485872 -1.865465  86.170212          48.728390
31         text        W_up          4        0.30     -0.089160  0.468391 -1.858502  88.297867          46.438660
32         text        W_up          3        0.40     -0.099570  0.455636 -1.850688  87.234039          45.457943
33         text        W_up          2        0.05     -0.103519  0.453291 -1.856034  86.170212          45.474564
34         text        W_up          1        0.05     -0.112692  0.446631 -1.864411  87.234039          45.046539
35         text        W_up          0        0.40     -0.120371  0.436842 -1.857375  86.170212          46.264126

2024-06-16 05:14:36,936 | INFO | searchers.py:208 | run | Best low rank configs: 
[['visual', 'W_up', 23, 0.4], ['visual', 'W_up', 22, 0.35], ['visual', 'W_up', 21, 0], ['visual', 'W_up', 20, 0.2], ['visual', 'W_up', 19, 0], ['visual', 'W_up', 18, 0.3], ['visual', 'W_up', 17, 0.25], ['visual', 'W_up', 16, 0.1], ['visual', 'W_up', 15, 0.05], ['visual', 'W_up', 14, 0.25], ['visual', 'W_up', 13, 0.05], ['visual', 'W_up', 12, 0.3], ['visual', 'W_up', 11, 0.05], ['visual', 'W_up', 10, 0.1], ['visual', 'W_up', 9, 0.15], ['visual', 'W_up', 8, 0.05], ['visual', 'W_up', 7, 0.2], ['visual', 'W_up', 6, 0.15], ['visual', 'W_up', 5, 0.3], ['visual', 'W_up', 4, 0.1], ['visual', 'W_up', 3, 0.1], ['visual', 'W_up', 2, 0.2], ['visual', 'W_up', 1, 0.1], ['visual', 'W_up', 0, 0.35], ['text', 'W_up', 11, 0], ['text', 'W_up', 10, 0.05], ['text', 'W_up', 9, 0.05], ['text', 'W_up', 8, 0.4], ['text', 'W_up', 7, 0], ['text', 'W_up', 6, 0.15], ['text', 'W_up', 5, 0], ['text', 'W_up', 4, 0.3], ['text', 'W_up', 3, 0.4], ['text', 'W_up', 2, 0.05], ['text', 'W_up', 1, 0.05], ['text', 'W_up', 0, 0.4]]
2024-06-16 05:14:36,936 | INFO | searchers.py:211 | run | ############ Done! Search time: 17m 3s ############
2024-06-16 05:14:36,937 | INFO | test_ood.py:29 | run_test_ood | ############ Test OOD Detection ############
2024-06-16 05:14:36,937 | INFO | test_ood.py:30 | run_test_ood | Loading CLIP model: openai/clip-vit-large-patch14...
2024-06-16 05:14:37,484 | INFO | test_ood.py:39 | run_test_ood | Applying SVD prune to 'small' weights...
2024-06-16 05:14:37,486 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.23.mlp.fc1] [rank(410)=round(full_rank(1024)*rank_ratio(0.4))]
2024-06-16 05:14:37,486 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.22.mlp.fc1] [rank(358)=round(full_rank(1024)*rank_ratio(0.35))]
2024-06-16 05:14:37,486 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.21.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.20.mlp.fc1] [rank(205)=round(full_rank(1024)*rank_ratio(0.2))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.19.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.18.mlp.fc1] [rank(307)=round(full_rank(1024)*rank_ratio(0.3))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.17.mlp.fc1] [rank(256)=round(full_rank(1024)*rank_ratio(0.25))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.16.mlp.fc1] [rank(102)=round(full_rank(1024)*rank_ratio(0.1))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.15.mlp.fc1] [rank(51)=round(full_rank(1024)*rank_ratio(0.05))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.14.mlp.fc1] [rank(256)=round(full_rank(1024)*rank_ratio(0.25))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.13.mlp.fc1] [rank(51)=round(full_rank(1024)*rank_ratio(0.05))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.12.mlp.fc1] [rank(307)=round(full_rank(1024)*rank_ratio(0.3))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.11.mlp.fc1] [rank(51)=round(full_rank(1024)*rank_ratio(0.05))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.10.mlp.fc1] [rank(102)=round(full_rank(1024)*rank_ratio(0.1))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.9.mlp.fc1] [rank(154)=round(full_rank(1024)*rank_ratio(0.15))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.8.mlp.fc1] [rank(51)=round(full_rank(1024)*rank_ratio(0.05))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.7.mlp.fc1] [rank(205)=round(full_rank(1024)*rank_ratio(0.2))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.6.mlp.fc1] [rank(154)=round(full_rank(1024)*rank_ratio(0.15))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.5.mlp.fc1] [rank(307)=round(full_rank(1024)*rank_ratio(0.3))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.4.mlp.fc1] [rank(102)=round(full_rank(1024)*rank_ratio(0.1))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.3.mlp.fc1] [rank(102)=round(full_rank(1024)*rank_ratio(0.1))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.2.mlp.fc1] [rank(205)=round(full_rank(1024)*rank_ratio(0.2))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.1.mlp.fc1] [rank(102)=round(full_rank(1024)*rank_ratio(0.1))]
2024-06-16 05:14:37,487 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.0.mlp.fc1] [rank(358)=round(full_rank(1024)*rank_ratio(0.35))]
2024-06-16 05:14:37,488 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.11.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 05:14:37,488 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.10.mlp.fc1] [rank(38)=round(full_rank(768)*rank_ratio(0.05))]
2024-06-16 05:14:37,488 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.9.mlp.fc1] [rank(38)=round(full_rank(768)*rank_ratio(0.05))]
2024-06-16 05:14:37,488 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.8.mlp.fc1] [rank(307)=round(full_rank(768)*rank_ratio(0.4))]
2024-06-16 05:14:37,488 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.7.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 05:14:37,488 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.6.mlp.fc1] [rank(115)=round(full_rank(768)*rank_ratio(0.15))]
2024-06-16 05:14:37,488 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.5.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 05:14:37,488 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.4.mlp.fc1] [rank(230)=round(full_rank(768)*rank_ratio(0.3))]
2024-06-16 05:14:37,488 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.3.mlp.fc1] [rank(307)=round(full_rank(768)*rank_ratio(0.4))]
2024-06-16 05:14:37,488 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.2.mlp.fc1] [rank(38)=round(full_rank(768)*rank_ratio(0.05))]
2024-06-16 05:14:37,488 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.1.mlp.fc1] [rank(38)=round(full_rank(768)*rank_ratio(0.05))]
2024-06-16 05:14:37,488 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.0.mlp.fc1] [rank(307)=round(full_rank(768)*rank_ratio(0.4))]
2024-06-16 05:14:37,488 | INFO | model_hub.py:194 | to_target_modules | lora_settings -> target_modules: 
{
    "vision_model.encoder.layers.23.mlp.fc1": 410,
    "vision_model.encoder.layers.22.mlp.fc1": 358,
    "vision_model.encoder.layers.21.mlp.fc1": 0,
    "vision_model.encoder.layers.20.mlp.fc1": 205,
    "vision_model.encoder.layers.19.mlp.fc1": 0,
    "vision_model.encoder.layers.18.mlp.fc1": 307,
    "vision_model.encoder.layers.17.mlp.fc1": 256,
    "vision_model.encoder.layers.16.mlp.fc1": 102,
    "vision_model.encoder.layers.15.mlp.fc1": 51,
    "vision_model.encoder.layers.14.mlp.fc1": 256,
    "vision_model.encoder.layers.13.mlp.fc1": 51,
    "vision_model.encoder.layers.12.mlp.fc1": 307,
    "vision_model.encoder.layers.11.mlp.fc1": 51,
    "vision_model.encoder.layers.10.mlp.fc1": 102,
    "vision_model.encoder.layers.9.mlp.fc1": 154,
    "vision_model.encoder.layers.8.mlp.fc1": 51,
    "vision_model.encoder.layers.7.mlp.fc1": 205,
    "vision_model.encoder.layers.6.mlp.fc1": 154,
    "vision_model.encoder.layers.5.mlp.fc1": 307,
    "vision_model.encoder.layers.4.mlp.fc1": 102,
    "vision_model.encoder.layers.3.mlp.fc1": 102,
    "vision_model.encoder.layers.2.mlp.fc1": 205,
    "vision_model.encoder.layers.1.mlp.fc1": 102,
    "vision_model.encoder.layers.0.mlp.fc1": 358,
    "text_model.encoder.layers.11.mlp.fc1": 0,
    "text_model.encoder.layers.10.mlp.fc1": 38,
    "text_model.encoder.layers.9.mlp.fc1": 38,
    "text_model.encoder.layers.8.mlp.fc1": 307,
    "text_model.encoder.layers.7.mlp.fc1": 0,
    "text_model.encoder.layers.6.mlp.fc1": 115,
    "text_model.encoder.layers.5.mlp.fc1": 0,
    "text_model.encoder.layers.4.mlp.fc1": 230,
    "text_model.encoder.layers.3.mlp.fc1": 307,
    "text_model.encoder.layers.2.mlp.fc1": 38,
    "text_model.encoder.layers.1.mlp.fc1": 38,
    "text_model.encoder.layers.0.mlp.fc1": 307
}
2024-06-16 05:14:37,506 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.23.mlp.fc1] [Rank: 410]
2024-06-16 05:14:37,521 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.22.mlp.fc1] [Rank: 358]
2024-06-16 05:14:37,521 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.21.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:14:37,530 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.20.mlp.fc1] [Rank: 205]
2024-06-16 05:14:37,530 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.19.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:14:37,543 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.18.mlp.fc1] [Rank: 307]
2024-06-16 05:14:37,554 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.17.mlp.fc1] [Rank: 256]
2024-06-16 05:14:37,558 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.16.mlp.fc1] [Rank: 102]
2024-06-16 05:14:37,561 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.15.mlp.fc1] [Rank: 51]
2024-06-16 05:14:37,572 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.14.mlp.fc1] [Rank: 256]
2024-06-16 05:14:37,575 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.13.mlp.fc1] [Rank: 51]
2024-06-16 05:14:37,587 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.12.mlp.fc1] [Rank: 307]
2024-06-16 05:14:37,590 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.11.mlp.fc1] [Rank: 51]
2024-06-16 05:14:37,594 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.10.mlp.fc1] [Rank: 102]
2024-06-16 05:14:37,601 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.9.mlp.fc1] [Rank: 154]
2024-06-16 05:14:37,603 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.8.mlp.fc1] [Rank: 51]
2024-06-16 05:14:37,612 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.7.mlp.fc1] [Rank: 205]
2024-06-16 05:14:37,619 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.6.mlp.fc1] [Rank: 154]
2024-06-16 05:14:37,632 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.5.mlp.fc1] [Rank: 307]
2024-06-16 05:14:37,638 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.4.mlp.fc1] [Rank: 102]
2024-06-16 05:14:37,643 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.3.mlp.fc1] [Rank: 102]
2024-06-16 05:14:37,652 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.2.mlp.fc1] [Rank: 205]
2024-06-16 05:14:37,656 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.1.mlp.fc1] [Rank: 102]
2024-06-16 05:14:37,671 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.0.mlp.fc1] [Rank: 358]
2024-06-16 05:14:37,671 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.11.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:14:37,673 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.10.mlp.fc1] [Rank: 38]
2024-06-16 05:14:37,674 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.9.mlp.fc1] [Rank: 38]
2024-06-16 05:14:37,684 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.8.mlp.fc1] [Rank: 307]
2024-06-16 05:14:37,684 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.7.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:14:37,688 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.6.mlp.fc1] [Rank: 115]
2024-06-16 05:14:37,688 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.5.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:14:37,695 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.4.mlp.fc1] [Rank: 230]
2024-06-16 05:14:37,705 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.3.mlp.fc1] [Rank: 307]
2024-06-16 05:14:37,706 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.2.mlp.fc1] [Rank: 38]
2024-06-16 05:14:37,708 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.1.mlp.fc1] [Rank: 38]
2024-06-16 05:14:37,718 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.0.mlp.fc1] [Rank: 307]
2024-06-16 05:14:39,199 | INFO | model.py:192 | svd_init | SVD initialized for adapter 'default'.
2024-06-16 05:14:39,243 | INFO | test_ood.py:63 | run_test_ood | ############ ID dataset: ID_VOC, test set: 906 images ############
2024-06-16 05:14:39,243 | INFO | test_ood.py:65 | run_test_ood | Computing scores for ID_VOC...
2024-06-16 05:14:50,737 | INFO | model_hub.py:304 | compute_scores | Took 11.49 s to run.
2024-06-16 05:14:50,773 | INFO | test_ood.py:78 | run_test_ood | ############ OOD dataset: OOD_iNaturalist, test set: 10000 images ############
2024-06-16 05:14:50,773 | INFO | test_ood.py:80 | run_test_ood | Computing scores for OOD_iNaturalist...
2024-06-16 05:16:36,066 | INFO | model_hub.py:304 | compute_scores | Took 105.29 s to run.
2024-06-16 05:16:36,124 | INFO | metrics.py:55 | print_metrics | OOD_iNaturalist - mcm_score
2024-06-16 05:16:36,124 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:16:36,124 | INFO | metrics.py:57 | print_metrics | & 26.05 & 96.23 & 86.48
2024-06-16 05:16:36,968 | INFO | metrics.py:55 | print_metrics | OOD_iNaturalist - gl_mcm_score
2024-06-16 05:16:36,969 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:16:36,969 | INFO | metrics.py:57 | print_metrics | & 9.62 & 97.51 & 90.61
2024-06-16 05:16:37,417 | INFO | test_ood.py:78 | run_test_ood | ############ OOD dataset: OOD_Sun, test set: 10000 images ############
2024-06-16 05:16:37,417 | INFO | test_ood.py:80 | run_test_ood | Computing scores for OOD_Sun...
2024-06-16 05:18:23,342 | INFO | model_hub.py:304 | compute_scores | Took 105.92 s to run.
2024-06-16 05:18:23,379 | INFO | metrics.py:55 | print_metrics | OOD_Sun - mcm_score
2024-06-16 05:18:23,379 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:18:23,379 | INFO | metrics.py:57 | print_metrics | & 35.97 & 94.20 & 74.51
2024-06-16 05:18:23,998 | INFO | metrics.py:55 | print_metrics | OOD_Sun - gl_mcm_score
2024-06-16 05:18:23,999 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:18:23,999 | INFO | metrics.py:57 | print_metrics | & 27.75 & 94.73 & 77.84
2024-06-16 05:18:24,450 | INFO | test_ood.py:78 | run_test_ood | ############ OOD dataset: OOD_Places, test set: 10000 images ############
2024-06-16 05:18:24,450 | INFO | test_ood.py:80 | run_test_ood | Computing scores for OOD_Places...
2024-06-16 05:20:07,022 | INFO | model_hub.py:304 | compute_scores | Took 102.57 s to run.
2024-06-16 05:20:07,064 | INFO | metrics.py:55 | print_metrics | OOD_Places - mcm_score
2024-06-16 05:20:07,064 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:20:07,064 | INFO | metrics.py:57 | print_metrics | & 33.10 & 92.45 & 58.29
2024-06-16 05:20:07,618 | INFO | metrics.py:55 | print_metrics | OOD_Places - gl_mcm_score
2024-06-16 05:20:07,618 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:20:07,618 | INFO | metrics.py:57 | print_metrics | & 28.85 & 92.99 & 62.44
2024-06-16 05:20:08,030 | INFO | test_ood.py:78 | run_test_ood | ############ OOD dataset: OOD_Texture, test set: 5640 images ############
2024-06-16 05:20:08,030 | INFO | test_ood.py:80 | run_test_ood | Computing scores for OOD_Texture...
2024-06-16 05:21:06,512 | INFO | model_hub.py:304 | compute_scores | Took 58.48 s to run.
2024-06-16 05:21:06,541 | INFO | metrics.py:55 | print_metrics | OOD_Texture - mcm_score
2024-06-16 05:21:06,541 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:21:06,541 | INFO | metrics.py:57 | print_metrics | & 50.32 & 91.91 & 76.74
2024-06-16 05:21:07,083 | INFO | metrics.py:55 | print_metrics | OOD_Texture - gl_mcm_score
2024-06-16 05:21:07,083 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:21:07,083 | INFO | metrics.py:57 | print_metrics | & 41.77 & 92.40 & 75.58
2024-06-16 05:21:07,509 | INFO | test_ood.py:78 | run_test_ood | ############ OOD dataset: OOD_ImageNet22K, test set: 18335 images ############
2024-06-16 05:21:07,509 | INFO | test_ood.py:80 | run_test_ood | Computing scores for OOD_ImageNet22K...
2024-06-16 05:24:10,268 | INFO | model_hub.py:304 | compute_scores | Took 182.76 s to run.
2024-06-16 05:24:10,336 | INFO | metrics.py:55 | print_metrics | OOD_ImageNet22K - mcm_score
2024-06-16 05:24:10,336 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:24:10,336 | INFO | metrics.py:57 | print_metrics | & 57.69 & 92.02 & 66.86
2024-06-16 05:24:10,887 | INFO | metrics.py:55 | print_metrics | OOD_ImageNet22K - gl_mcm_score
2024-06-16 05:24:10,888 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:24:10,888 | INFO | metrics.py:57 | print_metrics | & 39.42 & 93.98 & 72.30
2024-06-16 05:24:11,385 | INFO | test_ood.py:78 | run_test_ood | ############ OOD dataset: OOD_COCO, test set: 1000 images ############
2024-06-16 05:24:11,385 | INFO | test_ood.py:80 | run_test_ood | Computing scores for OOD_COCO...
2024-06-16 05:24:24,455 | INFO | model_hub.py:304 | compute_scores | Took 13.07 s to run.
2024-06-16 05:24:24,468 | INFO | metrics.py:55 | print_metrics | OOD_COCO - mcm_score
2024-06-16 05:24:24,468 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:24:24,469 | INFO | metrics.py:57 | print_metrics | & 52.30 & 90.67 & 90.73
2024-06-16 05:24:24,892 | INFO | metrics.py:55 | print_metrics | OOD_COCO - gl_mcm_score
2024-06-16 05:24:24,892 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:24:24,892 | INFO | metrics.py:57 | print_metrics | & 39.30 & 92.38 & 92.42
2024-06-16 05:24:25,275 | INFO | test_ood.py:98 | run_test_ood | ############ Metrics for mcm_score ############
2024-06-16 05:24:25,278 | INFO | metrics.py:76 | save_metrics | ############ Mean metrics ############
2024-06-16 05:24:25,279 | INFO | metrics.py:77 | save_metrics | 
                 FPR95  AUROC  AUPR
OOD dataset                        
OOD_iNaturalist  26.05  96.23 86.48
OOD_Sun          35.97  94.20 74.51
OOD_Places       33.10  92.45 58.29
OOD_Texture      50.32  91.91 76.74
OOD_ImageNet22K  57.69  92.02 66.86
OOD_COCO         52.30  90.67 90.73
Avg              42.57  92.91 75.60
2024-06-16 05:24:25,279 | INFO | metrics.py:78 | save_metrics | Metrics saved to ./results/training-free/clip_large/ID_VOC/SeTAR/metrics_mcm_score_test.csv
2024-06-16 05:24:25,280 | INFO | metrics.py:87 | save_cutoffs | ############ Thresholds Cut-off ############
2024-06-16 05:24:25,281 | INFO | metrics.py:88 | save_cutoffs | 
    OOD dataset   Cutoff
OOD_iNaturalist 0.073618
        OOD_Sun 0.073618
     OOD_Places 0.073619
    OOD_Texture 0.073619
OOD_ImageNet22K 0.073618
       OOD_COCO 0.073620
2024-06-16 05:24:25,281 | INFO | metrics.py:89 | save_cutoffs | Thresholds cutoff saved to ./results/training-free/clip_large/ID_VOC/SeTAR/cutoffs_mcm_score_test.csv
2024-06-16 05:24:25,281 | INFO | test_ood.py:98 | run_test_ood | ############ Metrics for gl_mcm_score ############
2024-06-16 05:24:25,283 | INFO | metrics.py:76 | save_metrics | ############ Mean metrics ############
2024-06-16 05:24:25,284 | INFO | metrics.py:77 | save_metrics | 
                 FPR95  AUROC  AUPR
OOD dataset                        
OOD_iNaturalist   9.62  97.51 90.61
OOD_Sun          27.75  94.73 77.84
OOD_Places       28.85  92.99 62.44
OOD_Texture      41.77  92.40 75.58
OOD_ImageNet22K  39.42  93.98 72.30
OOD_COCO         39.30  92.38 92.42
Avg              31.12  94.00 78.53
2024-06-16 05:24:25,284 | INFO | metrics.py:78 | save_metrics | Metrics saved to ./results/training-free/clip_large/ID_VOC/SeTAR/metrics_gl_mcm_score_test.csv
2024-06-16 05:24:25,284 | INFO | metrics.py:87 | save_cutoffs | ############ Thresholds Cut-off ############
2024-06-16 05:24:25,285 | INFO | metrics.py:88 | save_cutoffs | 
    OOD dataset   Cutoff
OOD_iNaturalist 0.149756
        OOD_Sun 0.149757
     OOD_Places 0.149757
    OOD_Texture 0.149757
OOD_ImageNet22K 0.149756
       OOD_COCO 0.149757
2024-06-16 05:24:25,285 | INFO | metrics.py:89 | save_cutoffs | Thresholds cutoff saved to ./results/training-free/clip_large/ID_VOC/SeTAR/cutoffs_gl_mcm_score_test.csv
2024-06-16 05:24:25,285 | INFO | test_ood.py:107 | run_test_ood | ############ Done! Test time: 9m 48s ############
2024-06-16 05:24:25,285 | INFO | test_classify.py:121 | run_test_classify | ############ Test Classification ############
2024-06-16 05:24:25,286 | INFO | test_classify.py:122 | run_test_classify | Loading CLIP model: openai/clip-vit-large-patch14...
2024-06-16 05:24:25,843 | INFO | test_classify.py:131 | run_test_classify | Applying SVD prune to 'small' weights...
2024-06-16 05:24:25,847 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.23.mlp.fc1] [rank(410)=round(full_rank(1024)*rank_ratio(0.4))]
2024-06-16 05:24:25,847 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.22.mlp.fc1] [rank(358)=round(full_rank(1024)*rank_ratio(0.35))]
2024-06-16 05:24:25,847 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.21.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 05:24:25,847 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.20.mlp.fc1] [rank(205)=round(full_rank(1024)*rank_ratio(0.2))]
2024-06-16 05:24:25,847 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.19.mlp.fc1] [rank(0)=round(full_rank(1024)*rank_ratio(0))]
2024-06-16 05:24:25,847 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.18.mlp.fc1] [rank(307)=round(full_rank(1024)*rank_ratio(0.3))]
2024-06-16 05:24:25,847 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.17.mlp.fc1] [rank(256)=round(full_rank(1024)*rank_ratio(0.25))]
2024-06-16 05:24:25,847 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.16.mlp.fc1] [rank(102)=round(full_rank(1024)*rank_ratio(0.1))]
2024-06-16 05:24:25,847 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.15.mlp.fc1] [rank(51)=round(full_rank(1024)*rank_ratio(0.05))]
2024-06-16 05:24:25,847 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.14.mlp.fc1] [rank(256)=round(full_rank(1024)*rank_ratio(0.25))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.13.mlp.fc1] [rank(51)=round(full_rank(1024)*rank_ratio(0.05))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.12.mlp.fc1] [rank(307)=round(full_rank(1024)*rank_ratio(0.3))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.11.mlp.fc1] [rank(51)=round(full_rank(1024)*rank_ratio(0.05))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.10.mlp.fc1] [rank(102)=round(full_rank(1024)*rank_ratio(0.1))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.9.mlp.fc1] [rank(154)=round(full_rank(1024)*rank_ratio(0.15))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.8.mlp.fc1] [rank(51)=round(full_rank(1024)*rank_ratio(0.05))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.7.mlp.fc1] [rank(205)=round(full_rank(1024)*rank_ratio(0.2))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.6.mlp.fc1] [rank(154)=round(full_rank(1024)*rank_ratio(0.15))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.5.mlp.fc1] [rank(307)=round(full_rank(1024)*rank_ratio(0.3))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.4.mlp.fc1] [rank(102)=round(full_rank(1024)*rank_ratio(0.1))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.3.mlp.fc1] [rank(102)=round(full_rank(1024)*rank_ratio(0.1))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.2.mlp.fc1] [rank(205)=round(full_rank(1024)*rank_ratio(0.2))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.1.mlp.fc1] [rank(102)=round(full_rank(1024)*rank_ratio(0.1))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.0.mlp.fc1] [rank(358)=round(full_rank(1024)*rank_ratio(0.35))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.11.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.10.mlp.fc1] [rank(38)=round(full_rank(768)*rank_ratio(0.05))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.9.mlp.fc1] [rank(38)=round(full_rank(768)*rank_ratio(0.05))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.8.mlp.fc1] [rank(307)=round(full_rank(768)*rank_ratio(0.4))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.7.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.6.mlp.fc1] [rank(115)=round(full_rank(768)*rank_ratio(0.15))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.5.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 05:24:25,848 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.4.mlp.fc1] [rank(230)=round(full_rank(768)*rank_ratio(0.3))]
2024-06-16 05:24:25,849 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.3.mlp.fc1] [rank(307)=round(full_rank(768)*rank_ratio(0.4))]
2024-06-16 05:24:25,849 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.2.mlp.fc1] [rank(38)=round(full_rank(768)*rank_ratio(0.05))]
2024-06-16 05:24:25,849 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.1.mlp.fc1] [rank(38)=round(full_rank(768)*rank_ratio(0.05))]
2024-06-16 05:24:25,849 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.0.mlp.fc1] [rank(307)=round(full_rank(768)*rank_ratio(0.4))]
2024-06-16 05:24:25,849 | INFO | model_hub.py:194 | to_target_modules | lora_settings -> target_modules: 
{
    "vision_model.encoder.layers.23.mlp.fc1": 410,
    "vision_model.encoder.layers.22.mlp.fc1": 358,
    "vision_model.encoder.layers.21.mlp.fc1": 0,
    "vision_model.encoder.layers.20.mlp.fc1": 205,
    "vision_model.encoder.layers.19.mlp.fc1": 0,
    "vision_model.encoder.layers.18.mlp.fc1": 307,
    "vision_model.encoder.layers.17.mlp.fc1": 256,
    "vision_model.encoder.layers.16.mlp.fc1": 102,
    "vision_model.encoder.layers.15.mlp.fc1": 51,
    "vision_model.encoder.layers.14.mlp.fc1": 256,
    "vision_model.encoder.layers.13.mlp.fc1": 51,
    "vision_model.encoder.layers.12.mlp.fc1": 307,
    "vision_model.encoder.layers.11.mlp.fc1": 51,
    "vision_model.encoder.layers.10.mlp.fc1": 102,
    "vision_model.encoder.layers.9.mlp.fc1": 154,
    "vision_model.encoder.layers.8.mlp.fc1": 51,
    "vision_model.encoder.layers.7.mlp.fc1": 205,
    "vision_model.encoder.layers.6.mlp.fc1": 154,
    "vision_model.encoder.layers.5.mlp.fc1": 307,
    "vision_model.encoder.layers.4.mlp.fc1": 102,
    "vision_model.encoder.layers.3.mlp.fc1": 102,
    "vision_model.encoder.layers.2.mlp.fc1": 205,
    "vision_model.encoder.layers.1.mlp.fc1": 102,
    "vision_model.encoder.layers.0.mlp.fc1": 358,
    "text_model.encoder.layers.11.mlp.fc1": 0,
    "text_model.encoder.layers.10.mlp.fc1": 38,
    "text_model.encoder.layers.9.mlp.fc1": 38,
    "text_model.encoder.layers.8.mlp.fc1": 307,
    "text_model.encoder.layers.7.mlp.fc1": 0,
    "text_model.encoder.layers.6.mlp.fc1": 115,
    "text_model.encoder.layers.5.mlp.fc1": 0,
    "text_model.encoder.layers.4.mlp.fc1": 230,
    "text_model.encoder.layers.3.mlp.fc1": 307,
    "text_model.encoder.layers.2.mlp.fc1": 38,
    "text_model.encoder.layers.1.mlp.fc1": 38,
    "text_model.encoder.layers.0.mlp.fc1": 307
}
2024-06-16 05:24:25,871 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.23.mlp.fc1] [Rank: 410]
2024-06-16 05:24:25,890 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.22.mlp.fc1] [Rank: 358]
2024-06-16 05:24:25,890 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.21.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:24:25,901 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.20.mlp.fc1] [Rank: 205]
2024-06-16 05:24:25,901 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.19.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:24:25,918 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.18.mlp.fc1] [Rank: 307]
2024-06-16 05:24:25,931 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.17.mlp.fc1] [Rank: 256]
2024-06-16 05:24:25,937 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.16.mlp.fc1] [Rank: 102]
2024-06-16 05:24:25,941 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.15.mlp.fc1] [Rank: 51]
2024-06-16 05:24:25,953 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.14.mlp.fc1] [Rank: 256]
2024-06-16 05:24:25,957 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.13.mlp.fc1] [Rank: 51]
2024-06-16 05:24:25,970 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.12.mlp.fc1] [Rank: 307]
2024-06-16 05:24:25,973 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.11.mlp.fc1] [Rank: 51]
2024-06-16 05:24:25,977 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.10.mlp.fc1] [Rank: 102]
2024-06-16 05:24:25,984 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.9.mlp.fc1] [Rank: 154]
2024-06-16 05:24:25,986 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.8.mlp.fc1] [Rank: 51]
2024-06-16 05:24:25,997 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.7.mlp.fc1] [Rank: 205]
2024-06-16 05:24:26,005 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.6.mlp.fc1] [Rank: 154]
2024-06-16 05:24:26,043 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.5.mlp.fc1] [Rank: 307]
2024-06-16 05:24:26,077 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.4.mlp.fc1] [Rank: 102]
2024-06-16 05:24:26,083 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.3.mlp.fc1] [Rank: 102]
2024-06-16 05:24:26,106 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.2.mlp.fc1] [Rank: 205]
2024-06-16 05:24:26,113 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.1.mlp.fc1] [Rank: 102]
2024-06-16 05:24:26,138 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.0.mlp.fc1] [Rank: 358]
2024-06-16 05:24:26,138 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.11.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:24:26,141 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.10.mlp.fc1] [Rank: 38]
2024-06-16 05:24:26,143 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.9.mlp.fc1] [Rank: 38]
2024-06-16 05:24:26,159 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.8.mlp.fc1] [Rank: 307]
2024-06-16 05:24:26,159 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.7.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:24:26,164 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.6.mlp.fc1] [Rank: 115]
2024-06-16 05:24:26,164 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.5.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:24:26,171 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.4.mlp.fc1] [Rank: 230]
2024-06-16 05:24:26,181 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.3.mlp.fc1] [Rank: 307]
2024-06-16 05:24:26,183 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.2.mlp.fc1] [Rank: 38]
2024-06-16 05:24:26,185 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.1.mlp.fc1] [Rank: 38]
2024-06-16 05:24:26,195 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.0.mlp.fc1] [Rank: 307]
2024-06-16 05:24:27,689 | INFO | model.py:192 | svd_init | SVD initialized for adapter 'default'.
2024-06-16 05:24:27,727 | INFO | test_classify.py:151 | run_test_classify | ############ ID_ImageNet1K ############
2024-06-16 05:32:57,477 | INFO | test_classify.py:161 | run_test_classify | Accuracy on ID_ImageNet1K: 68.20
2024-06-16 05:32:57,477 | INFO | test_classify.py:151 | run_test_classify | ############ OOD_Sun ############
2024-06-16 05:34:42,168 | INFO | test_classify.py:161 | run_test_classify | Accuracy on OOD_Sun: 74.55
2024-06-16 05:34:42,168 | INFO | test_classify.py:151 | run_test_classify | ############ OOD_Places ############
2024-06-16 05:36:23,700 | INFO | test_classify.py:161 | run_test_classify | Accuracy on OOD_Places: 46.47
2024-06-16 05:36:23,700 | INFO | test_classify.py:151 | run_test_classify | ############ OOD_Texture ############
2024-06-16 05:37:22,229 | INFO | test_classify.py:161 | run_test_classify | Accuracy on OOD_Texture: 50.51
2024-06-16 05:37:22,229 | INFO | test_classify.py:164 | run_test_classify | ############ Summary ############
2024-06-16 05:37:22,229 | INFO | test_classify.py:166 | run_test_classify | Accuracy on ID_ImageNet1K: 68.20
2024-06-16 05:37:22,229 | INFO | test_classify.py:166 | run_test_classify | Accuracy on OOD_Sun: 74.55
2024-06-16 05:37:22,229 | INFO | test_classify.py:166 | run_test_classify | Accuracy on OOD_Places: 46.47
2024-06-16 05:37:22,229 | INFO | test_classify.py:166 | run_test_classify | Accuracy on OOD_Texture: 50.51
