2024-06-16 05:20:57,276 | INFO | test_ood.py:29 | run_test_ood | ############ Test OOD Detection ############
2024-06-16 05:20:57,276 | INFO | test_ood.py:30 | run_test_ood | Loading CLIP model: openai/clip-vit-base-patch16...
2024-06-16 05:20:57,775 | INFO | test_ood.py:39 | run_test_ood | Applying SVD prune to 'small' weights...
2024-06-16 05:20:57,778 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.11.mlp.fc1] [rank(115)=round(full_rank(768)*rank_ratio(0.15))]
2024-06-16 05:20:57,778 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.10.mlp.fc1] [rank(115)=round(full_rank(768)*rank_ratio(0.15))]
2024-06-16 05:20:57,778 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.9.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 05:20:57,778 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.8.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 05:20:57,778 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.7.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 05:20:57,778 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.6.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 05:20:57,778 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.5.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 05:20:57,778 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.4.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 05:20:57,778 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.3.mlp.fc1] [rank(38)=round(full_rank(768)*rank_ratio(0.05))]
2024-06-16 05:20:57,778 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.2.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 05:20:57,778 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.1.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 05:20:57,778 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.0.mlp.fc1] [rank(115)=round(full_rank(768)*rank_ratio(0.15))]
2024-06-16 05:20:57,778 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.11.mlp.fc1] [rank(0)=round(full_rank(512)*rank_ratio(0))]
2024-06-16 05:20:57,778 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.10.mlp.fc1] [rank(0)=round(full_rank(512)*rank_ratio(0))]
2024-06-16 05:20:57,778 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.9.mlp.fc1] [rank(0)=round(full_rank(512)*rank_ratio(0))]
2024-06-16 05:20:57,778 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.8.mlp.fc1] [rank(0)=round(full_rank(512)*rank_ratio(0))]
2024-06-16 05:20:57,778 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.7.mlp.fc1] [rank(0)=round(full_rank(512)*rank_ratio(0))]
2024-06-16 05:20:57,778 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.6.mlp.fc1] [rank(128)=round(full_rank(512)*rank_ratio(0.25))]
2024-06-16 05:20:57,778 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.5.mlp.fc1] [rank(51)=round(full_rank(512)*rank_ratio(0.1))]
2024-06-16 05:20:57,779 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.4.mlp.fc1] [rank(102)=round(full_rank(512)*rank_ratio(0.2))]
2024-06-16 05:20:57,779 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.3.mlp.fc1] [rank(26)=round(full_rank(512)*rank_ratio(0.05))]
2024-06-16 05:20:57,779 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.2.mlp.fc1] [rank(26)=round(full_rank(512)*rank_ratio(0.05))]
2024-06-16 05:20:57,779 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.1.mlp.fc1] [rank(0)=round(full_rank(512)*rank_ratio(0))]
2024-06-16 05:20:57,779 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.0.mlp.fc1] [rank(102)=round(full_rank(512)*rank_ratio(0.2))]
2024-06-16 05:20:57,779 | INFO | model_hub.py:194 | to_target_modules | lora_settings -> target_modules: 
{
    "vision_model.encoder.layers.11.mlp.fc1": 115,
    "vision_model.encoder.layers.10.mlp.fc1": 115,
    "vision_model.encoder.layers.9.mlp.fc1": 0,
    "vision_model.encoder.layers.8.mlp.fc1": 0,
    "vision_model.encoder.layers.7.mlp.fc1": 0,
    "vision_model.encoder.layers.6.mlp.fc1": 0,
    "vision_model.encoder.layers.5.mlp.fc1": 0,
    "vision_model.encoder.layers.4.mlp.fc1": 0,
    "vision_model.encoder.layers.3.mlp.fc1": 38,
    "vision_model.encoder.layers.2.mlp.fc1": 0,
    "vision_model.encoder.layers.1.mlp.fc1": 0,
    "vision_model.encoder.layers.0.mlp.fc1": 115,
    "text_model.encoder.layers.11.mlp.fc1": 0,
    "text_model.encoder.layers.10.mlp.fc1": 0,
    "text_model.encoder.layers.9.mlp.fc1": 0,
    "text_model.encoder.layers.8.mlp.fc1": 0,
    "text_model.encoder.layers.7.mlp.fc1": 0,
    "text_model.encoder.layers.6.mlp.fc1": 128,
    "text_model.encoder.layers.5.mlp.fc1": 51,
    "text_model.encoder.layers.4.mlp.fc1": 102,
    "text_model.encoder.layers.3.mlp.fc1": 26,
    "text_model.encoder.layers.2.mlp.fc1": 26,
    "text_model.encoder.layers.1.mlp.fc1": 0,
    "text_model.encoder.layers.0.mlp.fc1": 102
}
2024-06-16 05:20:57,784 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.11.mlp.fc1] [Rank: 115]
2024-06-16 05:20:57,788 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.10.mlp.fc1] [Rank: 115]
2024-06-16 05:20:57,788 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.9.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:20:57,788 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.8.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:20:57,788 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.7.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:20:57,789 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.6.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:20:57,789 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.5.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:20:57,789 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.4.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:20:57,790 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.3.mlp.fc1] [Rank: 38]
2024-06-16 05:20:57,790 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.2.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:20:57,790 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.1.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:20:57,794 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.0.mlp.fc1] [Rank: 115]
2024-06-16 05:20:57,794 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.11.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:20:57,794 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.10.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:20:57,794 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.9.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:20:57,795 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.8.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:20:57,795 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.7.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:20:57,798 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.6.mlp.fc1] [Rank: 128]
2024-06-16 05:20:57,799 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.5.mlp.fc1] [Rank: 51]
2024-06-16 05:20:57,802 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.4.mlp.fc1] [Rank: 102]
2024-06-16 05:20:57,803 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.3.mlp.fc1] [Rank: 26]
2024-06-16 05:20:57,804 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.2.mlp.fc1] [Rank: 26]
2024-06-16 05:20:57,804 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.1.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:20:57,807 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.0.mlp.fc1] [Rank: 102]
2024-06-16 05:20:58,048 | INFO | model.py:192 | svd_init | SVD initialized for adapter 'default'.
2024-06-16 05:20:58,208 | INFO | test_ood.py:63 | run_test_ood | ############ ID dataset: ID_ImageNet1K, test set: 50000 images ############
2024-06-16 05:20:58,208 | INFO | test_ood.py:65 | run_test_ood | Computing scores for ID_ImageNet1K...
2024-06-16 05:23:16,403 | INFO | model_hub.py:304 | compute_scores | Took 138.19 s to run.
2024-06-16 05:23:16,574 | INFO | test_ood.py:78 | run_test_ood | ############ OOD dataset: OOD_iNaturalist, test set: 10000 images ############
2024-06-16 05:23:16,575 | INFO | test_ood.py:80 | run_test_ood | Computing scores for OOD_iNaturalist...
2024-06-16 05:23:49,537 | INFO | model_hub.py:304 | compute_scores | Took 32.96 s to run.
2024-06-16 05:23:49,608 | INFO | metrics.py:55 | print_metrics | OOD_iNaturalist - mcm_score
2024-06-16 05:23:49,608 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:23:49,608 | INFO | metrics.py:57 | print_metrics | & 26.92 & 94.67 & 98.81
2024-06-16 05:23:50,359 | INFO | metrics.py:55 | print_metrics | OOD_iNaturalist - gl_mcm_score
2024-06-16 05:23:50,359 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:23:50,359 | INFO | metrics.py:57 | print_metrics | & 13.36 & 96.92 & 99.28
2024-06-16 05:23:51,159 | INFO | test_ood.py:78 | run_test_ood | ############ OOD dataset: OOD_Sun, test set: 10000 images ############
2024-06-16 05:23:51,159 | INFO | test_ood.py:80 | run_test_ood | Computing scores for OOD_Sun...
2024-06-16 05:24:25,712 | INFO | model_hub.py:304 | compute_scores | Took 34.55 s to run.
2024-06-16 05:24:25,786 | INFO | metrics.py:55 | print_metrics | OOD_Sun - mcm_score
2024-06-16 05:24:25,786 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:24:25,786 | INFO | metrics.py:57 | print_metrics | & 35.57 & 92.79 & 98.34
2024-06-16 05:24:26,670 | INFO | metrics.py:55 | print_metrics | OOD_Sun - gl_mcm_score
2024-06-16 05:24:26,670 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:24:26,670 | INFO | metrics.py:57 | print_metrics | & 28.17 & 93.36 & 98.34
2024-06-16 05:24:27,378 | INFO | test_ood.py:78 | run_test_ood | ############ OOD dataset: OOD_Places, test set: 10000 images ############
2024-06-16 05:24:27,378 | INFO | test_ood.py:80 | run_test_ood | Computing scores for OOD_Places...
2024-06-16 05:24:58,452 | INFO | model_hub.py:304 | compute_scores | Took 31.07 s to run.
2024-06-16 05:24:58,523 | INFO | metrics.py:55 | print_metrics | OOD_Places - mcm_score
2024-06-16 05:24:58,524 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:24:58,524 | INFO | metrics.py:57 | print_metrics | & 42.64 & 90.16 & 97.59
2024-06-16 05:24:59,297 | INFO | metrics.py:55 | print_metrics | OOD_Places - gl_mcm_score
2024-06-16 05:24:59,297 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:24:59,297 | INFO | metrics.py:57 | print_metrics | & 36.80 & 90.40 & 97.52
2024-06-16 05:24:59,997 | INFO | test_ood.py:78 | run_test_ood | ############ OOD dataset: OOD_Texture, test set: 5640 images ############
2024-06-16 05:24:59,997 | INFO | test_ood.py:80 | run_test_ood | Computing scores for OOD_Texture...
2024-06-16 05:25:18,492 | INFO | model_hub.py:304 | compute_scores | Took 18.49 s to run.
2024-06-16 05:25:18,550 | INFO | metrics.py:55 | print_metrics | OOD_Texture - mcm_score
2024-06-16 05:25:18,551 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:25:18,551 | INFO | metrics.py:57 | print_metrics | & 55.83 & 86.58 & 98.11
2024-06-16 05:25:19,272 | INFO | metrics.py:55 | print_metrics | OOD_Texture - gl_mcm_score
2024-06-16 05:25:19,272 | INFO | metrics.py:56 | print_metrics |   FPR95 AUROC AUPR
2024-06-16 05:25:19,272 | INFO | metrics.py:57 | print_metrics | & 54.17 & 84.59 & 97.58
2024-06-16 05:25:19,952 | INFO | test_ood.py:98 | run_test_ood | ############ Metrics for mcm_score ############
2024-06-16 05:25:19,955 | INFO | metrics.py:76 | save_metrics | ############ Mean metrics ############
2024-06-16 05:25:19,956 | INFO | metrics.py:77 | save_metrics | 
                 FPR95  AUROC  AUPR
OOD dataset                        
OOD_iNaturalist  26.92  94.67 98.81
OOD_Sun          35.57  92.79 98.34
OOD_Places       42.64  90.16 97.59
OOD_Texture      55.83  86.58 98.11
Avg              40.24  91.05 98.21
2024-06-16 05:25:19,956 | INFO | metrics.py:78 | save_metrics | Metrics saved to ./results/training-free/clip_base/ID_ImageNet1K/SeTAR/metrics_mcm_score_test.csv
2024-06-16 05:25:19,957 | INFO | metrics.py:87 | save_cutoffs | ############ Thresholds Cut-off ############
2024-06-16 05:25:19,958 | INFO | metrics.py:88 | save_cutoffs | 
    OOD dataset   Cutoff
OOD_iNaturalist 0.001096
        OOD_Sun 0.001096
     OOD_Places 0.001096
    OOD_Texture 0.001096
2024-06-16 05:25:19,958 | INFO | metrics.py:89 | save_cutoffs | Thresholds cutoff saved to ./results/training-free/clip_base/ID_ImageNet1K/SeTAR/cutoffs_mcm_score_test.csv
2024-06-16 05:25:19,958 | INFO | test_ood.py:98 | run_test_ood | ############ Metrics for gl_mcm_score ############
2024-06-16 05:25:19,960 | INFO | metrics.py:76 | save_metrics | ############ Mean metrics ############
2024-06-16 05:25:19,960 | INFO | metrics.py:77 | save_metrics | 
                 FPR95  AUROC  AUPR
OOD dataset                        
OOD_iNaturalist  13.36  96.92 99.28
OOD_Sun          28.17  93.36 98.34
OOD_Places       36.80  90.40 97.52
OOD_Texture      54.17  84.59 97.58
Avg              33.12  91.32 98.18
2024-06-16 05:25:19,960 | INFO | metrics.py:78 | save_metrics | Metrics saved to ./results/training-free/clip_base/ID_ImageNet1K/SeTAR/metrics_gl_mcm_score_test.csv
2024-06-16 05:25:19,961 | INFO | metrics.py:87 | save_cutoffs | ############ Thresholds Cut-off ############
2024-06-16 05:25:19,962 | INFO | metrics.py:88 | save_cutoffs | 
    OOD dataset   Cutoff
OOD_iNaturalist 0.002232
        OOD_Sun 0.002232
     OOD_Places 0.002232
    OOD_Texture 0.002232
2024-06-16 05:25:19,962 | INFO | metrics.py:89 | save_cutoffs | Thresholds cutoff saved to ./results/training-free/clip_base/ID_ImageNet1K/SeTAR/cutoffs_gl_mcm_score_test.csv
2024-06-16 05:25:19,962 | INFO | test_ood.py:107 | run_test_ood | ############ Done! Test time: 4m 23s ############
2024-06-16 05:25:19,962 | INFO | test_classify.py:121 | run_test_classify | ############ Test Classification ############
2024-06-16 05:25:19,962 | INFO | test_classify.py:122 | run_test_classify | Loading CLIP model: openai/clip-vit-base-patch16...
2024-06-16 05:25:20,545 | INFO | test_classify.py:131 | run_test_classify | Applying SVD prune to 'small' weights...
2024-06-16 05:25:20,548 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.11.mlp.fc1] [rank(115)=round(full_rank(768)*rank_ratio(0.15))]
2024-06-16 05:25:20,548 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.10.mlp.fc1] [rank(115)=round(full_rank(768)*rank_ratio(0.15))]
2024-06-16 05:25:20,548 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.9.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 05:25:20,548 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.8.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 05:25:20,548 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.7.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 05:25:20,548 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.6.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 05:25:20,548 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.5.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 05:25:20,549 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.4.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 05:25:20,549 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.3.mlp.fc1] [rank(38)=round(full_rank(768)*rank_ratio(0.05))]
2024-06-16 05:25:20,549 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.2.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 05:25:20,549 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.1.mlp.fc1] [rank(0)=round(full_rank(768)*rank_ratio(0))]
2024-06-16 05:25:20,549 | INFO | model_hub.py:190 | to_target_modules | [vision_model.encoder.layers.0.mlp.fc1] [rank(115)=round(full_rank(768)*rank_ratio(0.15))]
2024-06-16 05:25:20,549 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.11.mlp.fc1] [rank(0)=round(full_rank(512)*rank_ratio(0))]
2024-06-16 05:25:20,549 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.10.mlp.fc1] [rank(0)=round(full_rank(512)*rank_ratio(0))]
2024-06-16 05:25:20,549 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.9.mlp.fc1] [rank(0)=round(full_rank(512)*rank_ratio(0))]
2024-06-16 05:25:20,549 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.8.mlp.fc1] [rank(0)=round(full_rank(512)*rank_ratio(0))]
2024-06-16 05:25:20,549 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.7.mlp.fc1] [rank(0)=round(full_rank(512)*rank_ratio(0))]
2024-06-16 05:25:20,549 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.6.mlp.fc1] [rank(128)=round(full_rank(512)*rank_ratio(0.25))]
2024-06-16 05:25:20,549 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.5.mlp.fc1] [rank(51)=round(full_rank(512)*rank_ratio(0.1))]
2024-06-16 05:25:20,549 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.4.mlp.fc1] [rank(102)=round(full_rank(512)*rank_ratio(0.2))]
2024-06-16 05:25:20,549 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.3.mlp.fc1] [rank(26)=round(full_rank(512)*rank_ratio(0.05))]
2024-06-16 05:25:20,549 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.2.mlp.fc1] [rank(26)=round(full_rank(512)*rank_ratio(0.05))]
2024-06-16 05:25:20,549 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.1.mlp.fc1] [rank(0)=round(full_rank(512)*rank_ratio(0))]
2024-06-16 05:25:20,549 | INFO | model_hub.py:190 | to_target_modules | [text_model.encoder.layers.0.mlp.fc1] [rank(102)=round(full_rank(512)*rank_ratio(0.2))]
2024-06-16 05:25:20,549 | INFO | model_hub.py:194 | to_target_modules | lora_settings -> target_modules: 
{
    "vision_model.encoder.layers.11.mlp.fc1": 115,
    "vision_model.encoder.layers.10.mlp.fc1": 115,
    "vision_model.encoder.layers.9.mlp.fc1": 0,
    "vision_model.encoder.layers.8.mlp.fc1": 0,
    "vision_model.encoder.layers.7.mlp.fc1": 0,
    "vision_model.encoder.layers.6.mlp.fc1": 0,
    "vision_model.encoder.layers.5.mlp.fc1": 0,
    "vision_model.encoder.layers.4.mlp.fc1": 0,
    "vision_model.encoder.layers.3.mlp.fc1": 38,
    "vision_model.encoder.layers.2.mlp.fc1": 0,
    "vision_model.encoder.layers.1.mlp.fc1": 0,
    "vision_model.encoder.layers.0.mlp.fc1": 115,
    "text_model.encoder.layers.11.mlp.fc1": 0,
    "text_model.encoder.layers.10.mlp.fc1": 0,
    "text_model.encoder.layers.9.mlp.fc1": 0,
    "text_model.encoder.layers.8.mlp.fc1": 0,
    "text_model.encoder.layers.7.mlp.fc1": 0,
    "text_model.encoder.layers.6.mlp.fc1": 128,
    "text_model.encoder.layers.5.mlp.fc1": 51,
    "text_model.encoder.layers.4.mlp.fc1": 102,
    "text_model.encoder.layers.3.mlp.fc1": 26,
    "text_model.encoder.layers.2.mlp.fc1": 26,
    "text_model.encoder.layers.1.mlp.fc1": 0,
    "text_model.encoder.layers.0.mlp.fc1": 102
}
2024-06-16 05:25:20,555 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.11.mlp.fc1] [Rank: 115]
2024-06-16 05:25:20,559 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.10.mlp.fc1] [Rank: 115]
2024-06-16 05:25:20,560 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.9.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:25:20,560 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.8.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:25:20,560 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.7.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:25:20,560 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.6.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:25:20,560 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.5.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:25:20,560 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.4.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:25:20,562 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.3.mlp.fc1] [Rank: 38]
2024-06-16 05:25:20,562 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.2.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:25:20,562 | INFO | model.py:71 | inject_adapter | [vision_model.encoder.layers.1.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:25:20,566 | INFO | model.py:78 | inject_adapter | [vision_model.encoder.layers.0.mlp.fc1] [Rank: 115]
2024-06-16 05:25:20,566 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.11.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:25:20,566 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.10.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:25:20,566 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.9.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:25:20,566 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.8.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:25:20,566 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.7.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:25:20,570 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.6.mlp.fc1] [Rank: 128]
2024-06-16 05:25:20,571 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.5.mlp.fc1] [Rank: 51]
2024-06-16 05:25:20,574 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.4.mlp.fc1] [Rank: 102]
2024-06-16 05:25:20,575 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.3.mlp.fc1] [Rank: 26]
2024-06-16 05:25:20,576 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.2.mlp.fc1] [Rank: 26]
2024-06-16 05:25:20,576 | INFO | model.py:71 | inject_adapter | [text_model.encoder.layers.1.mlp.fc1] [Rank: 0] [Skipped]
2024-06-16 05:25:20,579 | INFO | model.py:78 | inject_adapter | [text_model.encoder.layers.0.mlp.fc1] [Rank: 102]
2024-06-16 05:25:20,841 | INFO | model.py:192 | svd_init | SVD initialized for adapter 'default'.
2024-06-16 05:25:20,863 | INFO | test_classify.py:151 | run_test_classify | ############ ID_ImageNet1K ############
2024-06-16 05:27:33,760 | INFO | test_classify.py:161 | run_test_classify | Accuracy on ID_ImageNet1K: 63.97
2024-06-16 05:27:33,760 | INFO | test_classify.py:151 | run_test_classify | ############ OOD_Sun ############
2024-06-16 05:28:07,914 | INFO | test_classify.py:161 | run_test_classify | Accuracy on OOD_Sun: 75.50
2024-06-16 05:28:07,914 | INFO | test_classify.py:151 | run_test_classify | ############ OOD_Places ############
2024-06-16 05:28:35,354 | INFO | test_classify.py:161 | run_test_classify | Accuracy on OOD_Places: 45.81
2024-06-16 05:28:35,355 | INFO | test_classify.py:151 | run_test_classify | ############ OOD_Texture ############
2024-06-16 05:28:52,215 | INFO | test_classify.py:161 | run_test_classify | Accuracy on OOD_Texture: 43.76
2024-06-16 05:28:52,216 | INFO | test_classify.py:164 | run_test_classify | ############ Summary ############
2024-06-16 05:28:52,216 | INFO | test_classify.py:166 | run_test_classify | Accuracy on ID_ImageNet1K: 63.97
2024-06-16 05:28:52,216 | INFO | test_classify.py:166 | run_test_classify | Accuracy on OOD_Sun: 75.50
2024-06-16 05:28:52,216 | INFO | test_classify.py:166 | run_test_classify | Accuracy on OOD_Places: 45.81
2024-06-16 05:28:52,216 | INFO | test_classify.py:166 | run_test_classify | Accuracy on OOD_Texture: 43.76
